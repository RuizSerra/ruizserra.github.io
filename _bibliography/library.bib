Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Brockman2016,
abstract = {OpenAI Gym is a toolkit for reinforcement learning research. It includes a growing collection of benchmark problems that expose a common interface, and a website where people can share their results and compare the performance of algorithms. This whitepaper discusses the components of OpenAI Gym and the design decisions that went into the software.},
archivePrefix = {arXiv},
arxivId = {1606.01540},
author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
eprint = {1606.01540},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Brockman et al. - 2016 - OpenAI Gym.pdf:pdf},
month = {jun},
title = {{OpenAI Gym}},
url = {http://arxiv.org/abs/1606.01540},
year = {2016}
}
@article{Hochreiter1997,
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient-based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
author = {Hochreiter, Sepp and Schmidhuber, J{\"{u}}rgen},
doi = {10.1162/neco.1997.9.8.1735},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hochreiter, Schmidhuber - 1997 - Long Short-Term Memory.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {8},
pages = {1735--1780},
pmid = {9377276},
title = {{Long Short-Term Memory}},
volume = {9},
year = {1997}
}
@inproceedings{Tang2020,
abstract = {Inattentional blindness is the psychological phenomenon that causes one to miss things in plain sight. It is a consequence of the selective attention in perception that lets us remain focused on important parts of our world without distraction from irrelevant details. Motivated by selective attention, we study the properties of artificial agents that perceive the world through the lens of a self-attention bottleneck. By constraining access to only a small fraction of the visual input, we show that their policies are directly interpretable in pixel space. We find neuroevolution ideal for training self-attention architectures for vision-based reinforcement learning (RL) tasks, allowing us to incorporate modules that can include discrete, non-differentiable operations which are useful for our agent. We argue that self-attention has similar properties as indirect encoding, in the sense that large implicit weight matrices are generated from a small number of key-query parameters, thus enabling our agent to solve challenging vision based tasks with at least 1000x fewer parameters than existing methods. Since our agent attends to only task critical visual hints, they are able to generalize to environments where task irrelevant elements are modified while conventional methods fail. Videos of our results and source code available at https://attentionagent.github.io/},
annote = {Tang2020 in Obsidian.md},
archivePrefix = {arXiv},
arxivId = {2003.08165},
author = {Tang, Yujin and Nguyen, Duong and Ha, David},
booktitle = {GECCO '20: Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
doi = {10.1145/3377930.3389847},
eprint = {2003.08165},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Tang, Nguyen, Ha - 2020 - Neuroevolution of Self-Interpretable Agents.pdf:pdf},
pages = {414--424},
title = {{Neuroevolution of Self-Interpretable Agents}},
url = {http://arxiv.org/abs/2003.08165},
year = {2020}
}
@article{Simons1999,
abstract = {With each eye fixation, we experience a richly detailed visual world. Yet recent work on visual integration and change direction reveals that we are surprisingly unaware of the details of our environment from one view to the next: we often do not detect large changes to objects and scenes (`change blindness'). Furthermore, without attention, we may not even perceive objects (`inattentional blindness'). Taken together, these findings suggest that we perceive and remember only those objects and details that receive focused attention. In this paper, we briefly review and discuss evidence for these cognitive forms of `blindness'. We then present a new study that builds on classic studies of divided visual attention to examine inattentional blindness for complex objects and events in dynamic scenes. Our results suggest that the likelihood of noticing an unexpected object depends on the similarity of that object to other objects in the display and on how difficult the priming monitoring task is. Interestingly, spatial proximity of the critical unattended object to attended locations does not appear to affect detection, suggesting that observers attend to objects and events, not spatial positions. We discuss the implications of these results for visual representations and awareness of our visual environment.},
author = {Simons, Daniel J and Chabris, Christopher F},
doi = {10.1068/p281059},
file = {:Users/jaime/Documents/SwinDRLVP/papers/simons1999.pdf:pdf},
journal = {Perception},
number = {9},
pages = {1059--74},
title = {{Gorillas in our midst: sustained inattentional blindness for dynamic events}},
volume = {28},
year = {1999}
}
@misc{Zeiler2013,
author = {Zeiler, Matthew D and Fergus, Rob},
title = {{Visualizing and Understanding Convolutional Networks}},
url = {https://arxiv.org/abs/1311.2901},
year = {2013}
}
@article{Qiu2020,
abstract = {A critical issue in evolutionary robotics is the transfer of controllers learned in simulation to reality. This is especially the case for small Unmanned Aerial Vehicles (UAVs), as the platforms are highly dynamic and susceptible to breakage. Previous approaches often require simulation models with a high level of accuracy, otherwise significant errors may arise when the well-designed controller is being deployed onto the targeted platform. Here we try to overcome the transfer problem from a different perspective, by designing a spiking neurocontroller which uses synaptic plasticity to cross the reality gap via online adaptation. Through a set of experiments we show that the evolved plastic spiking controller can maintain its functionality by self-adapting to model changes that take place after evolutionary training, and consequently exhibit better performance than its non-plastic counterpart.},
archivePrefix = {arXiv},
arxivId = {2002.09854},
author = {Qiu, Huanneng and Garratt, Matthew and Howard, David and Anavatti, Sreenatha},
doi = {10.1145/3377930.3389843},
eprint = {2002.09854},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2002.09854.pdf:pdf},
isbn = {9781450371285},
journal = {GECCO 2020 - Proceedings of the 2020 Genetic and Evolutionary Computation Conference},
keywords = {Evolutionary robotics,Hebbian plasticity,Neuroevolution,Spiking neural networks,UAV control},
pages = {130--138},
title = {{Towards crossing the reality gap with evolved plastic neurocontrollers}},
year = {2020}
}
@inproceedings{Perez-Yus2017,
abstract = {Recent research demonstrates that visual prostheses are able to provide visual perception to people with some kind of blindness. In visual prostheses, image information from the scene is transformed to a phosphene pattern to be sent to the implant. This is a complex problem where the main challenge is the very limited spatial and intensity resolution. Moreover, depth perception, which is relevant to perform agile navigation, is lost and codifying the semantic information to phosphene patterns remains an open problem. In this work, we consider the framework of perception for navigation where aspects such as obstacle avoidance are critical. We propose using a head-mounted RGB-D camera to detect free-space, obstacles and scene direction in front of the user. The main contribution is a new approach to represent depth information and provide motion cues by using particular phosphene patterns. The effectiveness of this approach is tested in simulation with real data from indoor environments.},
author = {Perez-Yus, Alejandro and Bermudez-Cameo, Jesus and Guerrero, Jose J. and Lopez-Nicolas, Gonzalo},
booktitle = {Proceedings - 2017 IEEE International Conference on Computer Vision Workshops, ICCVW 2017},
doi = {10.1109/ICCVW.2017.179},
isbn = {9781538610343},
pages = {1516--1525},
title = {{Depth and Motion Cues with Phosphene Patterns for Prosthetic Vision}},
volume = {2018-Janua},
year = {2017}
}
@article{Montavon2017,
abstract = {Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard for various challenging machine learning problems such as image recognition. Although these methods perform impressively well, they have a significant disadvantage, the lack of transparency, limiting the interpretability of the solution and thus the scope of application in practice. Especially DNNs act as black boxes due to their multilayer nonlinear structure. In this paper we introduce a novel methodology for interpreting generic multilayer neural networks by decomposing the network classification decision into contributions of its input elements. Although our focus is on image classification, the method is applicable to a broad set of input data, learning tasks and network architectures. Our method called deep Taylor decomposition efficiently utilizes the structure of the network by backpropagating the explanations from the output to the input layer. We evaluate the proposed method empirically on the MNIST and ILSVRC data sets.},
archivePrefix = {arXiv},
arxivId = {1512.02479},
author = {Montavon, Gr{\'{e}}goire and Lapuschkin, Sebastian and Binder, Alexander and Samek, Wojciech and M{\"{u}}ller, Klaus Robert},
doi = {10.1016/j.patcog.2016.11.008},
eprint = {1512.02479},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1512.02479.pdf:pdf},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Deep neural networks,Heatmapping,Image recognition,Relevance propagation,Taylor decomposition},
pages = {211--222},
title = {{Explaining nonlinear classification decisions with deep Taylor decomposition}},
volume = {65},
year = {2017}
}
@article{Zhao2019,
abstract = {Saliency detection is one of the basic challenges in computer vision. Recently, CNNs are the most widely used and powerful techniques for saliency detection, in which feature maps from different layers are always integrated without distinction. However, instinctively, the different feature maps of CNNs and the different features in the same maps should play different roles in saliency detection. To address this problem, a novel CNN named pyramid feature attention network (PFAN) is proposed to enhance the high-level context features and the low-level spatial structural features. In the proposed PFAN, a context-aware pyramid feature extraction (CPFE) module is designed for multi-scale high-level feature maps to capture the rich context features. A channel-wise attention (CA) model and a spatial attention (SA) model are respectively applied to the CPFE feature maps and the low-level feature maps, and then fused to detect salient regions. Finally, an edge preservation loss is proposed to get the accurate boundaries of salient regions. The proposed PFAN is extensively evaluated on five benchmark datasets and the experimental results demonstrate that the proposed network outperforms the state-of-the-art approaches under different evaluation metrics.},
archivePrefix = {arXiv},
arxivId = {1903.00179},
author = {Zhao, Ting and Wu, Xiangqian},
doi = {10.1109/CVPR.2019.00320},
eprint = {1903.00179},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Zhao{\_}Pyramid{\_}Feature{\_}Attention{\_}Network{\_}for{\_}Saliency{\_}Detection{\_}CVPR{\_}2019{\_}paper.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Categorization,Deep Learning,Grouping and Shape,Recognition: Detection,Retrieval,Segmentation},
pages = {3080--3089},
title = {{Pyramid feature attention network for saliency detection}},
volume = {2019-June},
year = {2019}
}
@article{Nagel1974,
author = {Nagel, Thomas},
doi = {10.2307/2176743},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Nagel - 1974 - What Is It Like to Be a Bat.pdf:pdf},
isbn = {0031810820090},
journal = {The Philosophical Review},
number = {4},
pages = {435--450},
title = {{What Is It Like to Be a Bat ?}},
volume = {83},
year = {1974}
}
@article{Ma2019,
abstract = {Robot navigation in mapless environment is one of the essential problems and challenges in mobile robots. Deep reinforcement learning is a promising technique to tackle the task of mapless navigation. Since reinforcement learning requires a lot of explorations, it is usually necessary to train the agent in the simulator and then migrate to the real environment. The big reality gap makes RGB image, the most common visual format, rarely used. In this paper we present a learning-based mapless motion planner taking RGB image as visual input. In the end-to-end navigation network many of the parameters are used to extract visual features. The proposed motion palnner decoupled visual features extracted module from the reinforcement learning network to improve the sample efficiency. Variational Autoencoder (VAE) is used to encode the image, and the obtained latent vector is input as low-dimensional visual features into the network together with the target and motion information. We built and released a set of simulation environments for algorithm comparison. In the test environment, the proposed method was compared with the end-to-end network, which proved its effectiveness and efficiency. The source code is available: Https://github.com/marooncn/navbot.},
archivePrefix = {arXiv},
arxivId = {1903.09927},
author = {Ma, Liulong and Liu, Yanjie and Chen, Jiao},
eprint = {1903.09927},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1903.09927.pdf:pdf},
journal = {arXiv},
number = {2},
title = {{Using rgb image as visual input for mapless robot navigation}},
year = {2019}
}
@article{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies di- rectly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learn- ing Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:pdf},
isbn = {9789811540950},
journal = {Deep Reinforcement Learning: Fundamentals, Research and Applications},
keywords = {DQN},
title = {{Playing Atari with Deep Reinforcement Learning}},
year = {2013}
}
@article{Lozano2003,
abstract = {This paper presents a neural design which is able to provide the necessary reactive navigation and attention skills for 3D embodied agents (virtual humanoids or characters). Based on Grossbergs neural model of conditioning [6], as recently implemented by Chang and Gaudiando [7], and according to the Adaptative Resonance Theory (ART) and the neuroscientific concepts associated, the neural design introduced has been divided in two main phases. Firstly, an environmentcategorization phase, where an on-line pattern recognition and categorization of the current agent sensory input data is carried out by a self organizing neural network, which will finally provide the agents short term memory layer(STM). Secondly, and based on the classical conditioning paradigm, the model will associate the interesting STM states, from the navigation or attention points of view, to finally simulate these necessary skills for 3D characters or humanoids. Finally, we will show some experimental navigational results, through the integration of the model presented in 3D virtual environments. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
author = {Lozano, Miguel and Grimaldo, Francisco and Villaplana, Javier},
doi = {10.1007/3-540-44869-1_27},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Lozano, Grimaldo, Villaplana - 2003 - Towards reactive navigation and attention skills for 3D intelligent characters.pdf:pdf},
isbn = {354040211X},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {209--216},
title = {{Towards reactive navigation and attention skills for 3D intelligent characters}},
volume = {2687},
year = {2003}
}
@article{Stanley2009,
author = {Stanley, Kenneth O. and D'Ambrosio, David B. and Gauci, Jason},
journal = {Artificial Life},
number = {15},
pages = {182--212},
title = {{A hypercube-based encoding for evolving large-scale neural networks}},
url = {http://eplex.cs.ucf.edu/hyperNEATpage/},
volume = {2},
year = {2009}
}
@article{Choi2017,
abstract = {Deep reinforcement learning (DRL) has shown incredible performance in learning various tasks to the human level. However, unlike human perception, current DRL models connect the entire low-level sensory input to the state-action values rather than exploiting the relationship between and among entities that constitute the sensory input. Because of this difference, DRL needs vast amount of experience samples to learn. In this paper, we propose a Multi-focus Atten-tion Network (MANet) which mimics human ability to spatially abstract the low-level sensory input into multiple entities and attend to them simultaneously. The proposed method first divides the low-level input into several segments which we refer to as partial states. After this segmentation, parallel attention layers attend to the partial states relevant to solving the task. Our model estimates state-action values using these attended partial states. In our experiments, MANet attains highest scores with significantly less experience samples. Additionally, the model shows higher performance compared to the Deep Q-network and the single attention model as benchmarks. Furthermore, we extend our model to attentive communication model for performing multi-agent cooperative tasks, in multi-agent cooperative task experiments, our model shows 20{\%} faster learning than existing state-of-the-art model.},
archivePrefix = {arXiv},
arxivId = {1712.04603},
author = {Choi, Jinyoung and Lee, Beom-Jin Jin and Zhang, Byoung-Tak Tak},
eprint = {1712.04603},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Choi, Lee, Zhang - 2017 - Multi-focus Attention Network for Efficient Deep Reinforcement Learning.pdf:pdf;:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Choi, Lee, Zhang - 2017 - Multi-focus Attention Network for Efficient Deep Reinforcement Learning(2).pdf:pdf;:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Choi, Lee, Zhang - 2017 - Multi-focus attention network for efficient deep reinforcement learning(3).pdf:pdf},
isbn = {9781577357865},
journal = {AAAI Workshop - Technical Report},
month = {dec},
pages = {952--958},
publisher = {AI Access Foundation},
title = {{Multi-focus attention network for efficient deep reinforcement learning}},
url = {http://arxiv.org/abs/1712.04603},
volume = {WS-17-01 -},
year = {2017}
}
@article{Cetin2019,
abstract = {Unmanned aerial vehicles (UAV) specifically drones have been used for surveillance, shipping and delivery, wildlife monitoring, disaster management etc. The increase on the number of drones in the airspace worldwide will lead necessarily to full autonomous drones. Given the expected huge number of drones, if they were operated by human pilots, the possibility to collide with each other could be too high. In this paper, deep reinforcement learning (DRL) architecture is proposed to make drones behave autonomously inside a suburb neighborhood environment. The environment in the simulator has plenty of obstacles such as trees, cables, parked cars and houses. In addition, there are also another drones, acting as moving obstacles, inside the environment while the learner drone has a goal to achieve. In this way the drone can be trained to detect stationary and moving obstacles inside the neighborhood and so the drones can be used safely in a public area in the future. The drone has a front camera and it can capture continuously depth images. Every depth image is part of the state used in DRL architecture. Also, another part of the state is the distance to the geo-fence (a virtual barrier on the environment) which is added as a scalar value. The agent will be rewarded negatively when it tries to overpass the geo-fence limits. In addition, angle to goal and elevation angle between the goal and the drone will be used as information to be added to the state. It is considered that these scalar values will improve the DRL performance and also the reward obtained. The drone is trained using Q-Network and its convergence and final reward are evaluated. The states containing image and several scalars are processed by a neural network that joints the two state parts into a unique flow. This neural network is named as Joint Neural Network (JNN) [1]. The training and test results show that the agent can successfully learn to avoid any obstacle in the environment. The results for three scenarios are very promising and the learner drone reaches the destination with a success rate 100{\%} in first two tests and with a success rate 98{\%} in the last test, this one with a total of three drones.},
author = {Cetin, Ender and Barrado, Cristina and Munoz, Guillem and MacIas, Miquel and Pastor, Enric},
doi = {10.1109/DASC43569.2019.9081749},
file = {:Users/jaime/Documents/SwinDRLVP/papers/cetin2019.pdf:pdf},
isbn = {9781728106496},
issn = {21557209},
journal = {AIAA/IEEE Digital Avionics Systems Conference - Proceedings},
keywords = {DDQN,Deep Reinforcement Learning,Drones,JNN,Q-Network,UAV},
title = {{Drone Navigation and Avoidance of Obstacles Through Deep Reinforcement Learning}},
volume = {2019-Septe},
year = {2019}
}
@article{McLaren2020linkedin,
author = {McLaren, Glenn},
title = {{Anticipating uncertainty: living with the possibility of pandemics}},
url = {https://www.linkedin.com/posts/glenn-mclaren-ab585046{\_}anticipating-uncertainty-activity-6658594262483038208-ZIpl},
year = {2020}
}
@book{Pollan2013,
author = {Pollan, Michael},
isbn = {9780143125334},
publisher = {Allen Lane},
title = {{Cooked: A Natural History of Transformation}},
year = {2013}
}
@article{Bostrom1998,
abstract = {This paper outlines the case for believing that we will have superhuman artificial intelligence within the first third of the next century. It looks at different estimates of the processing power of the human brain; how long it will take until computer hardware achieve a similar performance; ways of creating the software through bottom-up approaches like the one used by biological brains; how difficult it will be for neuroscience figure out enough about how brains work to make this approach work; and how fast we can expect superintelligence to be developed once there is human-level artificial intelligence.},
author = {Bostrom, Nick},
journal = {International Journal of Future Studies},
title = {{How Long Before Superintelligence}},
volume = {2},
year = {1998}
}
@article{Bello2019,
abstract = {Convolutional networks have been the paradigm of choice in many computer vision applications. The convolution operation however has a significant weakness in that it only operates on a local neighborhood, thus missing global information. Self-attention, on the other hand, has emerged as a recent advance to capture long range interactions, but has mostly been applied to sequence modeling and generative modeling tasks. In this paper, we consider the use of self-attention for discriminative visual tasks as an alternative to convolutions. We introduce a novel two-dimensional relative self-attention mechanism that proves competitive in replacing convolutions as a stand-alone computational primitive for image classification. We find in control experiments that the best results are obtained when combining both convolutions and self-attention. We therefore propose to augment convolutional operators with this self-attention mechanism by concatenating convolutional feature maps with a set of feature maps produced via self-attention. Extensive experiments show that Attention Augmentation leads to consistent improvements in image classification on ImageNet and object detection on COCO across many different models and scales, including ResNets and a state-of-the art mobile constrained network, while keeping the number of parameters similar. In particular, our method achieves a {\$}1.3\backslash{\%}{\$} top-1 accuracy improvement on ImageNet classification over a ResNet50 baseline and outperforms other attention mechanisms for images such as Squeeze-and-Excitation. It also achieves an improvement of 1.4 mAP in COCO Object Detection on top of a RetinaNet baseline.},
archivePrefix = {arXiv},
arxivId = {1904.09925},
author = {Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V.},
eprint = {1904.09925},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Bello et al. - 2019 - Attention Augmented Convolutional Networks.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
month = {apr},
pages = {3285--3294},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Attention Augmented Convolutional Networks}},
url = {http://arxiv.org/abs/1904.09925},
volume = {2019-Octob},
year = {2019}
}
@book{Landy1995,
author = {Landy, Michael S. and Maloney, Laurence T. and Pavel, Misha},
file = {:Users/jaime/Documents/SwinDRLVP/papers/(Springer Series in Perception Engineering) Robert M. Steinman (auth.), Michael S. Landy, Laurence T. Maloney, Misha Pavel (eds.) - Exploratory Vision{\_} The Active Eye-Springer-Verlag New York (1996).pdf:pdf},
isbn = {0387945636},
title = {{Exploratory Vision: The Active Eye}},
url = {http://www.amazon.com/dp/0387945636},
year = {1995}
}
@inproceedings{Bermudez-Cameo2017,
abstract = {Recent research on visual prosthesis demonstrates the possibility of providing visual perception to people with certain blindness. Bypassing the damaged part of the visual path, electrical stimulation provokes spot percepts known as phosphenes. Due to physiological and technological limitations the information received by patients has very low resolution and reduced dynamic range. In this context, the inclusion of new computer vision techniques to improve the semantic content in this information channel is an active and open key topic. In this paper, we present a system for Simulated Prosthetic Vision based on a head-mounted display with an RGB-D camera, and two tools, one focused on human interaction and the other oriented to navigation, exploring different proposals of phosphenic representations.},
address = {Cham},
author = {Bermudez-Cameo, Jesus and Badias-Herbera, Alberto and Guerrero-Viu, Manuel and Lopez-Nicolas, Gonzalo and Guerrero, Jose J},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-58838-4_47},
isbn = {9783319588377},
issn = {16113349},
keywords = {Head-mounted displays,RGB-D vision,Simulated prosthetic vision},
pages = {427--436},
publisher = {Springer International Publishing},
title = {{RGB-D computer vision techniques for simulated prosthetic vision}},
volume = {10255 LNCS},
year = {2017}
}
@article{Muryy2020,
abstract = {Neuroscientists postulate 3D representations in the brain in a variety of different coordinate frames (e.g. ‘head-centred', ‘hand-centred' and ‘world-based'). Recent advances in reinforcement learning demonstrate a quite different approach that may provide a more promising model for biological representations underlying spatial perception and navigation. In this paper, we focus on reinforcement learning methods that reward an agent for arriving at a target image without any attempt to build up a 3D ‘map'. We test the ability of this type of representation to support geometrically consistent spatial tasks such as interpolating between learned locations using decoding of feature vectors. We introduce a hand-crafted representation that has, by design, a high degree of geometric consistency and demonstrate that, in this case, information about the persistence of features as the camera translates (e.g. distant features persist) can improve performance on the geometric tasks. These examples avoid Cartesian (in this case, 2D) representations of space. Non-Cartesian, learned representations provide an important stimulus in neuroscience to the search for alternatives to a ‘cognitive map'.},
archivePrefix = {arXiv},
arxivId = {1912.06615},
author = {Muryy, Alex and Siddharth, N. and Nardelli, Nantas and Glennerster, Andrew and Torr, Philip H.S.},
doi = {10.1016/j.visres.2020.05.009},
eprint = {1912.06615},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Muryy et al. - 2020 - Lessons from reinforcement learning for biological representations of space.pdf:pdf},
issn = {18785646},
journal = {Vision Research},
keywords = {3D spatial representation,Deep Reinforcement Learning,Moving observer,Navigation,Parallax,View-based},
number = {October 2019},
pages = {79--93},
pmid = {32683096},
publisher = {Elsevier},
title = {{Lessons from reinforcement learning for biological representations of space}},
url = {https://doi.org/10.1016/j.visres.2020.05.009},
volume = {174},
year = {2020}
}
@inproceedings{Kheradvar2017,
abstract = {Researchers in the field of visual prostheses need a Simulated Prosthetic Vision (SPV) setup to evaluate their image processing algorithms on people with normal vision before implanting any retinal prostheses. In this paper, an SPV developed for a visual prosthesis is introduced and the associated experimental results are reported. These experiments are designed to examine the efficacy of two down sampling methods, the mode down sampling (MDS) and the nearest neighbor method. The experiments are conducted in a corridor including some obstacles. Three levels of difficulties are considered for each of the two methods and two measures are used to compare the efficiency of the methods: Percentage of Preferred Walking Speed (PPWS), and Total Hit Count (THC). The qualitative and quantitative results reported in this paper reveal that the controlled blinking of phosphenes would present additional information to help the patients.},
author = {Kheradvar, Benyamin and Mousavinia, Amir and Sodagar, Amir M},
booktitle = {Iranian Conference on Machine Vision and Image Processing, MVIP},
doi = {10.1109/IranianMVIP.2017.8342352},
isbn = {9781538644041},
issn = {21666784},
keywords = {Down sampling,Image processing,Retinal implant,Simulated Prosthetic Vision (SPV),Visual prosthesis},
month = {may},
pages = {15--19},
title = {{SPV experiments for a retinal visual prosthesis: Introducing a new feature: 'Blinking'}},
url = {https://ieeexplore.ieee.org/document/8342352},
volume = {2017-Novem},
year = {2018}
}
@article{Li2017,
author = {Li, Heng and Han, Tingting and Wang, Jing and Lu, Zhuofan and Cao, Xiaofei and Chen, Yao and Li, Liming and Zhou, Chuanqing and Chai, Xinyu},
doi = {https://doi.org/10.1016/j.ins.2017.06.014},
issn = {0020-0255},
journal = {Information Sciences},
keywords = {Eye-hand coordination,Retinal prostheses,Saliency detection,Simulated prosthetic vision},
pages = {1 -- 18},
title = {{A real-time image optimization strategy based on global saliency detection for artificial retinal prostheses}},
url = {http://www.sciencedirect.com/science/article/pii/S0020025516317571},
volume = {415-416},
year = {2017}
}
@inproceedings{White2019,
abstract = {Developing hand-crafted visual features to enhance perception with prosthetic vision devices can often miss important aspects of a given task. Retinal implants suffer from the need to create low-dimensional features for elaborate tasks such as navigation in complex environments. Using Deep Reinforcement Learning (DRL), visual features are learnt through task-based simulations that remove the ambiguity of inferring the visual information most crucial to a specific activity. Learning task-based features ensures that the visual information is salient to the tasks an implant recipient may be undertaking and eliminates potentially redundant features. In this paper, we focus specifically on basic orientation and mobility, and the methods for feature learning and visualisation in structured 3D environments. We propose a new model for learning visual features through task-based simulations and show that learnt features can be transferred directly to real RGB-D images. We demonstrate this new scalable approach for feature learning in simulation and open the possibility for more complex simulations of more complex tasks in the future.},
author = {White, Jack and Kameneva, Tatiana and McCarthy, Chris},
booktitle = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
doi = {10.1109/EMBC.2019.8856541},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/White, Kameneva, McCarthy - 2019 - Deep reinforcement learning for task-based feature learning in prosthetic vision.pdf:pdf},
isbn = {9781538613115},
issn = {1557170X},
pages = {2809--2812},
pmid = {31946477},
title = {{Deep reinforcement learning for task-based feature learning in prosthetic vision}},
year = {2019}
}
@article{Porter2016,
author = {Porter, Harry H.},
doi = {10.1007/978-3-319-41649-6},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Porter - 2016 - A Methodology for the Assesment of AI Consciousness.pdf:pdf},
isbn = {9783319416489},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {consciousness},
pages = {V},
title = {{A Methodology for the Assesment of AI Consciousness}},
volume = {9782},
year = {2016}
}
@article{Affanni2005,
abstract = {Different types of electric vehicles (EVs) have been recently designed with the aim of solving pollution problems caused by the emission of gasoline-powered engines. Environmental problems promote the adoption of new-generation electric vehicles for urban transportation. As it is well known, one of the weakest points of electric vehicles is the battery system. Vehicle autonomy and, therefore, accurate detection of battery state of charge (SoC) together with battery expected life, i.e., battery state of health, are among the major drawbacks that prevent the introduction of electric vehicles in the consumer market. The electric scooter may provide the most feasible opportunity among EVs. They may be a replacement product for the primary-use vehicle, especially in Europe and Asia, provided that drive performance, safety, and cost issues are similar to actual engine scooters. The battery system choice is a cruci al item, and thanks to an increasing emphasis on vehicle range and performance, the Li-ion battery could become a viable candidate. This paper deals with the design of a battery pack based on Li-ion technology for a prototype electric scooter with high performance and autonomy. The adopted battery system is composed of a suitable number of cells series connected, featuring a high voltage level. Therefore, cell equalization and monitoring need to be provided. Due to manufacturing asymmetries, charge and discharge cycles lead to cell unbalancing, reducing battery capacity and, depending on cell type, causing safety troubles or strongly limiting the storage capacity of the full pack. No solution is available on the mark et at a cheap price, because of the required voltage level and performance, therefore, a dedicated battery management system was designed, that also includes a battery SoC monitoring. The proposed solution features a high capability of energy storing in braking conditions, charge equalization, overvoltage and undervoltage protection and, obviously, SoC information in order to optimize autonomy instead of performance or vice-versa. {\textcopyright} 2005 IEEE.},
author = {Affanni, Antonio and Bellini, Alberto and Franceschini, Giovanni and Guglielmi, Paolo and Tassoni, Carla},
doi = {10.1109/TIE.2005.855664},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Affanni et al. - 2005 - Battery choice and management for new-generation electric vehicles.pdf:pdf},
issn = {02780046},
journal = {IEEE Transactions on Industrial Electronics},
keywords = {Batteries,Electric vehicles (EVs)},
number = {5},
pages = {1343--1349},
title = {{Battery choice and management for new-generation electric vehicles}},
volume = {52},
year = {2005}
}
@article{Gordon2019,
abstract = {We propose SplitNet, a method for decoupling visual perception and policy learning. By incorporating auxiliary tasks and selective learning of portions of the model, we explicitly decompose the learning objectives for visual navigation into perceiving the world and acting on that perception. We show dramatic improvements over baseline models on transferring between simulators, an encouraging step towards Sim2Real. Additionally, SplitNet generalizes better to unseen environments from the same simulator and transfers faster and more effectively to novel embodied navigation tasks. Further, given only a small sample from a target domain, SplitNet can match the performance of traditional end-to-end pipelines which receive the entire dataset},
author = {Gordon, Daniel and Kadian, Abhishek and Parikh, Devi and Hoffman, Judy and Batra, Dhruv},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Gordon{\_}SplitNet{\_}Sim2Sim{\_}and{\_}Task2Task{\_}Transfer{\_}for{\_}Embodied{\_}Visual{\_}Navigation{\_}ICCV{\_}2019{\_}paper.pdf:pdf},
journal = {arXiv},
pages = {1022--1031},
title = {{SplitNet: Sim2Sim and Task2Task transfer for embodied visual navigation}},
year = {2019}
}
@article{Stooke2020,
abstract = {In an effort to overcome limitations of reward-driven feature learning in deep reinforcement learning (RL) from images, we propose decoupling representation learning from policy learning. To this end, we introduce a new unsupervised learning (UL) task, called Augmented Temporal Contrast (ATC), which trains a convolutional encoder to associate pairs of observations separated by a short time difference, under image augmentations and using a contrastive loss. In online RL experiments, we show that training the encoder exclusively using ATC matches or outperforms end-to-end RL in most environments. Additionally, we benchmark several leading UL algorithms by pre-training encoders on expert demonstrations and using them, with weights frozen, in RL agents; we find that agents using ATC-trained encoders outperform all others. We also train multi-task encoders on data from multiple environments and show generalization to different downstream RL tasks. Finally, we ablate components of ATC, and introduce a new data augmentation to enable replay of (compressed) latent images from pre-trained encoders when RL requires augmentation. Our experiments span visually diverse RL benchmarks in DeepMind Control, DeepMind Lab, and Atari, and our complete code is available at https://github.com/astooke/rlpyt/tree/master/rlpyt/ul.},
archivePrefix = {arXiv},
arxivId = {2009.08319},
author = {Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
eprint = {2009.08319},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2009.08319.pdf:pdf},
title = {{Decoupling Representation Learning from Reinforcement Learning}},
url = {http://arxiv.org/abs/2009.08319},
year = {2020}
}
@article{Buchert2015,
abstract = {For developing sustainable products design engineers need to foresee diverse interrelations between a product's characteristics and its economic, social and environmental impacts. In order to support this complex task a wide range of design methods has been developed. Retrospective analytical methods like Life Cycle Sustainability Assessment (LCSA) require a large amount of information and are thus utilized when important design decisions are already made. Prospective methods are rather generic (e.g. checklists) and too broad to be helpful in concrete design decisions. In this paper, the integration of discrete decision trees with LCSA is proposed for shifting multi-criterial quantitative analysis to earlier development. On the basis of sustainability indicators Pareto-optimal decision-paths for given material- and process alternatives along the product lifecycle can be compared up-front. Resulting benefits and obstacles are illustrated by evaluating value creation options of a bicycle frame.},
author = {Buchert, Tom and Neugebauer, Sabrina and Schenker, Sebastian and Lindow, Kai and Stark, Rainer},
doi = {10.1016/j.procir.2014.07.110},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Buchert et al. - 2015 - Multi-criteria decision making as a tool for sustainable product development - Benefits and obstacles.pdf:pdf},
issn = {22128271},
journal = {Procedia CIRP},
keywords = {Decision support,Life Cycle Sustainability Assessment,Multi-criteria decision making,Sustainable Product Development},
pages = {70--75},
publisher = {Elsevier B.V.},
title = {{Multi-criteria decision making as a tool for sustainable product development - Benefits and obstacles}},
url = {http://dx.doi.org/10.1016/j.procir.2014.07.110},
volume = {26},
year = {2015}
}
@article{Gare2009,
author = {Gare, A},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gare - 2009 - Philosophical Anthropology, Ethics and Political Philosophy in an Age of Impending Catastrophe.pdf:pdf},
journal = {Cosmos {\&} History},
keywords = {aristotle,biosemiotics,c,culture,ethics,hegel,herder,hierarchy theory,hobbes,human ecology,marx,peirce,philosophical anthropology,political philosophy,s,schelling},
number = {2},
pages = {1--17},
title = {{Philosophical Anthropology, Ethics and Political Philosophy in an Age of Impending Catastrophe.}},
volume = {5},
year = {2009}
}
@article{Stanley2007,
author = {Stanley, Kenneth O.},
journal = {Genetic programming and evolvable machines},
number = {8},
pages = {131--162},
title = {{Compositional pattern producing networks: A novel abstraction of development}},
url = {https://eplex.cs.ucf.edu/papers/stanley{\_}gpem07.pdf},
volume = {2},
year = {2007}
}
@article{Chen2019,
abstract = {The autonomous navigation of smart ships needs to meet their huge inertia and obey existing complex rules. A smart ship has to realise autonomous driving instead of manual operation, which consists of path planning and controlling. Toward to this goal, this research proposes a path planning and manipulating approach based on Q-learning, which can drive a cargo ship by itself without requiring any input from human experiences. At the very beginning, a ship is modelled with the Nomoto model in a simulation waterway. Then, distances, obstacles and prohibited areas are regularized as rewards or punishments, which are used to judge the performance, or manipulation decisions of the ship. Subsequently, Q-learning is introduced to learn the action–reward model and the learning outcome is used to manipulate the ship's movement. By chasing higher reward values, the ship can find an appropriate path or navigation strategies by itself. After a sufficient number of rounds of training, a convincing path and manipulating strategies will likely be produced. By comparing the proposed approach with the existing methods, it is shown that this approach is more effective in self-learning and continuous optimisation, and therefore closer to human manoeuvring.},
author = {Chen, Chen and Chen, Xian Qiao and Ma, Feng and Zeng, Xiao Jun and Wang, Jin},
doi = {10.1016/j.oceaneng.2019.106299},
file = {:Users/jaime/Documents/SwinDRLVP/papers/chen2019.pdf:pdf},
issn = {00298018},
journal = {Ocean Engineering},
keywords = {Path planning,Q-learning,Rewards,Smart ships,Value function},
number = {June},
pages = {106299},
publisher = {Elsevier Ltd},
title = {{A knowledge-free path planning approach for smart ships based on reinforcement learning}},
url = {https://doi.org/10.1016/j.oceaneng.2019.106299},
volume = {189},
year = {2019}
}
@inproceedings{Mott2019,
abstract = {Inspired by recent work in attention models for image captioning and question answering, we present a soft attention model for the reinforcement learning domain. This model uses a soft, top-down attention mechanism to create a bottleneck in the agent, forcing it to focus on task-relevant information by sequentially querying its view of the environment. The output of the attention mechanism allows direct observation of the information used by the agent to select its actions, enabling easier interpretation of this model than of traditional models. We analyze different strategies that the agents learn and show that a handful of strategies arise repeatedly across different games. We also show that the model learns to query separately about space and content (“where” vs. “what”). We demonstrate that an agent using this mechanism can achieve performance competitive with state-of-the-art models on ATARI tasks while still being interpretable.},
archivePrefix = {arXiv},
arxivId = {1906.02500},
author = {Mott, Alex and Zoran, Daniel and Chrzanowski, Mike and Wierstra, Daan and Rezende, Danilo J.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1906.02500},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mott et al. - 2019 - Towards Interpretable Reinforcement Learning Using Attention Augmented Agents.pdf:pdf;:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mott et al. - 2019 - Towards interpretable reinforcement learning using attention augmented agents(2).pdf:pdf},
issn = {10495258},
month = {jun},
number = {NeurIPS},
title = {{Towards interpretable reinforcement learning using attention augmented agents}},
url = {http://arxiv.org/abs/1906.02500},
volume = {32},
year = {2019}
}
@article{Stanley2019,
abstract = {Rather than acting as a review or analysis of the field, this essay focuses squarely on the motivations for investigating open-endedness and the opportunities it opens up. It begins by contemplating the awesome accomplishments of evolution in nature and the profound implications if such a process could be ignited on a computer. Some of the milestones in our understanding so far are then discussed, finally closing by highlighting the grand challenge of formalizing open-endedness as a computational process that can be encoded as an algorithm. The main contribution is to articulate why open-endedness deserves a place alongside artificial intelligence as one of the great computational challenges, and opportunities, of our time.},
author = {Stanley, Kenneth O.},
doi = {10.1162/artl_a_00294},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Stanley - 2019 - Why Open-Endedness Matters.pdf:pdf},
issn = {15309185},
journal = {Artificial Life},
keywords = {Artificial intelligence,Machine learning,Novelty search,Open-ended algorithms,Open-ended evolution,Open-endedness,Quality diversity},
number = {3},
pages = {232--235},
pmid = {31397603},
title = {{Why Open-Endedness Matters}},
volume = {25},
year = {2019}
}
@article{Dulac-Arnold2019,
abstract = {Reinforcement learning (RL) has proven its worth in a series of artificial domains, and is beginning to show some successes in real-world scenarios. However, much of the research advances in RL are often hard to leverage in real-world systems due to a series of assumptions that are rarely satisfied in practice. We present a set of nine unique challenges that must be addressed to productionize RL to real world problems. For each of these challenges, we specify the exact meaning of the challenge, present some approaches from the literature, and specify some metrics for evaluating that challenge. An approach that addresses all nine challenges would be applicable to a large number of real world problems. We also present an example domain that has been modified to present these challenges as a testbed for practical RL research.},
archivePrefix = {arXiv},
arxivId = {1904.12901},
author = {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
eprint = {1904.12901},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Dulac-Arnold, Mankowitz, Hester - 2019 - Challenges of Real-World Reinforcement Learning.pdf:pdf},
title = {{Challenges of Real-World Reinforcement Learning}},
url = {http://arxiv.org/abs/1904.12901},
year = {2019}
}
@article{Rohmer2013,
abstract = {From exploring planets to cleaning homes, the reach and versatility of robotics is vast. The integration of actuation, sensing and control makes robotics systems powerful, but complicates their simulation. This paper introduces a versatile, scalable, yet powerful general-purpose robot simulation framework called V-REP. The paper discusses the utility of a portable and flexible simulation framework that allows for direct incorporation of various control techniques. This renders simulations and simulation models more accessible to a general-public, by reducing the simulation model deployment complexity. It also increases productivity by offering built-in and ready-to-use functionalities, as well as a multitude of programming approaches. This allows for a multitude of applications including rapid algorithm development, system verification, rapid prototyping, and deployment for cases such as safety/remote monitoring, training and education, hardware control, and factory automation simulation. {\textcopyright} 2013 IEEE.},
author = {Rohmer, Eric and Singh, Surya P.N. and Freese, Marc},
doi = {10.1109/IROS.2013.6696520},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Rohmer, Singh, Freese - 2013 - V-REP A versatile and scalable robot simulation framework.pdf:pdf},
isbn = {9781467363587},
issn = {21530858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {1321--1326},
title = {{V-REP: A versatile and scalable robot simulation framework}},
year = {2013}
}
@article{Schmidhuber1997,
abstract = {Some basic concepts of algorithmic complexity theory relevant to machine learning are reviewed along with the Solomon-Levin distribution (or universal prior) which deals with the prior problem. The universal prior leads to a probabilistic method for finding algorithmically simple problem solutions with high generalization capability. The method is based on Levin complexity and inspired by Levin's optimal universal search algorithm. For a given problem, solution candidates are computed by efficient self sizing programs that influence their own runtime and storage size. The method, at least with certain toy problems where it is computationally feasible, can lead to unmatchable generalization results.},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/S0893-6080(96)00127-X},
issn = {08936080},
journal = {Neural Networks},
keywords = {Generalization,Kolmogorov complexity,Levin complexity,Neural networks,Self-sizing programs,Solomonoff-Levin distribution,Universal search},
month = {jul},
number = {5},
pages = {857--873},
pmid = {12662875},
publisher = {Elsevier Science Ltd},
title = {{Discovering neural nets with low Kolmogorov complexity and high generalization capability}},
volume = {10},
year = {1997}
}
@misc{Yosinski2015,
author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
title = {{Understanding Neural Networks Through Deep Visualization}},
url = {https://arxiv.org/abs/1506.06579},
year = {2015}
}
@article{Zambaldi,
abstract = {We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretabil-ity. Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene. In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmaster-level on four. In a novel navigation and planning task, our agent's performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training. Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent's intentions. The main contribution of this work is to introduce techniques for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases. Our experiments show this approach can offer advantages in efficiency, generalization, and interpretability, and can scale up to meet some of the most challenging test environments in modern artificial intelligence.},
author = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Zambaldi et al. - Unknown - Deep Reinforcement Learning with Relational Inductive Biases.pdf:pdf},
title = {{Deep Reinforcement Learning with Relational Inductive Biases}}
}
@inproceedings{Ying2018,
author = {Ying, Z and Xiulin, G and Qi, L and Guangqi, J},
booktitle = {2018 Tenth International Conference on Advanced Computational Intelligence (ICACI)},
pages = {1--5},
title = {{Recognition of virtual maze scene under simulated prosthetic vision}},
year = {2018}
}
@article{Cordonnier2019,
abstract = {Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional layers as a primary building block. Beyond helping CNNs to handle long-range dependencies, Ramachandran et al. (2019) showed that attention can completely replace convolution and achieve state-of-the-art performance on vision tasks. This raises the question: do learned attention layers operate similarly to convolutional layers? This work provides evidence that attention layers can perform convolution and, indeed, they often learn to do so in practice. Specifically, we prove that a multi-head self-attention layer with sufficient number of heads is at least as expressive as any convolutional layer. Our numerical experiments then show that self-attention layers attend to pixel-grid patterns similarly to CNN layers, corroborating our analysis. Our code is publicly available.},
archivePrefix = {arXiv},
arxivId = {1911.03584},
author = {Cordonnier, Jean-Baptiste and Loukas, Andreas and Jaggi, Martin},
eprint = {1911.03584},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Cordonnier, Loukas, Jaggi - 2019 - On the Relationship between Self-Attention and Convolutional Layers.pdf:pdf},
title = {{On the Relationship between Self-Attention and Convolutional Layers}},
url = {http://arxiv.org/abs/1911.03584},
year = {2019}
}
@article{Hu2014,
abstract = {Due to the limitations of existing techniques, even the most advanced visual prostheses, using several hundred electrodes to transmit signals to the visual pathway, restrict sensory function and visual information. To identify the bottlenecks and guide prosthesis designing, psychophysics simulations of a visual prosthesis in normally sighted individuals are desirable. In this study, psychophysical experiments of discriminating objects with similar profiles were used to test the effects of phosphene array parameters (spatial resolution, gray scale, distortion, and dropout rate) on visual information using simulated prosthetic vision. The results showed that the increase in spatial resolution and number of gray levels and the decrease in phosphene distortion and dropout rate improved recognition performance, and the accuracy is 78.5{\%} under the optimum condition (resolution: 32×32, gray level: 8, distortion: k=0, dropout: 0{\%}). In combined parameter tests, significant facial recognition accuracy was achieved for all the images with k=0.1 distortion and 10{\%} dropout. Compared with other experiments, we find that different objects do not show specific sensitivity to the changes of parameters and visual information is not nearly enough even under the optimum condition. The results suggests that higher spatial resolution and more gray levels are required for visual prosthetic devices and further research on image processing strategies to improve prosthetic vision is necessary, especially when the wearers have to accomplish more than simple visual tasks. {\textcopyright} 2013 Wiley Periodicals, Inc. and International Center for Artificial Organs and Transplantation.},
annote = {cited By 5},
author = {Hu, Jie and Xia, Peng and Gu, Chaochen and Qi, Jin and Li, Sheng and Peng, Yinghong},
doi = {10.1111/aor.12147},
issn = {0160564X},
journal = {Artificial Organs},
keywords = {Object recognition,Psychophysics,Simulated prosthetic vision,Visual prosthesis},
number = {2},
pages = {159--167},
pmid = {24033534},
title = {{Recognition of similar objects using simulated prosthetic vision}},
volume = {38},
year = {2014}
}
@book{Macintyre2011,
author = {Macintyre, Alasdair C},
isbn = {9780268017590},
publisher = {University Of Notre Dame Press PP - Notre Dame, Ind.},
title = {{A short history of ethics : a history of moral philosophy from the Homeric Age to the twentieth century}},
year = {2011}
}
@book{Das2013,
author = {Das, K K},
isbn = {9781626363809},
publisher = {Skyhorse Publishing},
title = {{The Quantum Guide to Life: How the Laws of Physics Explain Our Lives from Laziness to Love}},
url = {https://books.google.com.au/books?id=LgMnAgAAQBAJ},
year = {2013}
}
@article{Zhang2019,
abstract = {In this letter, we deal with the reality gap from a novel perspective, targeting transferring deep reinforcement learning (DRL) policies learned in simulated environments to the real-world domain for visual control tasks. Instead of adopting the common solutions to the problem by increasing the visual fidelity of synthetic images output from simulators during the training phase, we seek to tackle the problem by translating the real-world image streams back to the synthetic domain during the deployment phase, to make the robot feel at home. We propose this as a lightweight, flexible, and efficient solution for visual control, as first, no extra transfer steps are required during the expensive training of DRL agents in simulation; second, the trained DRL agents will not be constrained to being deployable in only one specific real-world environment; and third, the policy training and the transfer operations are decoupled, and can be conducted in parallel. Besides this, we propose a simple yet effective shift loss that is agnostic to the downstream task, to constrain the consistency between subsequent frames which is important for consistent policy outputs. We validate the shift loss for artistic style transfer for videos and domain adaptation, and validate our visual control approach in indoor and outdoor robotics experiments.},
archivePrefix = {arXiv},
arxivId = {1802.00265},
author = {Zhang, Jingwei and Tai, Lei and Yun, Peng and Xiong, Yufeng and Liu, Ming and Boedecker, Joschka and Burgard, Wolfram},
doi = {10.1109/LRA.2019.2894216},
eprint = {1802.00265},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2019 - VR-Goggles for Robots Real-to-Sim Domain Adaptation for Visual Control.pdf:pdf},
issn = {23773766},
journal = {IEEE Robotics and Automation Letters},
keywords = {Deep learning in robotics and automation,model learning for control,visual-based navigation},
number = {2},
pages = {1148--1155},
publisher = {IEEE},
title = {{VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control}},
volume = {4},
year = {2019}
}
@techreport{Ramachandran2019,
abstract = {Convolutions are a fundamental building block of modern computer vision systems. Recent approaches have argued for going beyond convolutions in order to capture long-range dependencies. These efforts focus on augmenting convolutional models with content-based interactions, such as self-attention and non-local means, to achieve gains on a number of vision tasks. The natural question that arises is whether attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions. In developing and testing a pure self-attention vision model, we verify that self-attention can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of self-attention applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12{\%} fewer FLOPS and 29{\%} fewer parameters. On COCO object detection, a pure self-attention model matches the mAP of a baseline RetinaNet while having 39{\%} fewer FLOPS and 34{\%} fewer parameters. Detailed ablation studies demonstrate that self-attention is especially impactful when used in later layers. These results establish that stand-alone self-attention is an important addition to the vision practitioner's toolbox. Code for this project is made available. 1},
author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ramachandran et al. - 2019 - Stand-Alone Self-Attention in Vision Models.pdf:pdf},
pages = {68--80},
title = {{Stand-Alone Self-Attention in Vision Models}},
url = {https://github.com/google-research/google-research/tree/master/standalone{\_}self{\_}attention{\_}in{\_}vision{\_}models},
year = {2019}
}
@article{Sanchez-Garcia2020,
abstract = {Prosthetic vision is being applied to partially recover the retinal stimulation of visually impaired people. However, the phosphenic images produced by the implants have very limited information bandwidth due to the poor resolution and lack of color or contrast. The ability of object recognition and scene understanding in real environments is severely restricted for prosthetic users. Computer vision can play a key role to overcome the limitations and to optimize the visual information in the prosthetic vision, improving the amount of information that is presented. We present a new approach to build a schematic representation of indoor environments for simulated phosphene images. The proposed method combines a variety of convolutional neural networks for extracting and conveying relevant information about the scene such as structural informative edges of the environment and silhouettes of segmented objects. Experiments were conducted with normal sighted subjects with a Simulated Prosthetic Vision system. The results show good accuracy for object recognition and room identification tasks for indoor scenes using the proposed approach, compared to other image processing methods.},
author = {Sanchez-Garcia, Melani and Martinez-Cantin, Ruben and Guerrero, Jose J},
doi = {10.1371/journal.pone.0227677},
issn = {19326203},
journal = {PLoS ONE},
month = {may},
number = {1},
pmid = {31995568},
title = {{Semantic and structural image segmentation for prosthetic vision}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6988941/},
volume = {15},
year = {2020}
}
@article{WorldBankGroup2018,
abstract = {The Poverty and Shared Prosperity series provides a global audience with the latest and most accurate estimates on trends in global poverty and shared prosperity.},
author = {{World Bank Group}},
doi = {10.1596/978-1-4648-1330-6},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/World Bank Group - 2018 - Poverty and Shared Prosperity 2018 Piecing Together the Poverty Puzzle.pdf:pdf},
isbn = {9781464813306},
journal = {Piecing Together the Poverty Puzzle},
pages = {1--31},
title = {{Poverty and Shared Prosperity 2018: Piecing Together the Poverty Puzzle}},
year = {2018}
}
@misc{Tremblay2018,
abstract = {We present a system for training deep neural networks for object detection using synthetic images. To handle the variability in real-world data, the system relies upon the technique of domain randomization, in which the parameters of the simulator—such as lighting, pose, object textures, etc.—are randomized in non-realistic ways to force the neural network to learn the essential features of the object of interest. We explore the importance of these parameters, showing that it is possible to produce a network with compelling performance using only non-artistically-generated synthetic data. With additional fine-tuning on real data, the network yields better performance than using real data alone. This result opens up the possibility of using inexpensive synthetic data for training neural networks while avoiding the need to collect large amounts of hand-annotated real-world data or to generate high-fidelity synthetic worlds—both of which remain bottlenecks for many applications. The approach is evaluated on bounding box detection of cars on the KITTI dataset.},
author = {Tremblay, Jonathan and Prakash, Aayush and Acuna, David and Brophy, Mark and Jampani, Varun and Anil, Cem and To, Thang and Cameracci, Eric and Boochoon, Shaad and Birchfield, Stan},
booktitle = {arXiv},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Tremblay{\_}Training{\_}Deep{\_}Networks{\_}CVPR{\_}2018{\_}paper.pdf:pdf},
title = {{Training deep networks with synthetic data: bridging the reality gap by domain randomization}},
year = {2018}
}
@article{Pan2017,
abstract = {Recent approaches for saliency prediction are generally trained with a loss function based on a single saliency metric. This could lead to low performance when evaluating with other saliency metrics. In this paper, we propose a novel data-driven metric based saliency prediction method, named SalGAN (Saliency GAN), trained with adversarial loss function. SalGAN consists of two networks: one predicts saliency maps from raw pixels of an input image; the other one takes the output of the first one to discriminate whether a saliency map is a predicted one or ground truth. By trying to make the predicted saliency map indistinguishable with the ground truth, SalGAN is expected to generate saliency maps that resembles the ground truth. Our experiments show that the adversarial training allows our model to obtain state-of-the-art performances across various saliency metrics.},
author = {Pan, Junting and Canton-Ferrer, Cristian and McGuinness, Kevin and O'Connor, Noel E. and Torres, Jordi and Sayrol, Elisa and Giro-I-Nieto, Xavier},
file = {:Users/jaime/Documents/SwinDRLVP/papers/salgan-visual-saliency.pdf:pdf},
journal = {arXiv},
pages = {1--2},
title = {{SalGAN: Visual saliency prediction with adversarial networks}},
year = {2017}
}
@article{Lobos-Tsunekawa2018,
abstract = {In this letter, we propose a map-less visual navigation system for biped humanoid robots, which extracts information from color images to derive motion commands using deep reinforcement learning (DRL). The map-less visual navigation policy is trained using the Deep Deterministic Policy Gradients (DDPG) algorithm, which corresponds to an actor-critic DRL algorithm. The algorithm is implemented using two separate networks, one for the actor and one for the critic, but with similar structures. In addition to convolutional and fully connected layers, Long Short-Term Memory (LSTM) layers are included to address the limited observability present in the problem. As a proof of concept, we consider the case of robotic soccer using humanoid NAO V5 robots, which have reduced computational capabilities, and low-cost Red - Green - Blue (RGB) cameras as main sensors. The use of DRL allowed to obtain a complex and high performant policy from scratch, without any prior knowledge of the domain, or the dynamics involved. The visual navigation policy is trained in a robotic simulator and then successfully transferred to a physical robot, where it is able to run in 20 ms, allowing its use in real-time applications.},
author = {Lobos-Tsunekawa, Kenzo and Leiva, Francisco and Ruiz-Del-Solar, Javier},
doi = {10.1109/LRA.2018.2851148},
file = {:Users/jaime/Documents/SwinDRLVP/papers/lobos-tsunekawa2018.pdf:pdf},
issn = {23773766},
journal = {IEEE Robotics and Automation Letters},
keywords = {Visual-based navigation,deep learning in robotics and automation and human},
number = {4},
pages = {3247--3254},
publisher = {IEEE},
title = {{Visual navigation for biped humanoid robots using deep reinforcement learning}},
volume = {3},
year = {2018}
}
@article{Disu2020,
abstract = {This research is focused on the performance of a Deep Reinforcement Learning method on an agent (mobile robot) in a simulated virtual environment (Operating Room) for medical applications. The purpose of this research is to compare suitable decisive actions taken by the agent to achieve its goal target. Executing this goal requires the implementation of a reward-penalty system for observation and analysis. The agent's accumulated reward is based on the best-navigated decision to avoid collisions; solely generating an intelligent agent system. We reviewed previous works on the impact of Deep Reinforcement Learning algorithms on an agent in areas of navigation and exploration. Adopting a Deep Reinforcement Learning method and a physical simulator, we trained and tested the agent using existing environments and our modeled operating room, respectively. Measuring the positive reward output of the experiment with different parameters of the algorithm such as the learning rate, maximum Q-value and the average time to attain its goal position, we presented our work with plots of the experiment and compared it with a widely known traditional method. Our experimental results indicated that the agent achieved a high positive reward of 3800 in our operating room environment with a learning rate of 0.5. Our research aimed at training an agent to make intelligent decisions in achieving its goal destination without prior experience and input data. Reinforcement Learning provides a structure for robotics to function effectively; utilizing and engaging a robot to navigate and explore in any given environment.},
author = {Disu, Joel Dzidzorvi Kwame and Gandana, Clinton Elian and Xie, Hongzhi and Gu, Lixu},
doi = {10.1109/IAICT50021.2020.9172019},
file = {:Users/jaime/Documents/SwinDRLVP/papers/10.1109@IAICT50021.2020.9172019.pdf:pdf},
isbn = {9781728193366},
journal = {Proceedings - 2020 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology, IAICT 2020},
keywords = {Biomedical application,Deep Q-Networks,Exploration,Navigation,Operating room,Reinforcement Learning,SLAM},
pages = {35--41},
title = {{Short-range robotic navigation and exploration tasks via deep q-networks for biomedical applications}},
year = {2020}
}
@article{Tobin2017,
abstract = {Bridging the 'reality gap' that separates simulated robotics from experiments on hardware could accelerate robotic research through improved data availability. This paper explores domain randomization, a simple technique for training models on simulated images that transfer to real images by randomizing rendering in the simulator. With enough variability in the simulator, the real world may appear to the model as just another variation. We focus on the task of object localization, which is a stepping stone to general robotic manipulation skills. We find that it is possible to train a real-world object detector that is accurate to 1.5 cm and robust to distractors and partial occlusions using only data from a simulator with non-realistic random textures. To demonstrate the capabilities of our detectors, we show they can be used to perform grasping in a cluttered environment. To our knowledge, this is the first successful transfer of a deep neural network trained only on simulated RGB images (without pre-training on real images) to the real world for the purpose of robotic control.},
archivePrefix = {arXiv},
arxivId = {1703.06907},
author = {Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
doi = {10.1109/IROS.2017.8202133},
eprint = {1703.06907},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World.pdf:pdf},
isbn = {9781538626825},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {23--30},
title = {{Domain randomization for transferring deep neural networks from simulation to the real world}},
volume = {2017-Septe},
year = {2017}
}
@article{Rambach2020,
abstract = {Augmented reality (AR), virtual reality (VR) and mixed reality (MR) are technologies of great potential due to the engaging and enriching experiences they are capable of providing. Their use is rapidly increasing in diverse fields such as medicine, manufacturing or entertainment. However, the possibilities that AR, VR and MR offer in the area of environmental applications are not yet widely explored. In this paper we present the outcome of a survey meant to discover and classify existing AR/VR/MR applications that can benefit the environment or increase awareness on environmental issues. We performed an exhaustive search over several online publication access platforms and past proceedings of major conferences in the fields of AR/VR/MR. Identified relevant papers were filtered based on novelty, technical soundness, impact and topic relevance, and classified into different categories. Referring to the selected papers, we discuss how the applications of each category are contributing to environmental protection, preservation and sensitization purposes. We further analyse these approaches as well as possible future directions in the scope of existing and upcoming AR/VR/MR enabling technologies.},
archivePrefix = {arXiv},
arxivId = {2008.12024},
author = {Rambach, Jason and Lilligreen, Gergana and Sch{\"{a}}fer, Alexander and Bankanal, Ramya and Wiebel, Alexander and Stricker, Didier},
eprint = {2008.12024},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Rambach et al. - 2020 - A survey on applications of augmented, mixed and virtual reality for nature and environment.pdf:pdf},
keywords = {ar,augmented reality,ecology,environment,mixed reality,mr,nature,virtual reality,vr},
pages = {1--20},
title = {{A survey on applications of augmented, mixed and virtual reality for nature and environment}},
url = {http://arxiv.org/abs/2008.12024},
year = {2020}
}
@article{Li2019,
abstract = {Visual navigation in complex environments is inefficient with traditional reactive policy or general-purposed recurrent policy. To address the long-term memory issue, this paper proposes a graph attention memory (GAM) architecture consisting of memory construction module, graph attention module and control module. The memory construction module builds the topological graph based on supervised learning by taking the exploration prior. Then, guided attention features are extracted with the graph attention module. Finally, the deep reinforcement learning based control module makes decisions based on visual observations and guided attention features. Detailed convergence analysis of GAM is presented in this paper. We evaluate GAM-based navigation system in two complex 3D environments. Experimental results show that the GAM-based navigation system significantly improves learning efficiency and outperforms all baselines in average success rate.},
archivePrefix = {arXiv},
arxivId = {1905.13315},
author = {Li, Dong and Zhang, Qichao and Zhao, Dongbin and Zhuang, Yuzheng and Wang, Bin and Liu, Wulong and Tutunov, Rasul and Wang, Jun},
eprint = {1905.13315},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2019 - Graph Attention Memory for Visual Navigation.pdf:pdf},
title = {{Graph Attention Memory for Visual Navigation}},
url = {http://arxiv.org/abs/1905.13315},
year = {2019}
}
@article{Goodale1992,
abstract = {Accumulating neuropsychological, electrophysiological and behavioural evidence suggests that the neural substrates of visual perception may be quite distinct from those underlying the visual control of actions. In other words, the set of object descriptions that permit identification and recognition may be computed inde- pendently of the set of descriptions that allow an observer to shape the hand appropriately to pick up an object. We propose that the ventral stream of projections from the striate cortex to the inferotemporal cortex plays the major role in the perceptual identification of objects, while the dorsal stream projecting from the striate cortex to the posterior parietal region mediates the required sensorimotor transformations for visually guided actions directed at such objects},
author = {Goodale, Melvyn and Milner, David},
doi = {10.1016/0166-2236(92)90344-8},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Goodale, Milner - 1992 - Separate visual pathways for perception and action.pdf:pdf},
title = {{Separate visual pathways for perception and action}},
year = {1992}
}
@article{Mishra2018,
abstract = {Deep neural networks excel in regimes with large amounts of data, but tend to struggle when data is scarce or when they need to adapt quickly to changes in the task. In response, recent work in meta-learning proposes training a meta-learner on a distribution of similar tasks, in the hopes of generalization to novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. However, many recent meta-learning approaches are extensively hand-designed, either using architectures specialized to a particular application, or hard-coding algorithmic components that constrain how the meta-learner solves the task. We propose a class of simple and generic meta-learner architectures that use a novel combination of temporal convolutions and soft attention; the former to aggregate information from past experience and the latter to pinpoint specific pieces of information. In the most extensive set of meta-learning experiments to date, we evaluate the resulting Simple Neural AttentIve Learner (or SNAIL) on several heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement learning, SNAIL attains state-of-the-art performance by significant margins.},
archivePrefix = {arXiv},
arxivId = {arXiv:1707.03141v3},
author = {Mishra, Nikhil},
eprint = {arXiv:1707.03141v3},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mishra - 2018 - A Simple Neural Attentive Meta-Learner.pdf:pdf},
pages = {1--17},
title = {{A Simple Neural Attentive Meta-Learner}},
year = {2018}
}
@book{Sewak2019,
abstract = {We discuss deep reinforcement learning in an overview style. We draw a big picture, filled with details. We discuss six core elements, six important mechanisms, and twelve applications, focusing on contemporary work, and in historical contexts. We start with background of artificial intelligence, machine learning, deep learning, and reinforcement learning (RL), with resources. Next we discuss RL core elements, including value function, policy, reward, model, exploration vs. exploitation, and representation. Then we discuss important mechanisms for RL, including attention and memory, unsupervised learning, hierarchical RL, multi-agent RL, relational RL, and learning to learn. After that, we discuss RL applications, including games, robotics, natural language processing (NLP), computer vision, finance, business management, healthcare, education, energy, transportation, computer systems, and, science, engineering, and art. Finally we summarize briefly, discuss challenges and opportunities, and close with an epilogue.},
author = {Sewak, Mohit},
booktitle = {Deep Reinforcement Learning},
doi = {10.1007/978-981-13-8285-7},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Sewak - 2019 - Deep Reinforcement Learning.pdf:pdf},
isbn = {9789811540943},
title = {{Deep Reinforcement Learning}},
year = {2019}
}
@article{Chou2005,
abstract = {An electric scooter is one type of light motorcycle driven by an electric motor and used with small wheels, a low seat, and a fixed shield protecting the driver's legs. Since it can be considered as a constrained workstation for users of different sizes to fit on the same workstation, some ergonomic problems should be taken into consideration when designing an electric scooter. This article presents a case study for illustrating how to apply the anthropometric measurement to develop a new product. In this paper, we propose a two-dimensional anthropometric data collection approach and conduct an anthropometric experiment for scooter riders in Taiwan. Based on the obtained anthropometric data concerning scooter-riding postures, an electric scooter was developed which was the result of a collaborative project for new product development. The developed electric scooter was satisfactory, and resulted in a significant improvement in its appearance and ergonomic performance. Relevance to industry Anthropometric data should be appropriately used in ergonomic design to specify the physical dimensions of workstations, as well as should be applied to new product development. The integrated applications of aesthetic techniques and anthropometric data are critical factors for industrial designers to develop a satisfying product. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Chou, Jyh Rong and Hsiao, Shih Wen},
doi = {10.1016/j.ergon.2005.06.001},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Chou, Hsiao - 2005 - An anthropometric measurement for developing an electric scooter.pdf:pdf},
issn = {01698141},
journal = {International Journal of Industrial Ergonomics},
keywords = {Anthropometric measurement,Electric scooter,New product development,Riding posture,Scooter rider},
number = {11},
pages = {1047--1063},
title = {{An anthropometric measurement for developing an electric scooter}},
volume = {35},
year = {2005}
}
@book{Leech2012,
address = {London},
annote = {land disposession
suicide because of debt
preventable/treatable diseases
ecologically unsustainable

perpetuated by media, education and culture},
author = {Leech, Garry},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Leech - 2012 - Capitalism A Structural Genocide(2).pdf:pdf},
isbn = {9781780322025},
pages = {194},
publisher = {Zed Books},
title = {{Capitalism: A Structural Genocide}},
year = {2012}
}
@article{Barnes2016,
abstract = {Objective. One strategy to improve the effectiveness of prosthetic vision devices is to process incoming images to ensure that key information can be perceived by the user. This paper presents the first comprehensive results of vision function testing for a suprachoroidal retinal prosthetic device utilizing of 20 stimulating electrodes. Further, we investigate whether using image filtering can improve results on a light localization task for implanted participants compared to minimal vision processing. No controlled implanted participant studies have yet investigated whether vision processing methods that are not task-specific can lead to improved results. Approach. Three participants with profound vision loss from retinitis pigmentosa were implanted with a suprachoroidal retinal prosthesis. All three completed multiple trials of a light localization test, and one participant completed multiple trials of acuity tests. The visual representations used were: Lanczos2 (a high quality Nyquist bandlimited downsampling filter); minimal vision processing (MVP); wide view regional averaging filtering (WV); scrambled; and, system off. Main results. Using Lanczos2, all three participants successfully completed a light localization task and obtained a significantly higher percentage of correct responses than using MVP () or with system off (). Further, in a preliminary result using Lanczos2, one participant successfully completed grating acuity and Landolt C tasks, and showed significantly better performance () compared to WV, scrambled and system off on the grating acuity task. Significance. Participants successfully completed vision tasks using a 20 electrode suprachoroidal retinal prosthesis. Vision processing with a Nyquist bandlimited image filter has shown an advantage for a light localization task. This result suggests that this and targeted, more advanced vision processing schemes may become important components of retinal prostheses to enhance performance. ClinicalTrials.gov Identifier: NCT01503576.},
author = {Barnes, Nick and Scott, Adele F and Lieby, Paulette and Petoe, Matthew A and McCarthy, Chris and Stacey, Ashley and Ayton, Lauren N and Sinclair, Nicholas C and Shivdasani, Mohit N and Lovell, Nigel H and McDermott, Hugh J and Walker, Janine G},
doi = {10.1088/1741-2560/13/3/036013},
issn = {17412552},
journal = {Journal of Neural Engineering},
keywords = {blindness,computer vision,image filtering,retinal prosthetic,retinitis pigmentosa,vision processing for prosthetic vision},
month = {apr},
number = {3},
pages = {36013},
pmid = {27108845},
publisher = {IOP Publishing},
title = {{Vision function testing for a suprachoroidal retinal prosthesis: Effects of image filtering}},
volume = {13},
year = {2016}
}
@article{Musk2019,
abstract = {Brain-machine interfaces hold promise for the restoration of sensory and motor function and the treatment of neurological disorders, but clinical brain-machine interfaces have not yet been widely adopted, in part, because modest channel counts have limited their potential. In this white paper, we describe Neuralink's first steps toward a scalable high-bandwidth brain-machine interface system. We have built arrays of small and flexible electrode “threads,” with as many as 3072 electrodes per array distributed across 96 threads. We have also built a neurosurgical robot capable of inserting six threads (192 electrodes) per minute. Each thread can be individually inserted into the brain with micron precision for avoidance of surface vasculature and targeting specific brain regions. The electrode array is packaged into a small implantable device that contains custom chips for low-power on-board amplification and digitization: The package for 3072 channels occupies less than 23×18.5×2 mm3. A single USB-C cable provides full-bandwidth data streaming from the device, recording from all channels simultaneously. This system has achieved a spiking yield of up to 70{\%} in chronically implanted electrodes. Neuralink's approach to brain-machine interface has unprecedented packaging density and scalability in a clinically relevant package.},
author = {Musk, Elon},
doi = {10.2196/16194},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Musk - 2019 - An integrated brain-machine interface platform with thousands of channels.pdf:pdf},
issn = {14388871},
journal = {Journal of Medical Internet Research},
keywords = {Brain-machine interface,Motor function,Neurology,Sensory function},
number = {10},
pages = {1--14},
pmid = {31642810},
title = {{An integrated brain-machine interface platform with thousands of channels}},
volume = {21},
year = {2019}
}
@book{Russell2016,
author = {Russell, Stuart J and Norvig, Peter},
publisher = {Pearson},
title = {{Artificial intelligence : a modern approach}},
year = {2016}
}
@article{Arulkumaran2017,
author = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
journal = {IEEE Signal Processing Magazine},
month = {may},
pages = {26--38},
title = {{Deep Reinforcement Learning: A Brief Survey}},
volume = {34},
year = {2017}
}
@misc{Tang2019a,
author = {Tang, Yujin and Ha, David},
title = {{How to run evolution strategies on Google Kubernetes Engine}},
url = {https://cloud.google.com/blog/products/ai-machine-learning/how-to-run-evolution-strategies-on-google-kubernetes-engine},
urldate = {2020-07-02},
year = {2019}
}
@book{Hawking2009,
author = {Hawking, Stephen},
isbn = {1409092364},
publisher = {Random House},
title = {{A brief history of time: from big bang to black holes}},
year = {2009}
}
@article{Chrisley2008,
abstract = {Objective: Consciousness is often thought to be that aspect of mind that is least amenable to being understood or replicated by artificial intelligence (AI). The first-personal, subjective, what-it-is-like-to-be-something nature of consciousness is thought to be untouchable by the computations, algorithms, processing and functions of AI method. Since AI is the most promising avenue toward artificial consciousness (AC), the conclusion many draw is that AC is even more doomed than AI supposedly is. The objective of this paper is to evaluate the soundness of this inference. Methods: The results are achieved by means of conceptual analysis and argumentation. Results and conclusions: It is shown that pessimism concerning the theoretical possibility of artificial consciousness is unfounded, based as it is on misunderstandings of AI, and a lack of awareness of the possible roles AI might play in accounting for or reproducing consciousness. This is done by making some foundational distinctions relevant to AC, and using them to show that some common reasons given for AC scepticism do not touch some of the (usually neglected) possibilities for AC, such as prosthetic, discriminative, practically necessary, and lagom (necessary-but-not-sufficient) AC. Along the way three strands of the author's work in AC - interactive empiricism, synthetic phenomenology, and ontologically conservative heterophenomenology - are used to illustrate and motivate the distinctions and the defences of AC they make possible. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Chrisley, Ron},
doi = {10.1016/j.artmed.2008.07.011},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Chrisley - 2008 - Philosophical foundations of artificial consciousness.pdf:pdf},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Artificial consciousness,Heterophenomenology,Interactive empiricism,Machine consciousness,Prosthetic artificial intelligence,Synthetic phenomenology},
number = {2},
pages = {119--137},
title = {{Philosophical foundations of artificial consciousness}},
volume = {44},
year = {2008}
}
@article{Piao2019,
abstract = {In this work, we propose a novel depth-induced multi-scale recurrent attention network for saliency detection. It achieves dramatic performance especially in complex scenarios. There are three main contributions of our network that are experimentally demonstrated to have significant practical merits. First, we design an effective depth refinement block using residual connections to fully extract and fuse multi-level paired complementary cues from RGB and depth streams. Second, depth cues with abundant spatial information are innovatively combined with multi-scale context features for accurately locating salient objects. Third, we boost our model's performance by a novel recurrent attention module inspired by Internal Generative Mechanism of human brain. This module can generate more accurate saliency results via comprehensively learning the internal semantic relation of the fused feature and progressively optimizing local details with memory-oriented scene understanding. In addition, we create a large scale RGB-D dataset containing more complex scenarios, which can contribute to comprehensively evaluating saliency models. Extensive experiments on six public datasets and ours demonstrate that our method can accurately identify salient objects and achieve consistently superior performance over 16 state-of-the-art RGB and RGB-D approaches.},
author = {Piao, Yongri and Ji, Wei and Li, Jingjing and Zhang, Miao and Lu, Huchuan},
doi = {10.1109/ICCV.2019.00735},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Piao{\_}Depth-Induced{\_}Multi-Scale{\_}Recurrent{\_}Attention{\_}Network{\_}for{\_}Saliency{\_}Detection{\_}ICCV{\_}2019{\_}paper.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {7253--7262},
title = {{Depth-induced multi-scale recurrent attention network for saliency detection}},
volume = {2019-Octob},
year = {2019}
}
@article{Bouhamed2020,
abstract = {In this paper, we propose a three-dimensional autonomous UAV navigation framework using Deep Deterministic Policy Gradient (DDPG) learning approach. The objective is to employ a self-trained UAV as an airborne Internet of Things (IoT) unit to navigate obstacles and reach a destination point, where it can communicate with a ground sensor node with sufficiently high data rate. We develop a customized reward function which aims to minimize the distance separating the UAV and its destination while penalizing collisions. A dynamic energy threshold is also set to redirect the UAV towards the charging station in case of battery depletion. We numerically simulate the behavior of the UAV when learning the environmental obstacles, and autonomously selecting trajectories for selected scenarios. Finally, we show that our learning approach achieves close performance to the one of the graph-based Dijkstra's algorithm.},
author = {Bouhamed, Omar and Wan, Xiangpeng and Ghazzai, Hakim and Massoud, Yehia},
doi = {10.1109/WF-IoT48130.2020.9221115},
file = {:Users/jaime/Documents/SwinDRLVP/papers/10.1109@WF-IoT48130.2020.9221115.pdf:pdf},
isbn = {9781728155036},
journal = {IEEE World Forum on Internet of Things, WF-IoT 2020 - Symposium Proceedings},
keywords = {Autonomous navigation,deep reinforcement learning,internet of things,obstacle avoidance,unmanned aerial vehicle},
title = {{A DDPG-based Approach for Energy-aware UAV Navigation in Obstacle-constrained Environment}},
year = {2020}
}
@article{Jakobi1998,
abstract = {This paper describes experiments in which neural network control architectures were evolved in minimal simulation for an octopod robot. The robot is around 30cm long and has 4 infra red sensors that point ahead and to the side, various bumpers and whiskers, and ten ambient light sensors positioned strategically around the body. Each of the robot's eight legs is controlled by two servo motors, one for movement in the horizontal plane, and one for movement in the vertical plane, which means that the robots motors have a total of sixteen degrees of freedom. The aim of the experiments was to evolve neural network control architectures that would allow the robot to wander around its environment avoiding objects using its infra-red sensors and backing away from objects that it hits with its bumpers. This is a hard behaviour to evolve when one considers that in order to achieve any sort of coherent movement the controller has to control not just one or two motors in a coordinated fashion but sixteen. Moreover it is an extremely difficult set-up to simulate using traditional techniques since the physical outcome of sixteen motor movements is rarely predictable in all but the simplest cases. The evolution of this behaviour in a minimal simulation, with perfect transference to reality, therefore, provides essential evidence that complex motor behaviours can be evolved in simulations built according to the theory and methodology of minimal simulations.},
author = {Jakobi, Nick},
doi = {10.1007/3-540-64957-3_63},
file = {:Users/jaime/Documents/SwinDRLVP/papers/jakobi1998.pdf:pdf},
isbn = {3540649573},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {39--58},
title = {{Running across the reality gap: Octopod locomotion evolved in a minimal simulation}},
volume = {1468},
year = {1998}
}
@article{Yang2018,
abstract = {It is important to reduce loss caused by fires through improved operations performed by virtual and augmented reality (VR/AR) trained and equipped fire-fighters. This paper collaborates with firefighting professionals to training firefighting skills with VR/AR systems. The system is also integrated with computational models and decision tools to provide situational awareness and address challenges faced by firefighters on the fire ground.},
author = {Yang, Li and Liang, Yu and Wu, Dalei and Gault, Jim},
doi = {10.1109/CIC.2018.00068},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Yang et al. - 2018 - Train and equip firefighters with cognitive virtual and augmented reality.pdf:pdf},
isbn = {9781538695029},
journal = {Proceedings - 4th IEEE International Conference on Collaboration and Internet Computing, CIC 2018},
keywords = {Fire dynamic simulation,Firefighting,Virtual and augmented reality},
pages = {453--459},
publisher = {IEEE},
title = {{Train and equip firefighters with cognitive virtual and augmented reality}},
year = {2018}
}
@article{Mishkin1983,
abstract = {Evidence is reviewed indicating that striate cortex in the monkey is the source of two multisynaptic corticocortical pathways. One courses ventrally, interconnecting the striate, prestriate, and inferior temporal areas, and enables the visual identification of objects. The other runs dorsally, interconnecting the striate, prestriate, and inferior parietal areas, and allows instead the visual location of objects. How the information carried in these two separate pathways is reintegrated has become an important question for future research. {\textcopyright} 1983.},
author = {Mishkin, Mortimer and Ungerleider, Leslie G. and Macko, Kathleen A.},
doi = {10.1016/0166-2236(83)90190-X},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mishkin, Ungerleider, Macko - 1983 - Object vision and spatial vision two cortical pathways.pdf:pdf},
issn = {01662236},
journal = {Trends in Neurosciences},
number = {C},
pages = {414--417},
title = {{Object vision and spatial vision: two cortical pathways}},
volume = {6},
year = {1983}
}
@article{McCarthy2014,
author = {McCarthy, Chris and Walker, Janine G and Lieby, Paulette and Scott, Adele and Barnes, Nick},
doi = {10.1088/1741-2560/12/1/016003},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/McCarthy et al. - 2015 - Mobility and low contrast trip hazard avoidance using augmented depth.pdf:pdf},
issn = {1741-2552},
journal = {Journal of Neural Engineering},
month = {nov},
number = {1},
publisher = {IOP Publishing},
title = {{Mobility and low contrast trip hazard avoidance using augmented depth}},
url = {https://doi.org/10.1088/1741-2560/12/1/016003},
volume = {12},
year = {2014}
}
@inproceedings{Bousmalis2018,
abstract = {Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to reduce the number of real-world samples needed to achieve a given level of performance by up to 50 times, using only randomly generated simulated objects. We also show that by using only unlabeled real-world data and our GraspGAN methodology, we obtain real-world grasping performance without any real-world labels that is similar to that achieved with 939,777 labeled real-world samples.},
archivePrefix = {arXiv},
arxivId = {1709.07857},
author = {Bousmalis, Konstantinos and Irpan, Alex and Wohlhart, Paul and Bai, Yunfei and Kelcey, Matthew and Kalakrishnan, Mrinal and Downs, Laura and Ibarz, Julian and Pastor, Peter and Konolige, Kurt and Levine, Sergey and Vanhoucke, Vincent},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2018.8460875},
eprint = {1709.07857},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1709.07857.pdf:pdf},
isbn = {9781538630815},
issn = {10504729},
pages = {4243--4250},
title = {{Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping}},
year = {2018}
}
@book{Segall2020,
address = {White Plains, NY},
author = {Segall, Seth Zuihō},
doi = {10.1007/978-3-030-37027-5},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Segall - 2020 - Buddhism and Human Flourishing A Modern Western Perspective.pdf:pdf},
isbn = {9783030370268},
keywords = {aristotle,buddhism,eudaimonia,virtue},
mendeley-tags = {aristotle,buddhism,eudaimonia,virtue},
pages = {200},
publisher = {Palgrave MacMillan},
title = {{Buddhism and Human Flourishing: A Modern Western Perspective}},
year = {2020}
}
@article{Kubler2020,
abstract = {The history of brain-computer interfaces (BCI) developed from a mere idea in the days of early digital technology to today's highly sophisticated approaches for signal detection, recording, and analysis. In the 1960s, electroencephalography (EEG) was tied to the laboratory due to equipment and recording requirements. Today, amplifiers exist that are built in the electrode cap and are so resistant to movement artefacts that data collection in the field is no longer a critical issue. Within 60 years, the field has moved from simple and artefact-sensitive EEG recording to making real the vision of brain-computer communication. In the last 40 years, direct brain-computer interaction went from simple communication programs to sophisticated BCI-controlled applications. In the past two decades, much research was conducted with locked-in individuals, and since the 2010s, independent home use by exemplary patients has been demonstrated. In these patients with locked-in syndrome (LIS), BCI were installed at their home and long-term usage was established, resulting in increased quality of life (QOL). Maintaining communication in disorders leading to LIS contributes significantly to the patients' sense of being full persons. BCI as an assistive technology will likely be perceived as integral part of the self: insofar as it can prevent total loss of communication and the ensuing social isolation, it enables essential conditions for the subjective and intersubjective experience of personhood.},
author = {K{\"{u}}bler, Andrea},
doi = {10.1007/s12152-019-09409-4},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/K{\"{u}}bler - 2020 - The history of BCI From a vision for the future to real support for personhood in people with locked-in syndrome.pdf:pdf},
issn = {18745504},
journal = {Neuroethics},
keywords = {Amyotrophic lateral sclerosis (ALS), brain-compute,Communication,Quality of life (QOL),User-Centred design},
number = {2},
pages = {163--180},
publisher = {Neuroethics},
title = {{The history of BCI: From a vision for the future to real support for personhood in people with locked-in syndrome}},
volume = {13},
year = {2020}
}
@article{Henderson2018,
abstract = {In recent years, significant progress has been made in solving challenging problems across various domains using deep reinforcement learning (RL). Reproducing existing work and accurately judging the improvements offered by novel methods is vital to sustaining this progress. Unfortunately, reproducing results for state-of-the-art deep RL methods is seldom straightforward. In particular, non-determinism in standard benchmark environments, combined with variance intrinsic to the methods, can make reported results tough to interpret. Without significance metrics and tighter standardization of experimental reporting, it is difficult to determine whether improvements over the prior state-of-the-art are meaningful. In this paper, we investigate challenges posed by reproducibility, proper experimental techniques, and reporting procedures. We illustrate the variability in reported metrics and results when comparing against common baselines and suggest guidelines to make future results in deep RL more reproducible. We aim to spur discussion about how to ensure continued progress in the field by minimizing wasted effort stemming from results that are non-reproducible and easily misinterpreted.},
archivePrefix = {arXiv},
arxivId = {1709.06560},
author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
eprint = {1709.06560},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Henderson et al. - 2018 - Deep reinforcement learning that matters.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
pages = {3207--3214},
title = {{Deep reinforcement learning that matters}},
year = {2018}
}
@article{Priadythama2017,
abstract = {Bicycle development as a mode of urban transport by considering the ergonomic and health aspects have been developed since 2011 by the Department of Industrial Engineering, Sebelas Maret University. Based on the result, we get that the Short Wheel Base Recumbent Bike selected as the best concept for an urban condition. Then the prototype was made. The results of the prototype, it was discovered that the bike has a high weight because of the structure of a frame that made from steel with a large size and thick material. We still use steel as the frame material because it has a low price, highly manufacture ability, high formability more than other materials and highly recomended for the material of the bike in the urban area. Because of these problem, the research has continued to get the standard tube using simulated finite element analysis (FEA) which eventually resulted the best tube geometry for SWB Recumbent Bike is rectangular steel tube 30 × 60 mm with the material wall thickness is 1.3 mm. But the results are not optimal because the size of the dropout on the main frame is not calculated. So we need more research to find the size of the main frame by calculating the size of dropout. This study aims to determine did use the size of underneath (25 × 50 mm) and with reduce the size of dropouts remain capable and safe in use for SWB recumbent bike frame material. This research same as before, use Autodesk Inventor to Simulation Finite Element Analysis. As the result, rectangular steel tube 25 × 50 mm with the reduction of the dropout still capable and safe in use for SWB Recumbent Bicycle.},
author = {Priadythama, Ilham and Suhardi, Bambang and Adiasa, Iksan},
doi = {10.1109/ICIMECE.2016.7910461},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Priadythama, Suhardi, Adiasa - 2017 - Further study on a short wheel base recumbent bike frame using simulated finite element analysis.pdf:pdf},
isbn = {9781467385046},
journal = {2016 2nd International Conference of Industrial, Mechanical, Electrical, and Chemical Engineering, ICIMECE 2016},
keywords = {Finite Element Analysis,Recumbent Bicycle,standard tube frame},
pages = {219--224},
title = {{Further study on a short wheel base recumbent bike frame using simulated finite element analysis}},
year = {2017}
}
@article{Gare1996,
author = {Gare, Arran},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gare - 1996 - Nihilism Inc. Environmental Destruction and the Metaphysics of Sustainability.pdf:pdf},
journal = {Ecological Press},
title = {{Nihilism Inc.: Environmental Destruction and the Metaphysics of Sustainability}},
year = {1996}
}
@article{Stronks2013,
author = {Stronks, H Christiaan and Dagnelie, Gislin},
journal = {Expert Review of Medical Devices},
month = {may},
pages = {23--30},
title = {{The functional performance of the Argus II retinal prosthesis}},
volume = {11},
year = {2013}
}
@article{Luo2017,
author = {Luo, Wenjie and Li, Yujia and Urtasun, Raquel and Zemel, Richard},
journal = {arXiv:1701.04128 [cs]},
month = {may},
title = {{Understanding the Effective Receptive Field in Deep Convolutional Neural Networks}},
url = {https://arxiv.org/abs/1701.04128},
year = {2017}
}
@misc{Tang2019,
author = {Tang, Yujin and Ha, David},
title = {{How to run evolution strategies on Google Kubernetes Engine}},
url = {https://cloud.google.com/blog/products/ai-machine-learning/how-to-run-evolution-strategies-on-google-kubernetes-engine},
urldate = {2020-05-05},
year = {2019}
}
@book{matlin2008cognition,
author = {Matlin, Margaret W},
publisher = {Wiley},
title = {{Cognition}},
year = {2008}
}
@inproceedings{Sadeghi2017,
abstract = {Deep reinforcement learning has emerged as a promising and powerful technique for automatically acquiring control policies that can process raw sensory inputs, such as images, and perform complex behaviors. However, extending deep RL to real-world robotic tasks has proven challenging, particularly in safety-critical domains such as autonomous flight, where a trial-and-error learning process is often impractical. In this paper, we explore the following question: can we train visionbased navigation policies entirely in simulation, and then transfer them into the real world to achieve real-world flight without a single real training image? We propose a learning method that we call CAD2RL, which can be used to perform collision-free indoor flight in the real world while being trained entirely on 3D CAD models. Our method uses single RGB images from a monocular camera, without needing to explicitly reconstruct the 3D geometry of the environment or perform explicit motion planning. Our learned collision avoidance policy is represented by a deep convolutional neural network that directly processes raw monocular images and outputs velocity commands. This policy is trained entirely on simulated images, with a Monte Carlo policy evaluation algorithm that directly optimizes the network's ability to produce collision-free flight. By highly randomizing the rendering settings for our simulated training set, we show that we can train a policy that generalizes to the real world, without requiring the simulator to be particularly realistic or high-fidelity. We evaluate our method by flying a real quadrotor through indoor environments, and further evaluate the design choices in our simulator through a series of ablation studies on depth prediction.},
archivePrefix = {arXiv},
arxivId = {1611.04201},
author = {Sadeghi, Fereshteh and Levine, Sergey},
booktitle = {Robotics: Science and Systems},
doi = {10.15607/rss.2017.xiii.034},
eprint = {1611.04201},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1611.04201.pdf:pdf},
isbn = {9780992374730},
issn = {2330765X},
title = {{CAD2RL: Real single-image flight without a single real image}},
volume = {13},
year = {2017}
}
@article{Scheper2017,
abstract = {One of the major challenges of evolutionary robotics is to transfer robot controllers evolved in simulation to robots in the real world. In this article, we investigate abstraction of the sensory inputs and motor actions as a tool to tackle this problem. Abstraction in robots is simply the use of preprocessed sensory inputs and low-level closed-loop control systems that execute higher-level motor commands. To demonstrate the impact abstraction could have, we evolved two controllers with different levels of abstraction to solve a task of forming an asymmetric triangle with a homogeneous swarm of micro air vehicles. The results show that although both controllers can effectively complete the task in simulation, the controller with the lower level of abstraction is not effective on the real vehicle, due to the reality gap. The controller with the higher level of abstraction is, however, effective both in simulation and in reality, suggesting that abstraction can be a useful tool in making evolved behavior robust to the reality gap. Additionally, abstraction aided in reducing the computational complexity of the simulation environment, speeding up the optimization process. Preeminently, we show that the optimized behavior exploits the environment (in this case the identical behavior of the other robots) and performs input shaping to allow the vehicles to fly into and maintain the required formation, demonstrating clear sensory-motor coordination. This shows that the power of the genetic optimization to find complex correlations is not necessarily lost through abstraction as some have suggested.},
author = {Scheper, Kirk Y. W. and de Croon, Guido C. H. E.},
doi = {10.1162/ARTL_a_00227},
file = {:Users/jaime/Documents/SwinDRLVP/papers/scheper2017.pdf:pdf},
isbn = {1064-5462$\backslash$n1530-9185},
issn = {1064-5462},
journal = {Artificial Life},
month = {may},
number = {2},
pages = {124--141},
pmid = {23373976},
title = {{Abstraction, Sensory-Motor Coordination, and the Reality Gap in Evolutionary Robotics}},
url = {https://www.mitpressjournals.org/doi/abs/10.1162/ARTL{\_}a{\_}00227},
volume = {23},
year = {2017}
}
@article{Hansen2016,
abstract = {This tutorial introduces the CMA Evolution Strategy (ES), where CMA stands for Covariance Matrix Adaptation. The CMA-ES is a stochastic, or randomized, method for real-parameter (continuous domain) optimization of non-linear, non-convex functions. We try to motivate and derive the algorithm from intuitive concepts and from requirements of non-linear, non-convex search in continuous domain.},
archivePrefix = {arXiv},
arxivId = {1604.00772},
author = {Hansen, Nikolaus},
eprint = {1604.00772},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hansen - 2016 - The CMA Evolution Strategy A Tutorial.pdf:pdf},
title = {{The CMA Evolution Strategy: A Tutorial}},
url = {http://arxiv.org/abs/1604.00772},
year = {2016}
}
@article{Molchanov2018,
abstract = {Learning a policy capable of moving an agent between any two states in the environment is important for many robotics problems involving navigation and manipulation. Due to the sparsity of rewards in such tasks, applying reinforcement learning in these scenarios can be challenging. Common approaches for tackling this problem include reward engineering with auxiliary rewards, requiring domain-specific knowledge or changing the objective. In this work, we introduce a method based on region-growing that allows learning in an environment with any pair of initial and goal states. Our algorithm first learns how to move between nearby states and then increases the difficulty of the start-goal transitions as the agent's performance improves. This approach creates an efficient curriculum for learning the objective behavior of reaching any goal from any initial state. In addition, we describe a method to adaptively adjust expansion of the growing region that allows automatic adjustment of the key exploration hyperparameter to environments with different requirements. We evaluate our approach on a set of simulated navigation and manipulation tasks, where we demonstrate that our algorithm can efficiently learn a policy in the presence of sparse rewards.},
archivePrefix = {arXiv},
arxivId = {1807.01425},
author = {Molchanov, Artem and Hausman, Karol and Birchfield, Stan and Sukhatme, Gaurav},
eprint = {1807.01425},
file = {:Users/jaime/Documents/SwinDRLVP/papers/p1026.pdf:pdf},
journal = {arXiv},
keywords = {2018,Curriculum Learning,Reinforcement Learning,Transfer Learning,acm reference format,and anna helena reali,costa,curriculum learning,felipe leno da silva,object-oriented,reinforcement learning,transfer learning},
pages = {1026--1034},
title = {{Region growing curriculum generation for reinforcement learning}},
year = {2018}
}
@article{Nishida2016,
abstract = {We propose a novel strategy to adapt the population size, i.e. the number of candidate solutions per iteration, for the rank-$\mu$ update covariance matrix adaptation evolution strategy (CMA-ES). Our strategy is based on the interpretation of the rank-$\mu$ update CMA-ES as the stochastic natural gradient approach on the parameter space of the sampling distribution. We introduce a measurement of the accuracy of the current estimate of the natural gradient. We propose a novel strategy to adapt the population size according to the accuracy measure. The proposed strategy is evaluated on test functions including rugged functions and noisy functions where a larger population size is known to help to find a better solution. The experimental results show the advantage of the adaptation of the population size over a fixed population size. It is also compared with the state-of-the-art uncertainty handling strategy for the CMA-ES, namely UH-CMA-ES, on noisy test functions.},
author = {Nishida, Kouhei and Akimoto, Youhei},
doi = {10.1145/2908812.2908864},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Nishida, Akimoto - 2016 - Population size adaptation for the CMA-ES based on the estimation accuracy of the natural gradient.pdf:pdf},
isbn = {9781450342063},
journal = {GECCO 2016 - Proceedings of the 2016 Genetic and Evolutionary Computation Conference},
keywords = {Covariance matrix adaptation,Natural gradient,Noisy optimization,Population size adaptation,Ruggedness},
pages = {237--244},
title = {{Population size adaptation for the CMA-ES based on the estimation accuracy of the natural gradient}},
year = {2016}
}
@article{Kamran2020,
abstract = {Reinforcement learning is nowadays a popular framework for solving different decision making problems in automated driving. However, there are still some remaining crucial challenges that need to be addressed for providing more reliable policies. In this paper, we propose a generic risk-aware DQN approach in order to learn high level actions for driving through unsignalized occluded intersections. The proposed state representation provides lane based information which allows to be used for multi-lane scenarios. Moreover, we propose a risk based reward function which punishes risky situations instead of only collision failures. Such rewarding approach helps to incorporate risk prediction into our deep Q network and learn more reliable policies which are safer in challenging situations. The efficiency of the proposed approach is compared with a DQN learned with conventional collision based rewarding scheme and also with a rule-based intersection navigation policy. Evaluation results show that the proposed approach outperforms both of these methods. It provides safer actions than collision-aware DQN approach and is less overcautious than the rule-based policy.},
archivePrefix = {arXiv},
arxivId = {2004.04450},
author = {Kamran, Danial and Lopez, Carlos Fernandez and Lauer, Martin and Stiller, Christoph},
eprint = {2004.04450},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2004.04450.pdf:pdf},
journal = {arXiv},
title = {{Risk-Aware High-level Decisions for Automated Driving at Occluded Intersections with Reinforcement Learning}},
year = {2020}
}
@article{Peng2018,
abstract = {Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this 'reality gap'. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite being trained exclusively in simulation, our policies are able to maintain a similar level of performance when deployed on a real robot, reliably moving an object to a desired location from random initial configurations. We explore the impact of various design decisions and show that the resulting policies are robust to significant calibration error.},
archivePrefix = {arXiv},
arxivId = {1710.06537},
author = {Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
doi = {10.1109/ICRA.2018.8460528},
eprint = {1710.06537},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Sim-to-Real Transfer of Robotic Control with Dynamics Randomization.pdf:pdf},
isbn = {9781538630815},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {3803--3810},
title = {{Sim-to-Real Transfer of Robotic Control with Dynamics Randomization}},
year = {2018}
}
@book{Gunkel2012,
author = {Gunkel, David J.},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gunkel - 2012 - The Machine Question Critical Perspectives on AI, Robots, and Ethics.pdf:pdf},
title = {{The Machine Question: Critical Perspectives on AI, Robots, and Ethics}},
year = {2012}
}
@article{Savinov2018,
abstract = {Rewards are sparse in the real world and most of today's reinforcement learning algorithms struggle with such sparsity. One solution to this problem is to allow the agent to create rewards for itself - thus making rewards dense and more suitable for learning. In particular, inspired by curious behaviour in animals, observing something novel could be rewarded with a bonus. Such bonus is summed up with the real task reward - making it possible for RL algorithms to learn from the combined reward. We propose a new curiosity method which uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach the current observation from those in memory - which incorporates rich information about environment dynamics. This allows us to overcome the known “couch-potato” issues of prior work - when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences. We test our approach in visually rich 3D environments in VizDoom, DMLab and MuJoCo. In navigational tasks from VizDoom and DMLab, our agent outperforms the state-of-the-art curiosity method ICM. In MuJoCo, an ant equipped with our curiosity module learns locomotion out of the first-person-view curiosity only. The code is available at https://github.com/google-research/episodic-curiosity.},
archivePrefix = {arXiv},
arxivId = {1810.02274},
author = {Savinov, Nikolay and Raichuk, Anton and Marinier, Rapha{\"{e}}l and Vincent, Damien and Pollefeys, Marc and Lillicrap, Timothy and Gelly, Sylvain},
eprint = {1810.02274},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1810.02274.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--20},
title = {{Episodic curiosity through reachability}},
year = {2018}
}
@article{Zhu2017,
abstract = {Two less addressed issues of deep reinforcement learning are (1) lack of generalization capability to new goals, and (2) data inefficiency, i.e., the model requires several (and often costly) episodes of trial and error to converge, which makes it impractical to be applied to real-world scenarios. In this paper, we address these two issues and apply our model to target-driven visual navigation. To address the first issue, we propose an actor-critic model whose policy is a function of the goal as well as the current state, which allows better generalization. To address the second issue, we propose the AI2-THOR framework, which provides an environment with high-quality 3D scenes and a physics engine. Our framework enables agents to take actions and interact with objects. Hence, we can collect a huge number of training samples efficiently. We show that our proposed method (1) converges faster than the state-of-the-art deep reinforcement learning methods, (2) generalizes across targets and scenes, (3) generalizes to a real robot scenario with a small amount of fine-tuning (although the model is trained in simulation), (4) is end-to-end trainable and does not need feature engineering, feature matching between frames or 3D reconstruction of the environment.},
archivePrefix = {arXiv},
arxivId = {1609.05143},
author = {Zhu, Yuke and Mottaghi, Roozbeh and Kolve, Eric and Lim, Joseph J. and Gupta, Abhinav and Fei-Fei, Li and Farhadi, Ali},
doi = {10.1109/ICRA.2017.7989381},
eprint = {1609.05143},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Zhu et al. - 2017 - Target-driven visual navigation in indoor scenes using deep reinforcement learning.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {3357--3364},
title = {{Target-driven visual navigation in indoor scenes using deep reinforcement learning}},
year = {2017}
}
@article{Cohen2007,
abstract = {The design of effective visual prostheses for the blind represents a challenge for biomedical engineers and neuroscientists. Significant progress has been made in the miniaturization and processing power of prosthesis electronics; however development lags in the design and construction of effective machine-brain interfaces with visual system neurons. This review summarizes what has been learned about stimulating neurons in the human and primate retina, lateral geniculate nucleus and visual cortex. Each level of the visual system presents unique challenges for neural interface design. Blind patients with the retinal degenerative disease retinitis pigmentosa (RP) are a common population in clinical trials of visual prostheses. The visual performance abilities of normals and RP patients are compared. To generate pattern vision in blind patients, the visual prosthetic interface must effectively stimulate the retinotopically organized neurons in the central visual field to elicit patterned visual percepts. The development of more biologically compatible methods of stimulating visual system neurons is critical to the development of finer spatial percepts. Prosthesis electrode arrays need to adapt to different optimal stimulus locations, stimulus patterns, and patient disease states. {\textcopyright} 2007 IOP Publishing Ltd.},
author = {Cohen, Ethan D.},
doi = {10.1088/1741-2560/4/2/R02},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Cohen - 2007 - Prosthetic interfaces with the visual system Biological issues.pdf:pdf},
issn = {17412560},
journal = {Journal of Neural Engineering},
number = {2},
pmid = {17409473},
title = {{Prosthetic interfaces with the visual system: Biological issues}},
volume = {4},
year = {2007}
}
@article{Schulman2015,
abstract = {In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.},
archivePrefix = {arXiv},
arxivId = {1502.05477},
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael and Abbeel, Pieter},
eprint = {1502.05477},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Schulman et al. - 2015 - Trust region policy optimization.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
pages = {1889--1897},
title = {{Trust region policy optimization}},
volume = {3},
year = {2015}
}
@article{Weinert2007,
abstract = {Annual electric bike (e-bike) sales in China grew from 40,000 in 1998 to 10 million in 2005. This rapid transition from human-powered bicycles, buses and gasoline-powered scooters to an all-electric vehicle/fuel technology system is special in the evolution of transportation technology and, thus far, unique to China. We examine how and why e-bikes developed so quickly in China with particular focus on the key technical, economic, and political factors involved. This case study provides important insights to policy makers in China and abroad on how timely regulatory policy can change the purchase choice of millions and create a new mode of transportation. These lessons are especially important to China as it embarks on a large-scale transition to personal vehicles, but also to other countries seeking more sustainable forms of transportation. {\textcopyright} Springer Science+Business Media, LLC 2007.},
author = {Weinert, Jonathan and Ma, Chaktan and Cherry, Christopher},
doi = {10.1007/s11116-007-9118-8},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Weinert, Ma, Cherry - 2007 - The transition to electric bikes in China History and key reasons for rapid growth.pdf:pdf},
isbn = {1111600791188},
issn = {00494488},
journal = {Transportation},
keywords = {China,E-bike,Electric bicycle,Electric scooter,Two-wheel vehicle},
number = {3},
pages = {301--318},
title = {{The transition to electric bikes in China: History and key reasons for rapid growth}},
volume = {34},
year = {2007}
}
@article{McCarthy2012,
author = {McCarthy, Chris and Barnes, Nick},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/McCarthy, Barnes - 2012 - Time-to-contact maps for navigation with a low resolution visual prosthesis.pdf:pdf},
journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
title = {{Time-to-contact maps for navigation with a low resolution visual prosthesis}},
year = {2012}
}
@article{Li2018,
author = {Li, Heng and Su, Xiaofan and Wang, Jing and Kan, Han and Han, Tingting and Zeng, Yajie and Chai, Xinyu},
doi = {https://doi.org/10.1016/j.artmed.2017.11.001},
issn = {0933-3657},
journal = {Artificial Intelligence in Medicine},
keywords = {Image processing strategy,Objects recognition,Saliency segmentation,Simulated prosthetic vision,Visual prosthesis},
pages = {64 -- 78},
title = {{Image processing strategies based on saliency segmentation for object recognition under simulated prosthetic vision}},
url = {http://www.sciencedirect.com/science/article/pii/S0933365716304195},
volume = {84},
year = {2018}
}
@article{Hou2007,
author = {Hou, Xiaodi and Zhang, Liqing},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hou, Zhang - 2007 - Saliency Detection A Spectral Residual Approach.pdf:pdf},
isbn = {1424411807},
number = {800},
title = {{Saliency Detection: A Spectral Residual Approach}},
url = {http://arxiv.org/abs/1807.09664},
year = {2007}
}
@article{Brace2019,
abstract = {An understanding of the roles of altered states of consciousness in disrupting entrenched and dysfunctional ways of thinking may give us hope for a correction to many of humanity's seemingly intractable problems. This article considers altered states induced via substances known as psychedelics at various levels of abstraction through the lenses of history, biology and botany, neurophysiology, psychology, and philosophy. The induction of these altered states in a therapeutic setting is already showing great promise for the treatment of certain psychological dysfunctions, but could a broader understanding of their effects help us to see how they might contribute to a civilization that is more focused on the harmonious integration of humanity with the rest of the natural world? Considering their pervasiveness across human cultures, as well as their deliberate induction by other species, their contribution to the development of Western philosophy, and their impact on the cognitive styles, processes, and deeply held views of individuals who have experienced them, the author calls for greater recognition of their positive potential and encourages a cautious but vigorous approach to further interdisciplinary study.},
author = {Brace, Peter},
doi = {10.1037/teo0000123},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Brace - 2019 - Altered States of Consciousness Natural Gateway to an Ecological Civilization.pdf:pdf},
issn = {10688471},
journal = {Journal of Theoretical and Philosophical Psychology},
keywords = {Altered states of consciousness,Ecology,History,Philosophy,Psychedelics},
number = {2},
pages = {69--84},
title = {{Altered States of Consciousness: Natural Gateway to an Ecological Civilization?}},
volume = {40},
year = {2019}
}
@article{Sani2016,
abstract = {Bicycle frames have to bear variety of loads and it is needed to ensure the frame can withstand dynamic loads to move. This paper focusing on dynamic study for bicycle frame structure with a purpose to avoid the problem regarding loads on the structure and to ensure the structure is safe when multiple loads are applied on it. The main objectives of dynamic study are to find the modal properties using two method; finite element analysis (FEA) and experimental modal analysis (EMA). The correlation between two studies will be obtained using percentage error. Firstly, 3D model of mountain bike frame structure has been draw using computer-aided design (CAD) software and normal mode analysis using MSC Nastran Patran was executed for numerical method meanwhile modal testing using impact hammer was performed for experimental counterpart. From the correlation result, it show that percentage error between FEA and EMA were below 10{\%} due to noise, imperfect experiment setup during perform EMA and imperfect modeling of mountain bike frame structure in CAD software. Small percentage error differences makes both of the method can be applied to obtain the dynamic characteristic of structure. It is essential to determine whether the structure is safe or not. In conclusion, model updating method is required to reduce more percentage error between two results.},
author = {Sani, M. S.M. and Nazri, N. A. and Zahari, S. N. and Abdullah, N. A.Z. and Priyandoko, G.},
doi = {10.1088/1757-899X/160/1/012009},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Sani et al. - 2016 - Dynamic Study of Bicycle Frame Structure.pdf:pdf},
issn = {1757899X},
journal = {IOP Conference Series: Materials Science and Engineering},
number = {1},
title = {{Dynamic Study of Bicycle Frame Structure}},
volume = {160},
year = {2016}
}
@article{McLaren2009,
abstract = {Modern process philosophy began when Alfred North Whitehead realized that existence is primarily vibratory, not points but processes. vibrations are best understood as sound waves, or through using auditory metaphors rather than visual ones. our Universe is more like music than matter, but how does this help us better understand it? In this paper I use the example of the large ocean current oscillators that help drive our climate systems to reveal the more effective nature of auditory approaches. Through an auditory approach, we can better understand the ways these oscillations constrain and interact with other levels of oscillations as well as how they might be destroyed by other levels. This can then lead to us extending our ethics to the conservation of these oscillations},
author = {McLaren, G.},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/McLaren - 2009 - Climate Change and Some Other Implications of Vibratory Existence.pdf:pdf},
issn = {1832-9101},
journal = {Cosmos and History: The Journal of Natural and Social Philosophy},
number = {2},
pages = {134},
title = {{Climate Change and Some Other Implications of Vibratory Existence}},
url = {http://cosmosandhistory.org/index.php/journal/article/view/146/253},
volume = {5},
year = {2009}
}
@misc{Contributors2019,
author = {Contributors, Wikipedia},
month = {may},
publisher = {Wikimedia Foundation},
title = {{Robotics simulator}},
url = {https://en.wikipedia.org/wiki/Robotics{\_}simulator},
year = {2019}
}
@misc{McLaren2020lecture,
address = {Melbourne},
author = {McLaren, Glenn},
publisher = {Swinburne University of Technology},
title = {{Towards an Ecological Ethics}},
year = {2020}
}
@misc{Urban2015,
annote = {AI, which will likely get to AGI by being programmed to self-improve, wouldn't see “human-level intelligence” as some important milestone—it's only a relevant marker from our point of view—and wouldn't have any reason to “stop” at our level},
author = {Urban, Tim},
title = {{The AI Revolution: The Road to Superintelligence}},
url = {https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html},
urldate = {2020-05-05},
year = {2015}
}
@article{Schmidhuber1991,
author = {Schmidhuber, J{\"{u}}rgen and Huber, Rudolf},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Schmidhuber, Huber - 1991 - Learning to Generate Artificial Fovea Trajectories for Target Detection.pdf:pdf},
title = {{Learning to Generate Artificial Fovea Trajectories for Target Detection}},
year = {1991}
}
@misc{Martyushev2006,
abstract = {The tendency of the entropy to a maximum as an isolated system is relaxed to the equilibrium (the second law of thermodynamics) has been known since the mid-19th century. However, independent theoretical and applied studies, which suggested the maximization of the entropy production during nonequilibrium processes (the so-called maximum entropy production principle, MEPP), appeared in the 20th century. Publications on this topic were fragmented and different research teams, which were concerned with this principle, were unaware of studies performed by other scientists. As a result, the recognition and the use of MEPP by a wider circle of researchers were considerably delayed. The objectives of the present review consist in summation and analysis of studies dealing with MEPP. The first part of the review is concerned with the thermodynamic and statistical basis of the principle (including the relationship of MEPP with the second law of thermodynamics and Prigogine's principle). Various existing applications of the principle to analysis of nonequilibrium systems will be discussed in the second part. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
author = {Martyushev, L M and Seleznev, V D},
booktitle = {Physics Reports},
doi = {10.1016/j.physrep.2005.12.001},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Martyushev{\&}Seleznev 2006$\backslash$; MEPP in physics, chemistry and biology.pdf:pdf},
issn = {03701573},
keywords = {MEPP applications,Maximum entropy production principle (MEPP),Ziegler's and Prigogine's principles},
number = {1},
pages = {1--45},
title = {{Maximum entropy production principle in physics, chemistry and biology}},
volume = {426},
year = {2006}
}
@article{Truong2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2011.12421v1},
author = {Truong, Joanne and Chernova, Sonia and Batra, Dhruv},
eprint = {arXiv:2011.12421v1},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2011.12421.pdf:pdf},
title = {{Bi-directional Domain Adaptation for Sim2Real Transfer of Embodied Navigation Agents}},
volume = {1},
year = {2020}
}
@article{Pregenzer1999,
abstract = {A new communication channel for severely handicapped people could be opened with a direct brain to computer interface (BCI). Such a system classifies electrical brain signals online. In a series of training sessions, where electroencephalograph (EEG) signals are recorded on the intact scalp, a classifier is trained to discriminate a limited number of different brain states. In a subsequent series of feedback sessions, where the subject is confronted with the classification results, the subject tries to reduce the number of misclassifications. In this study the relevance of different spectral components is analyzed: 1) on the training sessions to select optimal frequency bands for the feedback sessions and 2) on the feedback sessions to monitor changes.},
author = {Pregenzer, M. and Pfurtscheller, G.},
doi = {10.1109/86.808944},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Pregenzer, Pfurtscheller - 1999 - Frequency component selection for an EEG-based brain to computer interface.pdf:pdf},
issn = {10636528},
journal = {IEEE Transactions on Rehabilitation Engineering},
keywords = {Brain to computer interface (BCI),Classification,Distinctive sensitive learning vector quantization,Feature selection},
number = {4},
pages = {413--419},
pmid = {10609628},
title = {{Frequency component selection for an EEG-based brain to computer interface}},
volume = {7},
year = {1999}
}
@article{DaSilva2020,
abstract = {This work presents a three-dimensional control algorithm using reinforcement learning to guide an attacking hunter drone capable of performing a global navigation satellite systems (GNSS) repeater attack on the GNSS receiver of a target invader drone. Considering the mission and movement requirements of the hunter drone, a Q-learning algorithm was developed, for which the table with the possible transitions of the states and actions is obtained by the actions that the vehicle can take considering directions and the respective consequences of each action. The learning capability of the proposed algorithm arises from the trial and error by an agent. The penalty calculation is based on the error of the invader position to the hunter's desired position of the attacked drone. The developed algorithm is tested using a software-in-the-loop (SITL) implementation, which is based on the Ardupilot platform. SITL simulations are performed in a developed testbed to emulate operational scenarios, where an unmanned aerial vehicle (UAV) is hijacked and then controlled by an attacking UAV until it reaches the final position desired by the hunter, usually a secure area where the vehicle can be captured without being destroyed. Results, including error metrics and action time, are discussed for different mission scenarios.},
author = {{Da Silva}, Douglas L. and Antreich, Felix and Coutinho, Olympio L. and MacHado, Renato},
doi = {10.1109/PLANS46316.2020.9110222},
file = {:Users/jaime/Documents/SwinDRLVP/papers/dasilva2020.pdf:pdf},
isbn = {9781728102443},
journal = {2020 IEEE/ION Position, Location and Navigation Symposium, PLANS 2020},
keywords = {Ardupilot,Control Algorithm,Q-Learning,Reinforcement Learning,Software-in-the-loop},
pages = {91--99},
title = {{Q-Learning Applied to Soft-Kill Countermeasures for Unmanned Aerial Vehicles (UAVs)}},
year = {2020}
}
@article{Svetlik2017,
abstract = {In recent years, research has shown that transfer learning methods can be leveraged to construct curricula that sequence a series of simpler tasks such that performance on a final target task is improved. A major limitation of existing approaches is that such curricula are handcrafted by humans that are typically domain experts. To address this limitation, we introduce a method to generate a curriculum based on task descriptors and a novel metric of transfer potential. Our method automatically generates a curriculum as a directed acyclic graph (as opposed to a linear sequence as done in existing work). Experiments in both discrete and continuous domains show that our method produces curricula that improve the agent's learning performance when compared to the baseline condition of learning on the target task from scratch.},
author = {Svetlik, Maxwell and Leonetti, Matteo and Sinapov, Jivko and Shah, Rishi and Walker, Nick and Stone, Peter},
file = {:Users/jaime/Documents/SwinDRLVP/papers/AAAI17-Svetlik.pdf:pdf},
journal = {31st AAAI Conference on Artificial Intelligence, AAAI 2017},
number = {1},
pages = {2590--2596},
title = {{Automatic curriculum graph generation for reinforcement learning agents}},
year = {2017}
}
@article{Zhu2020,
abstract = {This paper surveys the field of transfer learning in the problem setting of Reinforcement Learning (RL). RL has been a key solution to sequential decision-making problems. Along with the fast advances of RL in various domains, such as robotics and game-playing, transfer learning arises as an important technique to assist RL by leveraging and transferring external expertise to boost the learning process of RL. In this survey, we review the central issues of transfer learning in the RL domain, providing a systematic categorization of its state-of-the-art techniques. We analyze their goals, methodologies, applications, and the RL frameworks under which the transfer learning techniques are approachable. We discuss the relationship between transfer learning and other relevant topics from the RL perspective and also explore the potential challenges as well as future development directions for transfer learning in RL.},
archivePrefix = {arXiv},
arxivId = {2009.07888},
author = {Zhu, Zhuangdi and Lin, Kaixiang and Zhou, Jiayu},
eprint = {2009.07888},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2009.07888.pdf:pdf},
pages = {1--22},
title = {{Transfer Learning in Deep Reinforcement Learning: A Survey}},
url = {http://arxiv.org/abs/2009.07888},
year = {2020}
}
@book{Ellis1986,
author = {Ellis, Ralph},
doi = {10.1007/978-94-017-0715-2},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ellis - 1986 - An Ontology of Consciousness.pdf:pdf},
isbn = {9789048182985},
title = {{An Ontology of Consciousness}},
year = {1986}
}
@article{Hawley2019,
abstract = {Of primary importance in formulating a response to the increasing prevalence and power of artificial intelligence (AI) applications in society are questions of ontology. Questions such as: What "are" these systems? How are they to be regarded? How does an algorithm come to be regarded as an agent? We discuss three factors which hinder discussion and obscure attempts to form a clear ontology of AI: (1) the various and evolving definitions of AI, (2) the tendency for pre-existing technologies to be assimilated and regarded as "normal," and (3) the tendency of human beings to anthropomorphize. This list is not intended as exhaustive, nor is it seen to preclude entirely a clear ontology, however, these challenges are a necessary set of topics for consideration. Each of these factors is seen to present a 'moving target' for discussion, which poses a challenge for both technical specialists and non-practitioners of AI systems development (e.g., philosophers and theologians) to speak meaningfully given that the corpus of AI structures and capabilities evolves at a rapid pace. Finally, we present avenues for moving forward, including opportunities for collaborative synthesis for scholars in philosophy and science.},
archivePrefix = {arXiv},
arxivId = {1903.03171},
author = {Hawley, Scott H.},
eprint = {1903.03171},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hawley - 2019 - Challenges for an Ontology of Artificial Intelligence.pdf:pdf},
number = {Ml},
pages = {1--20},
title = {{Challenges for an Ontology of Artificial Intelligence}},
url = {http://arxiv.org/abs/1903.03171},
year = {2019}
}
@article{Khetarpal2018,
abstract = {When humans perform a task, such as playing a game, they selectively pay attention to certain parts of the visual input, gathering relevant information and sequentially combining it to build a representation from the sensory data. In this work, we explore leveraging where humans look in an image as an implicit indication of what is salient for decision making. We build on top of the UNREAL architecture in DeepMind Lab's 3D navigation maze environment. We train the agent both with original images and foveated images, which were generated by overlaying the original images with saliency maps generated using a real-time spectral residual technique. We investigate the effectiveness of this approach in transfer learning by measuring performance in the context of noise in the environment.},
archivePrefix = {arXiv},
arxivId = {1807.09664},
author = {Khetarpal, Khimya and Precup, Doina},
eprint = {1807.09664},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Khetarpal, Precup - 2018 - Attend Before you Act Leveraging human visual attention for continual learning.pdf:pdf},
title = {{Attend Before you Act: Leveraging human visual attention for continual learning}},
url = {http://arxiv.org/abs/1807.09664},
year = {2018}
}
@misc{Ha2017,
author = {Ha, David},
title = {{A Visual Guide to Evolution Strategies}},
url = {https://blog.otoro.net/2017/10/29/visual-evolution-strategies/},
urldate = {2020-09-27},
year = {2017}
}
@article{Tay2020,
abstract = {Transformer model architectures have garnered immense interest lately due to their effectiveness across a range of domains like language, vision and reinforcement learning. In the field of natural language processing for example, Transformers have become an indispensable staple in the modern deep learning stack. Recently, a dizzying number of $\backslash$emph{\{}"X-former"{\}} models have been proposed - Reformer, Linformer, Performer, Longformer, to name a few - which improve upon the original Transformer architecture, many of which make improvements around computational and memory $\backslash$emph{\{}efficiency{\}}. With the aim of helping the avid researcher navigate this flurry, this paper characterizes a large and thoughtful selection of recent efficiency-flavored "X-former" models, providing an organized and comprehensive overview of existing work and models across multiple domains.},
archivePrefix = {arXiv},
arxivId = {2009.06732},
author = {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
eprint = {2009.06732},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Tay et al. - 2020 - Efficient Transformers A Survey.pdf:pdf},
keywords = {atten-,deep learning,natural language processing,transformer models},
number = {August 2020},
pages = {1--28},
title = {{Efficient Transformers: A Survey}},
url = {http://arxiv.org/abs/2009.06732},
year = {2020}
}
@article{Ostry2016,
abstract = {Instead of delivering growth, some neoliberal policies have increased inequality, in turn jeopardizing durable expansion},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ostry, Jonathan D and Loungani, Prakash and Furceri, Davide},
eprint = {arXiv:1011.1669v3},
file = {:Users/jaime/Downloads/ostry.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Imf Finance {\&} Development},
number = {2},
pages = {38--41},
pmid = {25246403},
title = {{Neoliberalism: Oversold? - IMF}},
volume = {53},
year = {2016}
}
@book{Sutton2018,
author = {Sutton, Richard S and Barto, Andrew},
publisher = {The Mit Press},
title = {{Reinforcement learning : an introduction}},
year = {2018}
}
@article{Ivanov2019,
author = {Ivanov, Sergey and D'yakonov, Alexander},
journal = {arXiv:1906.10025 [cs, stat]},
month = {may},
title = {{Modern Deep Reinforcement Learning Algorithms}},
url = {https://arxiv.org/abs/1906.10025},
year = {2019}
}
@misc{McLaren2020,
address = {Melbourne},
author = {McLaren, Glenn},
publisher = {Swinburne University of Technology},
title = {{PHI30008 – Ethics: Lecture slides}},
year = {2020}
}
@article{Kim2017,
abstract = {Most of the retinal prostheses use a head-fixed camera and a video processing unit. Some studies proposed various image processing methods to improve visual perception for patients. However, previous studies only focused on using spatial information. The present study proposes a spatiotemporal pixelization method mimicking fixational eye movements to generate stimulation images for artificial retina arrays by combining spatial and temporal information. Input images were sampled with a resolution that was four times higher than the number of pixel arrays. We subsampled this image and generated four different phosphene images. We then evaluated the recognition scores of characters by sequentially presenting phosphene images with varying pixel array sizes (6 × 6, 8 × 8 and 10 × 10) and stimulus frame rates (10 Hz, 15 Hz, 20 Hz, 30 Hz, and 60 Hz). The proposed method showed the highest recognition score at a stimulus frame rate of approximately 20 Hz. The method also significantly improved the recognition score for complex characters. This method provides a new way to increase practical resolution over restricted spatial resolution by merging the higher resolution image into high-frame time slots.},
author = {Kim, Hyun Seok and Park, Kwang Suk},
doi = {10.3390/s17102439},
issn = {14248220},
journal = {Sensors (Basel, Switzerland)},
keywords = {character recognition,retinal prosthesis,spatiotemporal,stimulus frame rates,subsampling},
number = {10},
pages = {2439},
pmid = {29073735},
title = {{Spatiotemporal Pixelization to Increase the Recognition Score of Characters for Retinal Prostheses}},
volume = {17},
year = {2017}
}
@article{Cornia2018,
abstract = {Data-driven saliency has recently gained a lot of attention thanks to the use of convolutional neural networks for predicting gaze fixations. In this paper, we go beyond standard approaches to saliency prediction, in which gaze maps are computed with a feed-forward network, and present a novel model which can predict accurate saliency maps by incorporating neural attentive mechanisms. The core of our solution is a convolutional long short-term memory that focuses on the most salient regions of the input image to iteratively refine the predicted saliency map. In addition, to tackle the center bias typical of human eye fixations, our model can learn a set of prior maps generated with Gaussian functions. We show, through an extensive evaluation, that the proposed architecture outperforms the current state-of-the-art on public saliency prediction datasets. We further study the contribution of each key component to demonstrate their robustness on different scenarios.},
archivePrefix = {arXiv},
arxivId = {1611.09571},
author = {Cornia, Marcella and Baraldi, Lorenzo and Serra, Giuseppe and Cucchiara, Rita},
doi = {10.1109/TIP.2018.2851672},
eprint = {1611.09571},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Cornia et al. - 2018 - Predicting human eye fixations via an LSTM-Based saliency attentive model.pdf:pdf},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Saliency,convolutional neural networks,deep learning,human eye fixations},
number = {10},
pages = {5142--5154},
title = {{Predicting human eye fixations via an LSTM-Based saliency attentive model}},
volume = {27},
year = {2018}
}
@article{Salimans2017,
annote = {ES is much more scalable than other RL methods. As a result, agents can be trained in a fraction of the time, depending on available CPUs. (e.g. 1400 cores trained humanoid walker in 10 min cf. 32 cores in 10 hours).

No need for backpropagation means we can use components that are not differentiable.

ES have no issues with changes to the frame skip hyperparameter. (cf. RL policies e.g. Atari that can fail with the wrong frame skip).

ES results in being able to use deterministic policies, avoiding jitter in action space.

Long-time scale results of actions are reflected in ES better than in other RL methods.

" in our preliminary experiments we found that using ES to estimate the gradient on the MNIST digit recognition task can be as much as 1,000 times slower than using backpropagation."},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.03864v2},
author = {Karpathy, Andrej and Salimans, Tim and Ho, Jonathan and Chen, Peter and Sutskever, Ilya and Schulman, John and Brockman, Greg and Sidor, Szymon},
eprint = {arXiv:1703.03864v2},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Karpathy et al. - 2017 - Evolution Strategies as a Scalable Alternative to Reinforcement Learning.pdf:pdf},
title = {{Evolution Strategies as a Scalable Alternative to Reinforcement Learning}},
url = {https://openai.com/blog/evolution-strategies/},
year = {2017}
}
@article{Irons2017,
author = {Irons, Jessica L and Gradden, Tamara and Zhang, Angel and He, Xuming and Barnes, Nick and Scott, Adele F and McKone, Elinor},
doi = {https://doi.org/10.1016/j.visres.2017.06.002},
issn = {0042-6989},
journal = {Vision Research},
keywords = {Caricaturing,Face recognition,Prosthetic vision,Retinal prosthesis},
pages = {61 -- 79},
title = {{Face identity recognition in simulated prosthetic vision is poorer than previously reported and can be improved by caricaturing}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698917301116},
volume = {137},
year = {2017}
}
@misc{Chomsky1971,
author = {Chomsky, Noam and Foucault, Michel},
title = {{Human Nature: Justice versus Power, Noam Chomsky debates with Michel Foucault}},
url = {https://chomsky.info/1971xxxx/},
urldate = {2020-05-04},
year = {1971}
}
@article{Mnih2014,
abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.},
archivePrefix = {arXiv},
arxivId = {1406.6247},
author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
eprint = {1406.6247},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mnih et al. - 2014 - Recurrent models of visual attention.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {January},
pages = {2204--2212},
title = {{Recurrent models of visual attention}},
volume = {3},
year = {2014}
}
@article{Wehrl1978,
abstract = {It is rather paradoxical that, although entropy is one of the most important quantities in physics, its main properties are rarely listed in the usual textbooks on statistical mechanics. In this paper we try to fill this gap by discussing these properties, as, for instance, invariance, additivity, concavity, subadditivity, strong subadditivity, continuity, etc., in detail, with reference to their implications in statistical mechanics. In addition, we consider related concepts such as relative entropy, skew entropy, dynamical entropy, etc. Taking into account that statistical mechanics deals with large, essentially infinite systems, we finally will get a glimpse of systems with infinitely many degrees of freedom. {\textcopyright} 1978 American Physical Society.},
author = {Wehrl, Alfred},
doi = {10.1103/RevModPhys.50.221},
file = {:Users/jaime/Downloads/wehrl1978.pdf:pdf},
issn = {00346861},
journal = {Reviews of Modern Physics},
number = {2},
pages = {221--260},
title = {{General properties of entropy}},
volume = {50},
year = {1978}
}
@book{Bostrom2014,
address = {London},
author = {Bostrom, Nick},
isbn = {978-0199678112},
publisher = {Oxford University Press},
title = {{Superintelligence: Paths, Dangers, Strategies}},
year = {2014}
}
@article{Chai2019,
abstract = {Recent advances in single-frame object detection and segmentation techniques have motivated a wide range of works to extend these methods to process video streams. In this paper, we explore the idea of hard attention aimed for latency-sensitive applications. Instead of reasoning about every frame separately, our method selects and only processes a small sub-window of the frame. Our technique then makes predictions for the full frame based on the sub-windows from previous frames and the update from the current sub-window. The latency reduction by this hard attention mechanism comes at the cost of degraded accuracy. We made two contributions to address this. First, we propose a specialized memory cell that recovers lost context when processing sub-windows. Secondly, we adopt a Q-learning-based policy training strategy that enables our approach to intelligently select the sub-windows such that the staleness in the memory hurts the performance the least. Our experiments suggest that our approach reduces the latency by approximately four times without significantly sacrificing the accuracy on the ImageNet VID video object detection dataset and the DAVIS video object segmentation dataset. We further demonstrate that we can reinvest the saved computation into other parts of the network, and thus resulting in an accuracy increase at a comparable computational cost as the original system and beating other recently proposed state-of-the-art methods in the low latency range.},
archivePrefix = {arXiv},
arxivId = {1904.01784},
author = {Chai, Yuning},
eprint = {1904.01784},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Chai - 2019 - Patchwork A Patch-wise Attention Network for Efficient Object Detection and Segmentation in Video Streams.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
month = {apr},
pages = {3414--3423},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Patchwork: A Patch-wise Attention Network for Efficient Object Detection and Segmentation in Video Streams}},
url = {http://arxiv.org/abs/1904.01784},
volume = {2019-Octob},
year = {2019}
}
@misc{Juliani2018,
author = {Juliani, Arthur},
title = {{Maximum Entropy Policies in Reinforcement Learning {\&} Everyday Life}},
url = {https://awjuliani.medium.com/maximum-entropy-policies-in-reinforcement-learning-everyday-life-f5a1cc18d32d{\#}:{~}:text=lives as well.-,In maximum entropy RL{\%}2C the basic principle is that optimal,the behavior of artificial agents.},
year = {2018}
}
@article{Brunner2018,
abstract = {The ability to use a 2D map to navigate a complex 3D environment is quite remarkable, and even difficult for many humans. Localization and navigation is also an important problem in domains such as robotics, and has recently become a focus of the deep reinforcement learning community. In this paper we teach a reinforcement learning agent to read a map in order to find the shortest way out of a random maze it has never seen before. Our system combines several state-of-the-art methods such as A3C and incorporates novel elements such as a recurrent localization cell. Our agent learns to localize itself based on 3D first person images and an approximate orientation angle. The agent generalizes well to bigger mazes, showing that it learned useful localization and navigation capabilities.},
archivePrefix = {arXiv},
arxivId = {1711.07479},
author = {Brunner, Gino and Richter, Oliver and Wang, Yuyi and Wattenhofer, Roger},
eprint = {1711.07479},
file = {:Users/jaime/Documents/SwinDRLVP/papers/mapreader{\_}CR.pdf:pdf},
isbn = {9781577358008},
journal = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
number = {Minsky},
pages = {2763--2770},
title = {{Teaching a machine to read maps with deep reinforcement learning}},
year = {2018}
}
@misc{Schulman2017,
author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
title = {{Proximal Policy Optimization Algorithms}},
url = {https://arxiv.org/abs/1707.06347},
year = {2017}
}
@article{Chaplot2016,
abstract = {The ability to transfer knowledge from previous experiences is critical for an agent to rapidly adapt to different environments and effectively learn new tasks. In this paper we conduct an empirical study of Deep Q-Networks (DQNs) where the agent is evaluated on previously unseen environments. We show that we can train a robust network for navigation in 3D environments and demonstrate its effectiveness in generalizing to unknown maps with unknown background textures. We further investigate the effectiveness of pretraining and finetuning for transferring knowledge between various scenarios in 3D environments. In particular, we show that the features learnt by the navigation network can be effectively utilized to transfer knowledge between a diverse set of tasks, such as object collection, deathmatch, and self-localization.},
author = {Chaplot, D. S. and Lample, G. and Sathyendra, K. M. and Salakhutdinov, R.},
file = {:Users/jaime/Documents/SwinDRLVP/papers/DeepRL{\_}Transfer.pdf:pdf},
number = {Nips},
title = {{Transfer Deep Reinforcement Learning in 3D Environments: An Empirical Study}},
year = {2016}
}
@misc{Lotte2018,
abstract = {Objective. Most current electroencephalography (EEG)-based brain-computer interfaces (BCIs) are based on machine learning algorithms. There is a large diversity of classifier types that are used in this field, as described in our 2007 review paper. Now, approximately ten years after this review publication, many new algorithms have been developed and tested to classify EEG signals in BCIs. The time is therefore ripe for an updated review of EEG classification algorithms for BCIs. Approach. We surveyed the BCI and machine learning literature from 2007 to 2017 to identify the new classification approaches that have been investigated to design BCIs. We synthesize these studies in order to present such algorithms, to report how they were used for BCIs, what were the outcomes, and to identify their pros and cons. Main results. We found that the recently designed classification algorithms for EEG-based BCIs can be divided into four main categories: adaptive classifiers, matrix and tensor classifiers, transfer learning and deep learning, plus a few other miscellaneous classifiers. Among these, adaptive classifiers were demonstrated to be generally superior to static ones, even with unsupervised adaptation. Transfer learning can also prove useful although the benefits of transfer learning remain unpredictable. Riemannian geometry-based methods have reached state-of-the-art performances on multiple BCI problems and deserve to be explored more thoroughly, along with tensor-based methods. Shrinkage linear discriminant analysis and random forests also appear particularly useful for small training samples settings. On the other hand, deep learning methods have not yet shown convincing improvement over state-of-the-art BCI methods. Significance. This paper provides a comprehensive overview of the modern classification algorithms used in EEG-based BCIs, presents the principles of these methods and guidelines on when and how to use them. It also identifies a number of challenges to further advance EEG classification in BCI.},
author = {Lotte, F and Bougrain, L and Cichocki, A and Clerc, M and Congedo, M and Rakotomamonjy, A and Yger, F},
booktitle = {Journal of Neural Engineering},
doi = {10.1088/1741-2552/aab2f2},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Lotte et al. - 2018 - A review of classification algorithms for EEG-based brain-computer interfaces A 10 year update.pdf:pdf},
issn = {17412552},
keywords = {Riemannian geometry,brain-computer interfaces,classification,deep learning,electroencephalography,spatial filtering,transfer learning},
number = {3},
pmid = {29488902},
publisher = {IOP Publishing},
title = {{A review of classification algorithms for EEG-based brain-computer interfaces: A 10 year update}},
volume = {15},
year = {2018}
}
@article{Narvekar2019,
abstract = {Curriculum learning in reinforcement learning is a training methodology that seeks to speed up learning of a difficult target task, by first training on a series of simpler tasks and transferring the knowledge acquired to the target task. Automatically choosing a sequence of such tasks (i.e., a curriculum) is an open problem that has been the subject of much recent work in this area. In this paper, we build upon a recent method for curriculum design, which formulates the curriculum sequencing problem as a Markov Decision Process. We extend this model to handle multiple transfer learning algorithms, and show for the first time that a curriculum policy over this MDP can be learned from experience. We explore various representations that make this possible, and evaluate our approach by learning curriculum policies for multiple agents in two different domains. The results show that our method produces curricula that can train agents to perform on a target task as fast or faster than existing methods.},
archivePrefix = {arXiv},
arxivId = {1812.00285},
author = {Narvekar, Sanmit and Stone, Peter},
eprint = {1812.00285},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1812.00285.pdf:pdf},
isbn = {9781510892002},
issn = {15582914},
journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
keywords = {Curriculum learning,Reinforcement learning,Transfer learning},
pages = {25--33},
title = {{Learning curriculum policies for reinforcement learning}},
volume = {1},
year = {2019}
}
@article{Keeley1998,
abstract = {Artificial life (ALife) is the attempt to create artificial instances of life in a variety of media, but primarily within the digital computer. As such, the field brings together computationally-minded biologists and biologically-minded computer scientists. I argue that this new field is filled with interesting philosophical issues. However, there is a dearth of philosophers actively conducting research in this area. I discuss two books on the new field: Margaret A. Boden's The philosophy of artificial life and Christopher G. Langton's Artificial life: an overview. They cover three areas of philosophical interest: the definition of life, the relationship between life and mind, and the possibility of creating life within a computational environment. This discussion allows me to critique past work in the philosophy of ALife that tends to see the field as a proving ground for traditional arguments from the philosophy of artificial intelligence. Instead, I suggest, what is interesting about ALife is how it differs from artificial intelligence and that the most interesting philosophical issues in the area are those derived from biology, not psychology. I recommend that these two books taken together constitute an interesting introduction to ALife and the wealth of philosophical issues found therein.},
author = {Keeley, Brian L.},
doi = {10.1080/09515089808573260},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Keeley - 1998 - Artificial life for philosophers.pdf:pdf},
issn = {09515089},
journal = {Philosophical Psychology},
number = {2},
pages = {251--260},
title = {{Artificial life for philosophers}},
volume = {11},
year = {1998}
}
@article{Henderson2018a,
abstract = {We compared the influence of meaning and of salience on attentional guidance in scene images. Meaning was captured by ''meaning maps'' representing the spatial distribution of semantic information in scenes. Meaning maps were coded in a format that could be directly compared to maps of image salience generated from image features. We investigated the degree to which meaning versus image salience predicted human viewers' spatiotemporal distribution of attention over scenes. Extending previous work, here the distribution of attention was operationalized as duration-weighted fixation density. The results showed that both meaning and image salience predicted the duration-weighted distribution of attention, but that when the correlation between meaning and salience was statistically controlled, meaning accounted for unique variance in attention whereas salience did not. This pattern was observed in early as well as late fixations, fixations including and excluding the centers of the scenes, and fixations following short as well as long saccades. The results strongly suggest that meaning guides attention in real-world scenes. We discuss the results from the perspective of a cognitive-relevance theory of attentional guidance.},
author = {Henderson, John M. and Hayes, Taylor R.},
doi = {10.1167/18.6.10},
file = {:Users/jaime/Downloads/i1534-7362-18-6-10.pdf:pdf},
issn = {15347362},
journal = {Journal of Vision},
keywords = {Attention,Eye movements,Scene perception},
number = {6},
pages = {1--18},
pmid = {30029216},
title = {{Meaning guides attention in real-world scene images: Evidence from eye movements and meaning maps}},
volume = {18},
year = {2018}
}
@article{Beattie2016,
abstract = {DeepMind Lab is a first-person 3D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.},
annote = {Intelligence requries complexity. Real world is complex but too slow to learn in. Rich virtual environments enable the learning process.

DeepMind Lab is a 3D first-person platform for AI research featuring rich sci-fi style visuals. Several task types are available for training agents and performing experiments. For pixel-to-action learning agents.

Comparable to VizDoom and Minecraft, but with richer visuals and more naturalistic physics.

RL API provides complex observations and accepts a rich set of actions. Simulation is lock-stepped.},
archivePrefix = {arXiv},
arxivId = {1612.03801},
author = {Beattie, Charles and Leibo, Joel Z. and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and K{\"{u}}ttler, Heinrich and Lefrancq, Andrew and Green, Simon and Vald{\'{e}}s, V{\'{i}}ctor and Sadik, Amir and Schrittwieser, Julian and Anderson, Keith and York, Sarah and Cant, Max and Cain, Adam and Bolton, Adrian and Gaffney, Stephen and King, Helen and Hassabis, Demis and Legg, Shane and Petersen, Stig},
eprint = {1612.03801},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Beattie et al. - 2016 - DeepMind Lab.pdf:pdf},
pages = {1--11},
title = {{DeepMind Lab}},
url = {http://arxiv.org/abs/1612.03801},
year = {2016}
}
@article{Lehman2011,
abstract = {In evolutionary computation, the fitness function normally measures progress toward an objective in the search space, effectively acting as an objective function. Through deception, such objective functions may actually prevent the objective from being reached. While methods exist to mitigate deception, they leave the underlying pathology untreated: Objective functions themselves may actively misdirect search toward dead ends. This paper proposes an approach to circumventing deception that also yields a new perspective on open-ended evolution. Instead of either explicitly seeking an objective or modeling natural evolution to capture open-endedness, the idea is to simply search for behavioral novelty. Even in an objective-based problem, such novelty search ignores the objective. Because many points in the search space collapse to a single behavior, the search for novelty is often feasible. Furthermore, because there are only so many simple behaviors, the search for novelty leads to increasing complexity. By decoupling open-ended search from artificial life worlds, the search for novelty is applicable to real world problems. Counterintuitively, in the maze navigation and biped walking tasks in this paper, novelty search significantly outperforms objectivebased search, suggesting the strange conclusion that some problems are best solved by methods that ignore the objective. The main lesson is the inherent limitation of the objective-based paradigm and the unexploited opportunity to guide search through other means. {\textcopyright} 2011 by the Massachusetts Institute of Technology.},
author = {Lehman, Joel and Stanley, Kenneth O.},
doi = {10.1162/EVCO_a_00025},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Lehman, Stanley - 2011 - Abandoning objectives Evolution through the search for novelty alone.pdf:pdf},
issn = {10636560},
journal = {Evolutionary Computation},
keywords = {Deception,Evolutionary algorithms,Neuroevolution,Novelty search,Open-ended evolution},
number = {2},
pages = {189--222},
pmid = {20868264},
title = {{Abandoning objectives: Evolution through the search for novelty alone}},
volume = {19},
year = {2011}
}
@article{Ponce2020,
abstract = {This paper presents a distributed evolutionary learning control based on social wound treatment for mobile robot navigation using an integrated multi-robot system comprised of simulated and physical robots. To do so, this work proposes an extension of the population-based metaheuristic wound treatment optimization (WTO) method into a distributed scheme. In addition, this distributed WTO method is implemented on the multi-robot system allowing them to experience the environment in their own and communicate their findings, resulting in an emergence intelligence. We implemented our proposal using the combination of five simulated robots with one physical robot for tuning a navigation controller to move freely in a workspace. Results showed that the solution found by this multi-robot system aims using the output controller in the physical robot for successfully achieving the goal to move the robot around a U-maze, without applying any transfer learning approach. We consider this proposal useful in evolutionary robotics, and of great importance to decrease the gap related to transfer knowledge in robotics from simulation to reality.},
author = {Ponce, Hiram and Moya-Albor, Ernesto and Mart{\'{i}}nez-Villase{\~{n}}or, Lourdes and Brieva, Jorge},
doi = {10.1016/j.simpat.2019.102058},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ponce et al. - 2020 - Distributed evolutionary learning control for mobile robot navigation based on virtual and physical agents.pdf:pdf},
issn = {1569190X},
journal = {Simulation Modelling Practice and Theory},
keywords = {Control navigation,Decentralized systems,Evolutionary robotics,Metaheuristic optimization,Multi-robot system},
number = {September},
pages = {102058},
publisher = {Elsevier},
title = {{Distributed evolutionary learning control for mobile robot navigation based on virtual and physical agents}},
url = {https://doi.org/10.1016/j.simpat.2019.102058},
volume = {102},
year = {2020}
}
@article{Manchin,
abstract = {Attention models have had a significant positive impact on deep learning across a range of tasks. However previous attempts at integrating attention with reinforcement learning have failed to produce significant improvements. We propose the first combination of self attention and reinforcement learning that is capable of producing significant improvements, including new state of the art results in the Arcade Learning Environment. Unlike the selective attention models used in previous attempts, which constrain the attention via preconceived notions of importance, our implementation utilises the Markovian properties inherent in the state input. Our method produces a faithful visualisation of the policy, focusing on the behaviour of the agent. Our experiments demonstrate that the trained policies use multiple simultaneous foci of attention, and are able to modulate attention over time to deal with situations of partial observability.},
archivePrefix = {arXiv},
arxivId = {1904.03367v1},
author = {Manchin, Anthony and {Van Den Hengel}, Anton and Abbasnejad, Ehsan},
doi = {10.13140/RG.2.2.36603.77608},
eprint = {1904.03367v1},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Manchin, Van Den Hengel, Abbasnejad - Unknown - Reinforcement Learning with Attention that Works A Self-Supervised Approach Image-based.pdf:pdf},
keywords = {Attention {\textperiodcentered},Deep,Learning {\textperiodcentered},Reinforcement,Vi-sualisation},
title = {{Reinforcement Learning with Attention that Works: A Self-Supervised Approach Image-based semantic modelling View project Feasibility Study: Development and demonstration of virtual reality simulation training for the BHPB Olympic Dam Site Inductions. View}},
url = {https://www.researchgate.net/publication/332292503}
}
@article{Stingl2013,
author = {Stingl, Katarina and Bartz-Schmidt, Karl Ulrich and Besch, Dorothea and Braun, Angelika and Bruckmann, Anna and Gekeler, Florian and Greppmaier, Udo and Hipp, Stephanie and H{\"{o}}rtd{\"{o}}rfer, Gernot and Kernstock, Christoph and Koitschev, Assen and Kusnyerik, Akos and Sachs, Helmut and Schatz, Andreas and Stingl, Krunoslav T and Peters, Tobias and Wilhelm, Barbara and Zrenner, Eberhart},
journal = {Proceedings of the Royal Society B: Biological Sciences},
month = {may},
pages = {20130077},
title = {{Artificial vision with wirelessly powered subretinal electronic implant alpha-IMS}},
volume = {280},
year = {2013}
}
@article{Kulhanek2019,
abstract = {Deep reinforcement learning (RL) has been successfully applied to a variety of game-like environments. However, the application of deep RL to visual navigation with realistic environments is a challenging task. We propose a novel learning architecture capable of navigating an agent, e.g. a mobile robot, to a target given by an image. To achieve this, we have extended the batched A2C algorithm with auxiliary tasks designed to improve visual navigation performance. We propose three additional auxiliary tasks: predicting the segmentation of the observation image and of the target image and predicting the depth-map. These tasks enable the use of supervised learning to pre-train a major part of the network and to reduce the number of training steps substantially. The training performance has been further improved by increasing the environment complexity gradually over time. An efficient neural network structure is proposed, which is capable of learning for multiple targets in multiple environments. Our method navigates in continuous state spaces and on the AI2-THOR environment simulator surpasses the performance of state-of-the-art goal-oriented visual navigation methods from the literature.},
archivePrefix = {arXiv},
arxivId = {1908.03627},
author = {Kulhanek, Jonas and Derner, Erik and {De Bruin}, Tim and Babuska, Robert},
doi = {10.1109/ECMR.2019.8870964},
eprint = {1908.03627},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Kulhanek et al. - 2019 - Vision-based navigation using deep reinforcement learning.pdf:pdf},
isbn = {9781728136059},
journal = {2019 European Conference on Mobile Robots, ECMR 2019 - Proceedings},
keywords = {Actor-critic,Auxiliary tasks,Deep reinforcement learning,Robot navigation},
pages = {1--8},
publisher = {IEEE},
title = {{Vision-based navigation using deep reinforcement learning}},
year = {2019}
}
@article{Khateeb2005,
abstract = {This work reports the laboratory test results of a Li-ion battery designed for electric scooter applications. Four different modes of heat dissipation were investigated in this experimental study: (1) natural convection cooling; (2) presence of aluminum foam heat transfer matrix; (3) use of phase change material (PCM); and (4) combination of aluminum foam and PCM. The objective of using the PCM is to lower the temperature rise of the Li-ion cells and create a uniform temperature distribution in the battery module. This is clearly justified looking at the experimental results presented in this work. The use of high thermal conductivity aluminum foam in the voids between the cells reduces the temperature rise of the Li-ion cells but is insufficient when operated in high ambient temperature such as those usually occur in summer. The use of aluminum foam with PCM causes a significant temperature drop of about 50{\%} compared to the first case of no thermal management. It also provides uniform temperature distribution within the battery module, which is important for the efficient performance of the cells used. The laboratory results were modeled using a 2-D thermal model accounting for the four different modes of heat dissipation and good agreement was obtained between the simulation and experimental results. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
author = {Khateeb, Siddique A. and Amiruddin, Shabab and Farid, Mohammed and Selman, J. Robert and Al-Hallaj, Said},
doi = {10.1016/j.jpowsour.2004.09.033},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Khateeb et al. - 2005 - Thermal management of Li-ion battery with phase change material for electric scooters Experimental validation.pdf:pdf},
issn = {03787753},
journal = {Journal of Power Sources},
keywords = {Air-cooling,Electric scooter,Lithium-ion battery,Phase change materials,Thermal management,Thermal modeling/simulation},
number = {1-2},
pages = {345--353},
title = {{Thermal management of Li-ion battery with phase change material for electric scooters: Experimental validation}},
volume = {142},
year = {2005}
}
@article{Ramachandran2019a,
abstract = {Convolutions are a fundamental building block of modern computer vision systems. Recent approaches have argued for going beyond convolutions in order to capture long-range dependencies. These efforts focus on augmenting convolutional models with content-based interactions, such as self-attention and non-local means, to achieve gains on a number of vision tasks. The natural question that arises is whether attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions. In developing and testing a pure self-attention vision model, we verify that self-attention can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of self-attention applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12{\%} fewer FLOPS and 29{\%} fewer parameters. On COCO object detection, a pure self-attention model matches the mAP of a baseline RetinaNet while having 39{\%} fewer FLOPS and 34{\%} fewer parameters. Detailed ablation studies demonstrate that self-attention is especially impactful when used in later layers. These results establish that stand-alone self-attention is an important addition to the vision practitioner's toolbox.},
archivePrefix = {arXiv},
arxivId = {1906.05909},
author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jonathon},
eprint = {1906.05909},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ramachandran et al. - 2019 - Stand-Alone Self-Attention in Vision Models(2).pdf:pdf},
number = {NeurIPS},
pages = {1--13},
title = {{Stand-Alone Self-Attention in Vision Models}},
url = {http://arxiv.org/abs/1906.05909},
year = {2019}
}
@article{Yang2010,
abstract = {China has seen explosive growth in the sales of electric bikes since 1998. The boom was triggered by Chinese local governments' efforts to restrict motorcycles in city centers. However, many Chinese cities have started to extend the restriction to electric bikes. Whether China's electric bike economy will continue to develop is highly uncertain. The experience of China's electric bike boom suggests that limiting the fossil-fueled alternatives could be an effective policy tool in fostering the commercialization of electric vehicles. The failure of Taiwan's electric scooter policy, on the other hand, indicates that subsidies alone may not be a sufficient launching strategy. The policy approach of limiting the alternatives deserves serious consideration if policymakers wish to foster electric vehicles. {\textcopyright} 2010 Elsevier Inc.},
author = {Yang, Chi Jen},
doi = {10.1016/j.techfore.2010.01.010},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Yang - 2010 - Launching strategy for electric vehicles Lessons from China and Taiwan.pdf:pdf},
issn = {00401625},
journal = {Technological Forecasting and Social Change},
keywords = {Electric bike,Electric vehicles,Plug-in hybrid,Transportation policy},
number = {5},
pages = {831--834},
publisher = {Elsevier Inc.},
title = {{Launching strategy for electric vehicles: Lessons from China and Taiwan}},
url = {http://dx.doi.org/10.1016/j.techfore.2010.01.010},
volume = {77},
year = {2010}
}
@article{Kinghorn1995,
abstract = {A challenge facing designers of commercial trucks and other commercial vehicles has been a lack of current operator anthropometric data on which to base design decisions. Existing data suffer from a number of limitations including those related to secular size changes, ethnic and gender composition shifts, and excessive standard errors (S.E.) of percentiles estimates. These and other limitations point out the need for estimates of contemporary, professional driver anthropometry. This report (1) presents tabulations of comprehensive male and female driver population anthropometry estimates, and (2) outlines a method for applying these anthropometric data to the design of trucks and other vehicles. {\textcopyright} 1995.},
author = {Kinghorn, Rhonda A. and Bittner, Alvah C.},
doi = {10.1016/0169-8141(94)00033-Y},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Kinghorn, Bittner - 1995 - Truck driver anthropometric data Estimation of the current population.pdf:pdf},
issn = {01698141},
journal = {International Journal of Industrial Ergonomics},
keywords = {Anthropometry,Commercial vehicle operator,Estimation,Truck driver},
number = {3},
pages = {199--204},
title = {{Truck driver anthropometric data: Estimation of the current population}},
volume = {15},
year = {1995}
}
@misc{Feynman1964,
author = {Feynman, Richard},
title = {{The Principle of Least Action}},
url = {https://www.feynmanlectures.caltech.edu/II{\_}19.html},
urldate = {2020-05-04},
year = {1964}
}
@article{Yudkowsky2004,
abstract = {This is an update to that part of Friendly AI theory that describes Friendliness, the objective or thing-we're-trying-to-do. The information is current as of May 2004, and should not become dreadfully obsolete until late June, when I plan to have an unexpected insight. (Update: Actually, it took two days. Still, the text here isn't too far from the mark.) Misleading terminology alert: I am still calling the Friendly Thingy an “Artificial Intelligence” or “superintelligence,” even though it would be more accurate to call it a Friendly Really Powerful Optimization Process},
author = {Yudkowsky, Eliezer S.},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Yudkowsky - 2004 - Coherent extrapolated volition.pdf:pdf},
journal = {Singularity Institute for Artificial Intelligence},
number = {2004},
title = {{Coherent extrapolated volition}},
url = {https://intelligence.org/files/CEV.pdf{\%}0Ahttp://miri.wpengine.com/files/CEV.pdf},
year = {2004}
}
@article{Rosso2007,
abstract = {Chaotic systems share with stochastic processes several properties that make them almost undistinguishable. In this communication we introduce a representation space, to be called the complexity-entropy causality plane. Its horizontal and vertical axis are suitable functionals of the pertinent probability distribution, namely, the entropy of the system and an appropriate statistical complexity measure, respectively. These two functionals are evaluated using the Bandt-Pompe recipe to assign a probability distribution function to the time series generated by the system. Several well-known model-generated time series, usually regarded as being of either stochastic or chaotic nature, are analyzed so as to illustrate the approach. The main achievement of this communication is the possibility of clearly distinguishing between them in our representation space, something that is rather difficult otherwise. {\textcopyright} 2007 The American Physical Society.},
author = {Rosso, O. A. and Larrondo, H. A. and Martin, M. T. and Plastino, A. and Fuentes, M. A.},
doi = {10.1103/PhysRevLett.99.154102},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Rosso et al. - 2007 - Distinguishing noise from chaos.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
number = {15},
pages = {1--4},
title = {{Distinguishing noise from chaos}},
volume = {99},
year = {2007}
}
@article{Graves2014,
abstract = {We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-to-end, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples.},
archivePrefix = {arXiv},
arxivId = {1410.5401},
author = {Graves, Alex and Wayne, Greg and Danihelka, Ivo},
eprint = {1410.5401},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Graves, Wayne, Danihelka - 2014 - Neural Turing Machines.pdf:pdf},
pages = {1--26},
title = {{Neural Turing Machines}},
url = {http://arxiv.org/abs/1410.5401},
year = {2014}
}
@article{Gessert2020,
abstract = {This paper addresses two key problems of skin lesion classification. The first problem is the effective use of high-resolution images with pretrained standard architectures for image classification. The second problem is the high-class imbalance encountered in real-world multi-class datasets. Methods: To use high-resolution images, we propose a novel patch-based attention architecture that provides global context between small, high-resolution patches. We modify three pretrained architectures and study the performance of patch-based attention. To counter class imbalance problems, we compare oversampling, balanced batch sampling, and class-specific loss weighting. Additionally, we propose a novel diagnosis-guided loss weighting method that takes the method used for ground-truth annotation into account. Results: Our patch-based attention mechanism outperforms previous methods and improves the mean sensitivity by $\backslash$text{\{}7{\}}$\backslash${\%}. Class balancing significantly improves the mean sensitivity and we show that our diagnosis-guided loss weighting method improves the mean sensitivity by $\backslash$text{\{}3{\}}$\backslash${\%} over normal loss balancing. Conclusion: The novel patch-based attention mechanism can be integrated into pretrained architectures and provides global context between local patches while outperforming other patch-based methods. Hence, pretrained architectures can be readily used with high-resolution images without downsampling. The new diagnosis-guided loss weighting method outperforms other methods and allows for effective training when facing class imbalance. Significance: The proposed methods improve automatic skin lesion classification. They can be extended to other clinical applications where high-resolution image data and class imbalance are relevant.},
archivePrefix = {arXiv},
arxivId = {1905.02793},
author = {Gessert, Nils and Sentker, Thilo and Madesta, Frederic and Schmitz, Rudiger and Kniep, Helge and Baltruschat, Ivo and Werner, Rene and Schlaefer, Alexander},
doi = {10.1109/TBME.2019.2915839},
eprint = {1905.02793},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gessert et al. - 2020 - Skin Lesion Classification Using CNNs with Patch-Based Attention and Diagnosis-Guided Loss Weighting.pdf:pdf},
issn = {15582531},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Skin lesion classification,attention,deep learning,dermoscopy},
month = {feb},
number = {2},
pages = {495--503},
publisher = {IEEE Computer Society},
title = {{Skin Lesion Classification Using CNNs with Patch-Based Attention and Diagnosis-Guided Loss Weighting}},
volume = {67},
year = {2020}
}
@article{Ding2019,
abstract = {The trade-off between feature representation power and spatial localization accuracy is crucial for the dense classification/semantic segmentation of aerial images. High-level features extracted from the late layers of a neural network are rich in semantic information, yet have blurred spatial details; low-level features extracted from the early layers of a network contain more pixel-level information, but are isolated and noisy. It is therefore difficult to bridge the gap between high and low-level features due to their difference in terms of physical information content and spatial distribution. In this work, we contribute to solve this problem by enhancing the feature representation in two ways. On the one hand, a patch attention module (PAM) is proposed to enhance the embedding of context information based on a patch-wise calculation of local attention. On the other hand, an attention embedding module (AEM) is proposed to enrich the semantic information of low-level features by embedding local focus from high-level features. Both of the proposed modules are light-weight and can be applied to process the extracted features of convolutional neural networks (CNNs). Experiments show that, by integrating the proposed modules into the baseline Fully Convolutional Network (FCN), the resulting local attention network (LANet) greatly improves the performance over the baseline and outperforms other attention based methods on two aerial image datasets.},
archivePrefix = {arXiv},
arxivId = {1911.08877},
author = {Ding, Lei and Tang, Hao and Bruzzone, Lorenzo},
eprint = {1911.08877},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ding, Tang, Bruzzone - 2019 - Improving Semantic Segmentation of Aerial Images Using Patch-based Attention.pdf:pdf},
month = {nov},
title = {{Improving Semantic Segmentation of Aerial Images Using Patch-based Attention}},
url = {http://arxiv.org/abs/1911.08877},
year = {2019}
}
@article{Li2020,
abstract = {This paper investigates the automatic exploration problem under the unknown environment, which is the key point of applying the robotic system to some social tasks. The solution to this problem via stacking decision rules is impossible to cover various environments and sensor properties. Learning based control methods are adaptive for these scenarios. However, these methods are damaged by low learning efficiency and awkward transferability from simulation to reality. In this paper, we construct a general exploration framework via decomposing the exploration process into the decision, planning, and mapping modules, which increases the modularity of the robotic system. Based on this framework, we propose a deep reinforcement learning based decision algorithm which uses a deep neural network to learning exploration strategy from the partial map. The results show that this proposed algorithm has better learning efficiency and adaptability for unknown environments. In addition, we conduct the experiments on the physical robot, and the results suggest that the learned policy can be well transfered from simulation to the real robot.},
author = {Li, Haoran and Zhang, Qichao and Zhao, Dongbin},
file = {:Users/jaime/Documents/SwinDRLVP/papers/li2019.pdf:pdf},
journal = {arXiv},
keywords = {Automatic exploration,Deep reinforcement learning,Optimal decision,Partial observation},
pages = {1--13},
title = {{Deep reinforcement learning based automatic exploration for navigation in unknown environment}},
year = {2020}
}
@article{Mills2017,
address = {London :},
author = {Mills, J O and Jalil, A and Stanga, P E},
issn = {0950-222X},
journal = {Eye.},
number = {10},
pages = {1383--1398},
publisher = {Nature Pub Group},
title = {{Electronic retinal implants and artificial vision: journey and present}},
volume = {31},
year = {2017}
}
@book{Blum2013,
abstract = {Includes index.},
author = {Blum, Christian and Alba, Enrique. and {Association for Computing Machinery. SIGEVO.}},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Blum, Alba, Association for Computing Machinery. SIGEVO. - 2013 - GECCO'13 proceedings of the 2013 Genetic and Evolutionary Computation.pdf:pdf},
isbn = {9781450319645},
pages = {1766},
publisher = {ACM},
title = {{GECCO'13 : proceedings of the 2013 Genetic and Evolutionary Computation Conference Companion : July 6-10, 2013, Amsterdam, the Netherlands}},
year = {2013}
}
@book{Altman1999,
author = {Altman, Eitan},
publisher = {Chapman {\&} Hall/Crc},
title = {{Constrained Markov decision processes}},
year = {1999}
}
@article{Dhiman2018,
abstract = {The navigation problem is classically approached in two steps: an exploration step, where map-information about the environment is gathered; and an exploitation step, where this information is used to navigate efficiently. Deep reinforcement learning (DRL) algorithms, alternatively, approach the problem of navigation in an end-to-end fashion. Inspired by the classical approach, we ask whether DRL algorithms are able to inherently explore, gather and exploit map-information over the course of navigation. We build upon Mirowski et al. [2017]'s work and introduce a systematic suite of experiments that vary three parameters: the agent's starting location, the agent's target location, and the maze structure. We choose evaluation metrics that explicitly measure the algorithm's ability to gather and exploit map-information. Our experiments show that when trained and tested on the same maps, the algorithm successfully gathers and exploits map-information. However, when trained and tested on different sets of maps, the algorithm fails to transfer the ability to gather and exploit map-information to unseen maps. Furthermore, we find that when the goal location is randomized and the map is kept static, the algorithm is able to gather and exploit map-information but the exploitation is far from optimal. We open-source our experimental suite in the hopes that it serves as a framework for the comparison of future algorithms and leads to the discovery of robust alternatives to classical navigation methods.},
archivePrefix = {arXiv},
arxivId = {1802.02274},
author = {Dhiman, Vikas and Banerjee, Shurjo and Griffin, Brent and Siskind, Jeffrey M. and Corso, Jason J.},
eprint = {1802.02274},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1802.02274.pdf:pdf},
journal = {arXiv},
title = {{A critical investigation of deep reinforcement learning for navigation}},
year = {2018}
}
@misc{Norberg-Hodge2012,
author = {Norberg-Hodge, Helena},
title = {{The Economics of Happiness}},
year = {2012}
}
@article{Wang2018,
abstract = {Traditionally, reinforcement learning treats punishments as negative rewards. However, in biological decision systems, some evidence shows that animals have separate systems for rewards and punishments. The MaxPain architecture parallelizes the predictions of rewards and punishments and scales them into dual-attribute policies, and has been shown to both improve the learning speed and the learning of safer behaviors. This paper extends the MaxPain architecture into a deep reinforcement learning framework using convolutional neural networks to approximate two action-value functions. To derive the behavioral policy, we consider the mixture distributions of the policies computed from the two action-value functions. For evaluation, we compare the MaxPain architecture with count-based exploration and a reward-decomposing structure called Hybrid Reward Architecture (HRA) in grid-world navigation and vision-based navigation in a U-shape maze in the Gazebo robot simulation environment. The simulation results show the superiority of the MaxPain approach over the count-based method because the MaxPain agents efficiently avoid dead-end states by predicting future punishments. In addition, the MaxPain agents learn safe behaviors, while the HRA agents learn similar behaviors, as in the case of no punishments.},
author = {Wang, Jiexin and Elfwing, Stefan and Uchibe, Eiji},
doi = {10.1109/DEVLRN.2018.8761044},
file = {:Users/jaime/Documents/SwinDRLVP/papers/wang2018.pdf:pdf},
isbn = {9781538661109},
journal = {2018 Joint IEEE 8th International Conference on Development and Learning and Epigenetic Robotics, ICDL-EpiRob 2018},
pages = {175--180},
publisher = {IEEE},
title = {{Deep reinforcement learning by parallelizing reward and punishment using the maxpain architecture}},
year = {2018}
}
@article{Florensa2017,
abstract = {Many relevant tasks require an agent to reach a certain state or to manipulate objects into a desired configuration. For example, we might want a robot to align and assemble a gear onto an axle or insert and turn a key in a lock. These goal-oriented tasks present a considerable challenge for reinforcement learning, since their natural reward function is sparse and prohibitive amounts of exploration are required to reach the goal and receive some learning signal. Past approaches tackle these problems by exploiting expert demonstrations or by manually designing a task-specific reward shaping function to guide the learning agent. Instead, we propose a method to learn these tasks without requiring any prior knowledge other than obtaining a single state in which the task is achieved. The robot is trained in “reverse,” gradually learning to reach the goal from a set of start states increasingly far from the goal. Our method automatically generates a curriculum of start states that adapts to the agent's performance, leading to efficient training on goal-oriented tasks. We demonstrate our approach on difficult simulated navigation and fine-grained manipulation problems, not solvable by state-of-the-art reinforcement learning methods.},
archivePrefix = {arXiv},
arxivId = {1707.05300},
author = {Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael R. and Abbeel, Pieter},
eprint = {1707.05300},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1707.05300.pdf:pdf},
journal = {arXiv},
keywords = {Automatic Curriculum Generation,Reinforcement Learning,Robotic Manipulation},
number = {CoRL},
pages = {1--14},
title = {{Reverse curriculum generation for reinforcement learning}},
year = {2017}
}
@misc{Meyes2019,
abstract = {Ablation studies have been widely used in the field of neuroscience to tackle complex biological systems such as the extensively studied Drosophila central nervous system, the vertebrate brain and more interestingly and most delicately, the human brain. In the past, these kinds of studies were utilized to uncover structure and organization in the brain, i.e. a mapping of features inherent to external stimuli onto different areas of the neocortex. considering the growth in size and complexity of state-of-the-art artificial neural networks (ANNs) and the corresponding growth in complexity of the tasks that are tackled by these networks, the question arises whether ablation studies may be used to investigate these networks for a similar organization of their inner representations. In this paper, we address this question and performed two ablation studies in two fundamentally different ANNs to investigate their inner representations of two well-known benchmark datasets from the computer vision domain. We found that features distinct to the local and global structure of the data are selectively represented in specific parts of the network. Furthermore, some of these representations are redundant, awarding the network a certain robustness to structural damages. We further determined the importance of specific parts of the network for the classification task solely based on the weight structure of single units. Finally, we examined the ability of damaged networks to recover from the consequences of ablations by means of recovery training. We argue that ablations studies are a feasible method to investigate knowledge representations in ANNs and are especially helpful to examine a networks robustness to structural damages, a feature of ANNs that will become increasingly important for future safety-critical applications. Our code is publicly available 1 to reproduce our results and build upon them.},
archivePrefix = {arXiv},
arxivId = {1901.08644},
author = {Meyes, Richard and Lu, Melanie and de Puiseau, Constantin Waubert and Meisen, Tobias},
booktitle = {arXiv},
eprint = {1901.08644},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1901.08644.pdf:pdf},
issn = {23318422},
pages = {1--19},
title = {{Ablation studies in artificial neural networks}},
year = {2019}
}
@article{Maille2020,
author = {Maill{\'{e}}, S{\'{e}}bastien and Lynn, Michael},
doi = {10.1523/JNEUROSCI.2740-19.2020},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Maill{\'{e}}, Lynn - 2020 - Reconciling current theories of consciousness.pdf:pdf},
issn = {15292401},
journal = {Journal of Neuroscience},
number = {10},
pages = {1994--1996},
pmid = {32132221},
title = {{Reconciling current theories of consciousness}},
volume = {40},
year = {2020}
}
@article{Verbancsics2013,
abstract = {An important goal for the machine learning (ML) community is to create approaches that can learn solutions with human-level capability. One domain where humans have held a significant advantage is visual processing. A significant approach to addressing this gap has been machine learning approaches that are inspired from the natural systems, such as artificial neural networks (ANNs), evolutionary computation (EC), and generative and developmental systems (GDS). Research into deep learning has demonstrated that such architectures can achieve performance competitive with humans on some visual tasks; however, these systems have been primarily trained through supervised and unsupervised learning algorithms. Alternatively, research is showing that evolution may have a significant role in the development of visual systems. Thus this paper investigates the role neuro-evolution (NE) can take in deep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting Topologies is a NE approach that can effectively learn large neural structures by training an indirect encoding that compresses the ANN weight pattern as a function of geometry. The results show that HyperNEAT struggles with performing image classification by itself, but can be effective in training a feature extractor that other ML approaches can learn from. Thus NeuroEvolution combined with other ML methods provides an intriguing area of research that can replicate the processes in nature.},
archivePrefix = {arXiv},
arxivId = {1312.5355},
author = {Verbancsics, Phillip and Harguess, Josh},
eprint = {1312.5355},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Verbancsics, Harguess - 2013 - Generative NeuroEvolution for Deep Learning.pdf:pdf},
pages = {1--9},
title = {{Generative NeuroEvolution for Deep Learning}},
url = {http://arxiv.org/abs/1312.5355},
year = {2013}
}
@article{Brandt1983,
abstract = {This article aims to summarize, for non-philosophers, what seems a persuasive form of rule-utilitarianism, to identify some problems of the theory which seem not wholly resolved, and to defend the theory against some popular objections. among the problems discussed are the implications of the theory for professional ethics, governments, and institutions; the choice between hedonistic and 'preference' conceptions of utility; and the implications for population control and obligations to future generations.},
author = {Brandt, Richard B.},
doi = {10.2307/3561774},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Brandt - 1983 - The Real {\&} Alleged Problems of Utilitarianism.pdf:pdf},
issn = {00930334},
journal = {The Hastings Center Report},
number = {2},
pages = {37},
title = {{The Real {\&} Alleged Problems of Utilitarianism}},
volume = {13},
year = {1983}
}
@book{Dawkins2003,
abstract = {This chapter illustrates the use of artificial life, not as a formal model of real life but as a generator of insight in the understanding of real life. Genetics is the study of the relationships between genotypes in successive generations. Embryology is the study of the relationship between genotype and phenotype in any one generation. The fundamental principle of embryology in real life was formulated by Weismann. In every generation, the genes of that generation influence the phenotype of that generation. The success of that phenotype determines whether or not the genes that it bears, a set that largely overlaps with the genes that influenced its development, shall go forward to the next generation. The chapter explores the far-reaching consequences of the fact that these sets do not necessarily have to overlap. Any individual born, therefore, inherits genes that have succeeded in building a long series of successful phenotypes, for the simple reason that failed phenotypes do not pass on their genes. It is important to understand that genes do two quite distinct things. They participate in embryology, influencing the development of the phenotype in a given generation; and they participate in genetics, getting themselves copied down the generations. It is too often not realized-even by some of those that wear the labels geneticist or embryologist-that there is a radical separation between the disciplines of genetics and embryology. {\textcopyright} 2003 Elsevier Ltd. All rights reserved.},
author = {Dawkins, Richard},
booktitle = {On Growth, Form and Computers},
doi = {10.1016/B978-012428765-5/50046-3},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Dawkins - 2003 - The evolution of evolvability.pdf:pdf},
isbn = {9780124287655},
number = {1893},
pages = {239--255},
publisher = {Woodhead Publishing Limited},
title = {{The evolution of evolvability}},
url = {http://dx.doi.org/10.1016/B978-012428765-5/50046-3},
year = {2003}
}
@article{Hardin1968,
author = {Hardin, Garrett},
doi = {10.7135/upo9781843318637.006},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hardin - 1968 - The tragedy of the commons.pdf:pdf},
isbn = {9781315092546},
issn = {00027685},
journal = {International Environmental Governance},
number = {December},
pages = {47--52},
title = {{The tragedy of the commons}},
volume = {162},
year = {1968}
}
@article{Bookchin1987,
abstract = {[Originally published in Green Perspectives: Newsletter of the Green Program Project, nos. 4-5 (summer 1987). In the original, the term deep ecology appeared in quotation marks; they have been removed in this online posting.] The environmental movement has traveled a long way since those early Earth Day festivals when millions of school kids were ritualistically mobilized to clean up streets, while Arthur Godfrey, Barry Commoner, Paul Ehrlich, and a bouquet of manipulative legislators scolded their parents for littering the landscape with cans, newspapers, and bottles. The movement has gone beyond a naive belief that patchwork reforms and solemn vows by EPA bureaucrats to act more resolutely will seriously arrest the insane pace at which we are tearing down the planet. This shopworn Earth Day approach to engineering nature so that we can ravage the Earth with minimal effect on ourselves---an approach that I called environmentalism in the late 1960s, in contrast to social ecology---has shown signs of giving way to a more searching and radical mentality. Today the new word in vogue is ecology---be it deep ecology, human ecology, biocentric ecology, antihumanist ecology, or to use a term that is uniquely rich in meaning, social ecology. Happily, the new relevance of ecology reveals a growing dissatisfaction among thinking people with attempts to use our vast ecological problems for cheaply spectacular and politically manipulative ends. As our forests disappear due to mindless cutting and increasing acid rain, as the ozone layer thins out because of the widespread use of fluorocarbons, as toxic dumps 1 / 22 Social Ecology versus Deep Ecology multiply all over the planet, as highly dangerous, often radioactive pollutants enter into our air, water, and food chains---all, and innumerable other hazards that threaten the integrity of life itself, raise far more basic issues than any that can be resolved by Earth Day clean-ups and faint-hearted changes in existing environmental laws. For good reason, more and more people are trying to go beyond the vapid environmentalism of the early 1970s and develop a more fundamental, indeed a more radical, approach to the ecological crises that beleaguer us. They are looking for an ecological approach, one that is rooted in an ecological philosophy, ethics, sensibility, and image of nature, and ultimately for an ecological movement that will transform our domineering market society into a nonhierarchical cooperative society---a society that will live in harmony with nature because its members live in harmony with one another.},
author = {Bookchin, Murray},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Bookchin - 1987 - Social Ecology versus Deep Ecology A Challenge for the Ecology Movement.pdf:pdf},
journal = {Green Perspectives: Newsletter of the Green Progra Project},
keywords = {Deep Ecology,Deep Malthusians,Earth Day,Green Perspectives,Murray Bookchin,Social Ecology,Social Ecology versus Deep Ecology},
number = {4, 5},
pages = {1--22},
title = {{Social Ecology versus "Deep Ecology": A Challenge for the Ecology Movement}},
url = {http://www.environment.gen.tr/deep-ecology/64-social-ecology-versus-deep-ecology.html},
year = {1987}
}
@incollection{Russell2010,
author = {Russell, Stuart J and Norvig, Peter},
booktitle = {Artificial Intelligence: a Modern Approach},
chapter = {16},
edition = {Third},
pages = {1020--1043},
publisher = {Pearson},
title = {{Philosophical Foundations}},
year = {2010}
}
@article{Barry2016,
author = {Barry, Michael P and Dagnelie, Gislin},
doi = {10.3389/fnsys.2016.00041},
issn = {1662-5137},
journal = {Frontiers in Systems Neuroscience},
pages = {41},
title = {{Hand-Camera Coordination Varies over Time in Users of the Argus{\textregistered} II Retinal Prosthesis System}},
url = {https://www.frontiersin.org/article/10.3389/fnsys.2016.00041},
volume = {10},
year = {2016}
}
@inproceedings{Horne2015,
abstract = {Current and near-term implantable prosthetic vision systems offer the potential to restore some visual function, but suffer from limited resolution and dynamic range of induced visual percepts. This can make navigating complex environments difficult for users. Using semantic labelling techniques, we demonstrate that a computer system can aid in obstacle avoidance, and localizing distant objects. Our system automatically classifies each pixel in a natural image into a semantic class, then produces an image from the induced visual percepts that highlights certain classes. This technique allows the user to clearly perceive the location of different types of objects in their field of view, and can be adapted for a range of navigation tasks.},
annote = {cited By 2},
author = {Horne, Lachlan and Alvarez, Jose M and McCarthy, Chris and Barnes, Nick},
booktitle = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
doi = {10.1109/EMBC.2015.7319117},
isbn = {9781424492718},
issn = {1557170X},
language = {English},
pages = {3379--3382},
pmid = {26737017},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Semantic labelling to aid navigation in prosthetic vision}},
volume = {2015-Novem},
year = {2015}
}
@article{Ji2018,
abstract = {Recent research has shown that conditional adversarial network (cGAN) can be adopted to perform image-to-image translation task effectively. Saliency detection is another challenging computer vision task to model human vision attention mechanism. By reformulating the saliency detection task, in this work, we propose to conduct saliency detection by exploiting conditional adversarial network under the cGAN framework, in which saliency map prediction is transformed as a saliency segmentation task by using pair-wised image-to-ground-truth saliency. To further investigate the potential of cGAN for saliency detection, we train the cGAN model to capture saliency-to-context information by translating saliency mask to real image. Experimental results confirm that the trained generator can achieve comparable state-of-the-art performance on saliency segmentation, and can generate reasonable results for saliency-to-image translation.},
author = {Ji, Yuzhu and Zhang, Haijun and {Jonathan Wu}, Q. M.},
doi = {10.1016/j.neucom.2018.08.013},
file = {:Users/jaime/Documents/SwinDRLVP/papers/ji2018.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Conditional adversarial network,Image to image translation,Saliency segmentation},
pages = {357--368},
publisher = {Elsevier B.V.},
title = {{Saliency detection via conditional adversarial image-to-image network}},
url = {https://doi.org/10.1016/j.neucom.2018.08.013},
volume = {316},
year = {2018}
}
@article{Chaffre2019,
archivePrefix = {arXiv},
arxivId = {arXiv:2004.14684v1},
author = {Chaffre, Thomas and Moras, Julien and Chan-hon-tong, Adrien and Marzat, Julien},
eprint = {arXiv:2004.14684v1},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2004.14684.pdf:pdf},
title = {{Sim-to-Real Transfer with Incremental Environment Complexity for Reinforcement Learning of Depth-Based Robot Navigation}},
year = {2019}
}
@misc{Monbiot2016,
author = {Monbiot, George},
booktitle = {The Guardian},
title = {{Neoliberalism – The Ideology at the Root of All Our Problems}},
url = {https://www.theguardian.com/books/2016/apr/15/neoliberalism-ideology-problem-george-monbiot},
urldate = {2020-05-30},
year = {2016}
}
@article{Kiral-Kornek2014,
annote = {cited By 1},
author = {Kiral-Kornek, F I and Osullivan-Greene, E and Savage, C O and McCarthy, C and Grayden, D B and Burkitt, A N},
doi = {10.1088/1741-2560/11/6/066002},
issn = {17412560},
journal = {Journal of Neural Engineering},
language = {English},
number = {6},
publisher = {Institute of Physics Publishing},
title = {{Improved visual performance in letter perception through edge orientation encoding in a retinal prosthesis simulation}},
volume = {11},
year = {2014}
}
@article{GarridoMerchan2020,
abstract = {Recent developments in machine learning have pushed the tasks that machines can do outside the boundaries of what was thought to be possible years ago. Methodologies such as deep learning or generative models have achieved complex tasks such as generating art pictures or literature automatically. Machine Consciousness is a field that has been deeply studied and several theories based in the functionalism philosophical theory like the global workspace theory have been proposed. In this work, we propose an architecture that may arise consciousness in a machine based in the global workspace theory and in the assumption that consciousness appear in machines that have cognitive processes and exhibit conscious behaviour. This architecture is based in processes that use the recent Deep Learning and generative process models. For every module of this architecture, we provide detailed explanations of the models involved and how they communicate with each other to create the cognitive architecture. We illustrate how we can optimize the architecture to generate social interactions between robots and genuine pieces of art, both features correlated with machine consciousness. As far as we know, this is the first machine consciousness architecture that use generative models and deep learning to exhibit conscious social behaviour and to retrieve pictures and other subjective content made by robots.},
archivePrefix = {arXiv},
arxivId = {2002.00509},
author = {{Garrido Merch{\'{a}}n}, Eduardo C. and Molina, Martin},
doi = {10.1007/978-3-030-61705-9_29},
eprint = {2002.00509},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2002.00509.pdf:pdf},
journal = {arXiv},
keywords = {Artificial Intelligence,Deep Learning Gaussian Processes,Machine Consciousness,Machine Learning},
pages = {1--12},
title = {{A machine consciousness architecture based on deep learning and gaussian processes}},
year = {2020}
}
@article{Carmigniani2011,
abstract = {This paper surveys the current state-of-the-art of technology, systems and applications in Augmented Reality. It describes work performed by many different research groups, the purpose behind each new Augmented Reality system, and the difficulties and problems encountered when building some Augmented Reality applications. It surveys mobile augmented reality systems challenges and requirements for successful mobile systems. This paper summarizes the current applications of Augmented Reality and speculates on future applications and where current research will lead Augmented Reality's development. Challenges augmented reality is facing in each of these applications to go from the laboratories to the industry, as well as the future challenges we can forecast are also discussed in this paper. Section 1 gives an introduction to what Augmented Reality is and the motivations for developing this technology. Section 2 discusses Augmented Reality Technologies with computer vision methods, AR devices, interfaces and systems, and visualization tools. The mobile and wireless systems for Augmented Reality are discussed in Section 3. Four classes of current applications that have been explored are described in Section 4. These applications were chosen as they are the most famous type of applications encountered when researching AR apps. The future of augmented reality and the challenges they will be facing are discussed in Section 5. {\textcopyright} 2010 Springer Science+Business Media, LLC.},
author = {Carmigniani, Julie and Furht, Borko and Anisetti, Marco and Ceravolo, Paolo and Damiani, Ernesto and Ivkovic, Misa},
doi = {10.1007/s11042-010-0660-6},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Carmigniani et al. - 2011 - Augmented reality technologies, systems and applications.pdf:pdf},
issn = {13807501},
journal = {Multimedia Tools and Applications},
keywords = {AR,Augmented reality,Augmented reality applications,Augmented reality iphone4,Augmented reality on mobile devices,Augmented reality systems,Augmented reality technologies},
number = {1},
pages = {341--377},
title = {{Augmented reality technologies, systems and applications}},
volume = {51},
year = {2011}
}
@article{Gunkel2018,
abstract = {This essay addresses the other side of the robot ethics debate, taking up and investigating the question “Can and should robots have rights?” The examination of this subject proceeds by way of three steps or movements. We begin by looking at and analyzing the form of the question itself. There is an important philosophical difference between the two modal verbs that organize the inquiry—can and should. This difference has considerable history behind it that influences what is asked about and how. Second, capitalizing on this verbal distinction, it is possible to identify four modalities concerning social robots and the question of rights. The second section will identify and critically assess these four modalities as they have been deployed and developed in the current literature. Finally, we will conclude by proposing another alternative, a way of thinking otherwise that effectively challenges the existing rules of the game and provides for other ways of theorizing moral standing that can scale to the unique challenges and opportunities that are confronted in the face of social robots.},
author = {Gunkel, David J.},
doi = {10.1007/s10676-017-9442-4},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gunkel - 2018 - The other question can and should robots have rights.pdf:pdf;:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gunkel - 2018 - The other question can and should robots have rights(2).pdf:pdf},
isbn = {0123456789},
issn = {15728439},
journal = {Ethics and Information Technology},
keywords = {David Hume,Emmanuel Levinas,Ethics,Philosophy of technology,Rights,Robotics,Social robots},
number = {2},
pages = {87--99},
publisher = {Springer Netherlands},
title = {{The other question: can and should robots have rights?}},
url = {http://dx.doi.org/10.1007/s10676-017-9442-4},
volume = {20},
year = {2018}
}
@book{Graesser2018,
abstract = {Intelligent tutoring systems (ITS) are computer learning environments that help students master knowledge and skills by implementing intelligent algorithms that adapt to students at a fine-grained level and that instantiate complex principles of learning. An ITS normally works with one student at a time because students differ on many dimensions and the goal is to be sensitive to the idiosyncrasies of individual learners. ITS have been developed for mathematics and other computationally well-formed topics as well as knowledge domains that have a verbal foundation. Reviews and quantitative meta-analyses confirm that ITS technologies frequently improve learning over reading text and traditional teacher-directed classroom teaching. This chapter describes affordances that are frequently incorporated in most applications. Some affordances are routinely incorporate in ITS (active student learning, interactivity, adaptivity, and feedback) whereas others are frequently but not always included (choice, non-linear access to topics, linked representations, and open-ended learner input). The Generalized Intelligent Framework for Tutoring (GIFT) is a framework that articulates the frequent practices, pedagogical and technical standards, and computational architectures for developing ITS; the goal of the GIFT initiative is to scale up ITS development for schools, the military, industry, and the public. The chapter also identifies major challenges in building ITS and some of their limitations.},
author = {Graesser, Arthur C. and Hu, Xiangen and Sottilare, Robert},
booktitle = {International Handbook of the Learning Sciences},
doi = {10.4324/9781315617572},
file = {:Users/jaime/Documents/SwinDRLVP/papers/10.1007@978-3-030-49663-0.pdf:pdf},
isbn = {9781317208365},
pages = {246--255},
title = {{Intelligent tutoring systems}},
year = {2018}
}
@article{Zhang2020,
abstract = {Computer-aided early diagnosis of Alzheimer's disease (AD) and its prodromal form mild cognitive impairment (MCI) based on structure Magnetic Resonance Imaging (sMRI) has provided a cost-effective and objective way for early prevention and treatment of disease progression, leading to improved patient care. In this work, we have proposed a novel computer-aided approach for early diagnosis of AD by introducing an explainable 3D Residual Attention Deep Neural Network (3D ResAttNet) for end-to-end learning from sMRI scans. Different from the existing approaches, the novelty of our approach is three-fold: 1) A Residual Self-Attention Deep Neural Network has been proposed to capture local, global and spatial information of MR images to improve diagnostic performance; 2) An explainable method using Gradient-based Localization Class Activation mapping (Grad-CAM) has been introduced to improve the explainable of the proposed method; 3) This work has provided a full end-to-end learning solution for automated disease diagnosis. Our proposed 3D ResAttNet method has been evaluated on a large cohort of subjects from real dataset for two changeling classification tasks (i.e. Alzheimer's disease (AD) vs. Normal cohort (NC) and progressive MCI (pMCI) vs. stable MCI (sMCI)). The experimental results show that the proposed approach outperforms the state-of-the-art models with significant performance improvement. The accuracy for AD vs. NC and sMCI vs. pMCI task are 97.1{\%} and 84.1{\%} respectively. The explainable mechanism in our approach regions is able to identify and highlight the contribution of the important brain parts (hippocampus, lateral ventricle and most parts of the cortex) for transparent decisions.},
archivePrefix = {arXiv},
arxivId = {2008.04024},
author = {Zhang, Xin and Han, Liangxiu and Zhu, Wenyong and Sun, Liang and Zhang, Daoqiang},
eprint = {2008.04024},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2020 - An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint Atrophy Localization and Alzheimer's Disea.pdf:pdf},
number = {8},
pages = {1--10},
title = {{An Explainable 3D Residual Self-Attention Deep Neural Network FOR Joint Atrophy Localization and Alzheimer's Disease Diagnosis using Structural MRI}},
url = {http://arxiv.org/abs/2008.04024},
volume = {14},
year = {2020}
}
@article{Lehnert2019,
abstract = {Reinforcement learning (RL) has been widely used to implement autonomous navigation in artificial agents, where the goal is to learn a behaviour which maximizes the reward, through interaction with the environment. Most of the recent architectures used in autonomous agents obtain information from the environment using visual modules implemented by convolutional neural networks, where the visual features resulting from learning are unknown or uncertain, which impose limitations considering the large number of parameters to be learned by the entire system. Research in retina physiology has been able to characterize it not as a single light-electrical transductor but as a complex device performing a variety of computations of the visual information, preparing the data for further stages of processing in the visual system. We propose an RL architecture that uses retina physiology knowledge to fed the convolutional neural network, avoiding the learning stage in the sensory input. The performance of the proposed architecture was evaluated using the DeepMind Lab environment simulating an agent moving inside two different maze scenarios. The results obtained reveal promising extension of the inclusion of biological- plausible mechanisms inside artificial intelligence applications.},
author = {Lehnert, Hans and Escobar, Maria Jose and Araya, Mauricio},
doi = {10.1109/IJCNN.2019.8851896},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Lehnert, Escobar, Araya - 2019 - Retina-inspired Visual Module for Robot Navigation in Complex Environments.pdf:pdf},
isbn = {9781728119854},
journal = {Proceedings of the International Joint Conference on Neural Networks},
number = {July},
pages = {1--8},
title = {{Retina-inspired Visual Module for Robot Navigation in Complex Environments}},
volume = {2019-July},
year = {2019}
}
@article{Trappey2012,
abstract = {Conserving energy and reducing carbon emissions have become the common responsibility of the international community. During the year 2010, the Taiwan government planned a four-year project budgeted at 300 million US dollars, called "The Penghu Low Carbon Island Development Project." The policy objective is to use Penghu Island (population 85,000) as a test platform to evaluate new ways to conserve energy and reduce carbon emissions before attempting to replicate the policies on Taiwan Island. For Taiwan, a zero carbon island green transportation policy will regulate the total number of electric scooters, the total number of gasoline motorcycles, influence government subsidy incentives, and create the need for new motorcycle license issuing and control. These factors interact with each other to form a complex and dynamic system that impacts policy as well as the current way of life. In this study, a system dynamics approach is designed to construct a model for evaluating the green transportation policy on Penghu Island. Simulations are conducted to model green transportation system behavior and related policy effects in a smaller, controlled environment before creating policies for Taiwan Island that will impact the lives of over 23 million people. {\textcopyright} 2012 Elsevier Ltd.},
author = {Trappey, Amy J.C. and Trappey, Charles and Hsiao, C. T. and Ou, Jerry J.R. and Li, S. J. and Chen, Kevin W.P.},
doi = {10.1016/j.enpol.2012.02.063},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Trappey et al. - 2012 - An evaluation model for low carbon island policy The case of Taiwan's green transportation policy.pdf:pdf},
issn = {03014215},
journal = {Energy Policy},
keywords = {Green transportation policy,Penghu Low Carbon Island,System dynamics},
pages = {510--515},
title = {{An evaluation model for low carbon island policy: The case of Taiwan's green transportation policy}},
volume = {45},
year = {2012}
}
@article{Jaderberg2017,
abstract = {Neural networks dominate the modern machine learning landscape, but their training and success still suffer from sensitivity to empirical choices of hyperparameters such as model architecture, loss function, and optimisation algorithm. In this work we present $\backslash$emph{\{}Population Based Training (PBT){\}}, a simple asynchronous optimisation algorithm which effectively utilises a fixed computational budget to jointly optimise a population of models and their hyperparameters to maximise performance. Importantly, PBT discovers a schedule of hyperparameter settings rather than following the generally sub-optimal strategy of trying to find a single fixed set to use for the whole course of training. With just a small modification to a typical distributed hyperparameter training framework, our method allows robust and reliable training of models. We demonstrate the effectiveness of PBT on deep reinforcement learning problems, showing faster wall-clock convergence and higher final performance of agents by optimising over a suite of hyperparameters. In addition, we show the same method can be applied to supervised learning for machine translation, where PBT is used to maximise the BLEU score directly, and also to training of Generative Adversarial Networks to maximise the Inception score of generated images. In all cases PBT results in the automatic discovery of hyperparameter schedules and model selection which results in stable training and better final performance.},
archivePrefix = {arXiv},
arxivId = {1711.09846},
author = {Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M. and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and Fernando, Chrisantha and Kavukcuoglu, Koray},
eprint = {1711.09846},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Jaderberg et al. - 2017 - Population Based Training of Neural Networks.pdf:pdf},
title = {{Population Based Training of Neural Networks}},
url = {http://arxiv.org/abs/1711.09846},
year = {2017}
}
@article{Hollingsworth2019,
abstract = {Shared stand-up electric scooters are now offered in many cities as an option for short-term rental, and marketed for short-distance travel. Using life cycle assessment, we quantify the total environmental impacts of this mobility option associated with global warming, acidification, eutrophication, and respiratory impacts. We find that environmental burdens associated with charging the e-scooter are small relative to materials and manufacturing burdens of the e-scooters and the impacts associated with transporting the scooters to overnight charging stations. The results of a Monte Carlo analysis show an average value of life cycle global warming impacts of 202 g CO2-eq/passenger-mile, driven by materials and manufacturing (50{\%}), followed by daily collection for charging (43{\%} of impact). We illustrate the potential to reduce life cycle global warming impacts through improved scooter collection and charging approaches, including the use of fuel-efficient vehicles for collection (yielding 177 g CO2-eq/passenger-mile), limiting scooter collection to those with a low battery state of charge (164 g CO2-eq/passenger-mile), and reducing the driving distance per scooter for e-scooter collection and distribution (147 g CO2-eq/passenger-mile). The results prove to be highly sensitive to e-scooter lifetime; ensuring that the shared e-scooters are used for two years decreases the average life cycle emissions to 141 g CO2-eq/passenger-mile. Under our Base Case assumptions, we find that the life cycle greenhouse gas emissions associated with e-scooter use is higher in 65{\%} of our Monte Carlo simulations than the suite of modes of transportation that are displaced. This likelihood drops to 35{\%}-50{\%} under our improved and efficient e-scooter collection processes and only 4{\%} when we assume two-year e-scooter lifetimes. When e-scooter usage replaces average personal automobile travel, we nearly universally realize a net reduction in environmental impacts.},
author = {Hollingsworth, Joseph and Copeland, Brenna and Johnson, Jeremiah X.},
doi = {10.1088/1748-9326/ab2da8},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hollingsworth, Copeland, Johnson - 2019 - Are e-scooters polluters the environmental impacts of shared dockless electric scooters.pdf:pdf},
issn = {17489326},
journal = {Environmental Research Letters},
keywords = {electric scooter,environmental impacts,life cycle assessment,transportation},
number = {8},
publisher = {IOP Publishing},
title = {{Are e-scooters polluters? the environmental impacts of shared dockless electric scooters}},
volume = {14},
year = {2019}
}
@article{Gare2010,
author = {Gare, Arran},
doi = {10.5840/process20103912},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Gare - 2010 - Toward an Ecological Civilization The Science, Ethics, and Politics of Eco-Poiesis.pdf:pdf},
issn = {0360-6503},
journal = {Process Studies},
keywords = {civilization,common good,environmental philosophy,hierarchy theory,human ecology,philosophy,political philosophy,politics,process philosophy,religious studies,social science},
number = {1},
pages = {5--38},
title = {{Toward an Ecological Civilization: The Science, Ethics, and Politics of Eco-Poiesis}},
volume = {39},
year = {2010}
}
@misc{Benhamou2018,
abstract = {Modern machine learning uses more and more advanced optimization techniques to find optimal hyper parameters. Whenever the objective function is non-convex, non continuous and with potentially multiple local minima, standard gradient descent optimization methods fail. A last resource and very different method is to assume that the optimum(s), not necessarily unique, is/are distributed according to a distribution and iteratively to adapt the distribution according to tested points. These strategies originated in the early 1960s, named Evolution Strategy (ES) have culminated with the CMA-ES (Covariance Matrix Adaptation) ES. It relies on a multi variate normal distribution and is supposed to be state of the art for general optimization program. However, it is far from being optimal for discrete variables. In this paper, we extend the method to multivariate binomial correlated distributions. For such a distribution, we show that it shares similar features to the multi variate normal: independence and correlation is equivalent and correlation is efficiently modeled by interaction between different variables. We discuss this distribution in the framework of the exponential family. We prove that the model can estimate not only pairwise interactions among the two variables but also is capable of modeling higher order interactions. This allows creating a version of CMA ES that can accomodate efficiently discrete variables. We provide the corresponding algorithm and conclude.},
archivePrefix = {arXiv},
arxivId = {1812.11859},
author = {Benhamou, Eric and Atif, Jamal and Laraki, Rida},
booktitle = {arXiv},
doi = {10.2139/ssrn.3307212},
eprint = {1812.11859},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1812.11859.pdf:pdf},
issn = {1556-5068},
title = {{A discrete version of CMA-ES}},
year = {2018}
}
@article{Hansen2001,
abstract = {This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation. Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed. Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed. Applying arbitrary, normal mutation distributions is equivalent to applying a general, linear problem encoding. The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future. If this objective is pursued rigorously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions. This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands. It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps. Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation. Their performances are comparable only on perfectly scaled functions. On badly scaled, non-separable functions usually a speed up factor of several orders of magnitude is observed. On moderately mis-scaled functions a speed up factor of three to ten can be expected.},
author = {Hansen, N. and Ostermeier, A.},
doi = {10.1162/106365601750190398},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hansen, Ostermeier - 2001 - Completely derandomized self-adaptation in evolution strategies.pdf:pdf},
issn = {10636560},
journal = {Evolutionary computation},
keywords = {covariance matrix adaptation,cumulation,cumulative path length control,de-,derandomized self-adaptation,evolu-,evolution strategy,randomization,self-adaptation,step size control,strategy parameter control,tion path},
number = {2},
pages = {159--195},
title = {{Completely derandomized self-adaptation in evolution strategies.}},
volume = {9},
year = {2001}
}
@article{Moiseyev1991,
author = {Moiseyev, N. N.},
doi = {10.1080/02604027.1991.9972260},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Moiseyev - 1991 - Noogenesis—The Fundamental Problem of Our Time.pdf:pdf},
issn = {15561844},
journal = {World Futures},
keywords = {contradictions,global evolution,global reason,noosphere,transition},
number = {4},
pages = {197--206},
title = {{Noogenesis—The Fundamental Problem of Our Time}},
volume = {32},
year = {1991}
}
@article{Cordonnier,
abstract = {Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional layers as a primary building block. Beyond helping CNNs to handle long-range dependencies, Ramachan-dran et al. (2019) showed that attention can completely replace convolution and achieve state-of-the-art performance on vision tasks. This raises the question: do learned attention layers operate similarly to convolutional layers? This work provides evidence that attention layers can perform convolution and, indeed, they often learn to do so in practice. Specifically, we prove that a multi-head self-attention layer with sufficient number of heads is at least as expressive as any convolutional layer. Our numerical experiments then show that self-attention layers attend to pixel-grid patterns similarly to CNN layers, corroborating our analysis. Our code is publicly available 1 .},
author = {Cordonnier, Jean-Baptiste and Loukas, Andreas and Jagg{\'{i}}, Martin Jagg{\'{i}}},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Cordonnier, Loukas, Jagg{\'{i}} - Unknown - On the Relationship Between Self-Attention and Convolutional Layers.pdf:pdf},
title = {{On the Relationship Between Self-Attention and Convolutional Layers}}
}
@article{Xia2015,
abstract = {Retinal prostheses for the restoration of functional vision are under development and visual prostheses targeting proximal stages of the visual pathway are also being explored. To investigate the experience with visual prostheses, psychophysical experiments using simulated prosthetic vision in normally sighted individuals are necessary. In this study, a helmet display with real-time images from a camera attached to the helmet provided the simulated vision, and experiments of recognition and discriminating multiple objects were used to evaluate visual performance under different parameters (gray scale, distortion, and dropout). The process of fitting and training with visual prostheses was simulated and estimated by adaptation to the parameters with time. The results showed that the increase in the number of gray scale and the decrease in phosphene distortion and dropout rate improved recognition performance significantly, and the recognition accuracy was 61.8±7.6{\%} under the optimum condition (gray scale: 8, distortion: k=0, dropout: 0{\%}). The adaption experiments indicated that the recognition performance was improved with time and the effect of adaptation to distortion was greater than dropout, which implies the difference of adaptation mechanism to the two parameters.},
author = {Xia, Peng and Hu, Jie and Peng, Yinghong},
doi = {10.1111/aor.12504},
issn = {15251594},
journal = {Artificial Organs},
keywords = {Neuroplasticity,Object recognition,Psychophysics,Retinal prostheses,Simulated prosthetic vision},
number = {12},
pages = {1038--1045},
pmid = {25912967},
title = {{Adaptation to Phosphene Parameters Based on Multi-Object Recognition Using Simulated Prosthetic Vision}},
volume = {39},
year = {2015}
}
@article{Sorokin2015,
abstract = {A deep learning approach to reinforcement learning led to a general learner able to train on visual input to play a variety of arcade games at the human and superhuman levels. Its creators at the Google DeepMind's team called the approach: Deep Q-Network (DQN). We present an extension of DQN by "soft" and "hard" attention mechanisms. Tests of the proposed Deep Attention Recurrent Q-Network (DARQN) algorithm on multiple Atari 2600 games show level of performance superior to that of DQN. Moreover, built-in attention mechanisms allow a direct online monitoring of the training process by highlighting the regions of the game screen the agent is focusing on when making decisions.},
archivePrefix = {arXiv},
arxivId = {1512.01693},
author = {Sorokin, Ivan and Seleznev, Alexey and Pavlov, Mikhail and Fedorov, Aleksandr and Ignateva, Anastasiia},
eprint = {1512.01693},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Sorokin et al. - 2015 - Deep Attention Recurrent Q-Network.pdf:pdf},
month = {dec},
title = {{Deep Attention Recurrent Q-Network}},
url = {http://arxiv.org/abs/1512.01693},
year = {2015}
}
@article{Park2020,
abstract = {Typical reinforcement learning (RL) methods show limited applicability for real-world industrial control problems because industrial systems involve various constraints and simultaneously require continuous and discrete control. To overcome these challenges, we devise a novel RL algorithm that enables an agent to handle a highly constrained action space. This algorithm has two main features. First, we devise two distance-based Q-value update schemes, incentive update and penalty update, in a distance-based incentive/penalty update technique to enable the agent to decide discrete and continuous actions in the feasible region and to update the value of these types of actions. Second, we propose a method for defining the penalty cost as a shadow price-weighted penalty. This approach affords two advantages compared to previous methods to efficiently induce the agent to not select an infeasible action. We apply our algorithm to an industrial control problem, microgrid system operation, and the experimental results demonstrate its superiority.},
archivePrefix = {arXiv},
arxivId = {2011.10897},
author = {Park, Hyungjun and Min, Daiki and Ryu, Jong-hyun and Choi, Dong Gu},
eprint = {2011.10897},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2011.10897.pdf:pdf},
pages = {1--8},
title = {{Reinforcement learning with distance-based incentive/penalty (DIP) updates for highly constrained industrial control systems}},
url = {http://arxiv.org/abs/2011.10897},
year = {2020}
}
@article{Mace2015,
abstract = {Clinical trials with blind patients implanted with a visual neuroprosthesis showed that even the simplest tasks were difficult to perform with the limited vision restored with current implants. Simulated prosthetic vision (SPV) is a powerful tool to investigate the putative functions of the upcoming generations of visual neuroprostheses. Recent studies based on SPV showed that several generations of implants will be required before usable vision is restored. However, none of these studies relied on advanced image processing. High-level image processing could significantly reduce the amount of information required to perform visual tasks and help restore visuomotor behaviors, even with current low-resolution implants. In this study, we simulated a prosthetic vision device based on object localization in the scene. We evaluated the usability of this device for object recognition, localization, and reaching. We showed that a very low number of electrodes (e.g., nine) are sufficient to restore visually guided reaching movements with fair timing (10s) and high accuracy. In addition, performance, both in terms of accuracy and speed, was comparable with 9 and 100 electrodes. Extraction of high level information (object recognition and localization) from video images could drastically enhance the usability of current visual neuroprosthesis. We suggest that this method-that is, localization of targets of interest in the scene-may restore various visuomotor behaviors. This method could prove functional on current low-resolution implants. The main limitation resides in the reliability of the vision algorithms, which are improving rapidly.},
annote = {cited By 7},
author = {Mac{\'{e}}, Marc J.M. and Guivarch, Val{\'{e}}rian and Denis, Gr{\'{e}}goire and Jouffrais, Christophe},
doi = {10.1111/aor.12476},
issn = {15251594},
journal = {Artificial Organs},
keywords = {Blindness,Computer vision,Simulated prosthetic vision,Visual impairment,Visual neuroprosthesis},
language = {English},
number = {7},
pages = {E102--E113},
pmid = {25900238},
publisher = {Blackwell Publishing Inc.},
title = {{Simulated Prosthetic Vision: The Benefits of Computer-Based Object Recognition and Localization}},
volume = {39},
year = {2015}
}
@article{Czarnecki2018,
abstract = {We introduce Mix {\&} Match (M{\&}M) - A training framework designed to facilitate rapid and effective learning in RL agents, especially those that would be too slow or too challenging to train otherwise. The key innovation is a procedure that allows us to automatically form a curriculum over agents. Through such a curriculum we can progressively train more complex agents by, effectively, bootstrapping from solutions found by simpler agents. In contradistinction to typical curriculum learning approaches, we do not gradually modify the tasks or environments presented, but instead use a process to gradually alter how the policy is represented internally. We show the broad applicability of our method by demonstrating significant performance gains in three different experimental setups: (I) We train an agent able to control more than 700 actions in a challenging 3D first-person task; using our method to progress through an action-space cur-riculum wc achieve both faster training and better final performance than one obtains using tradi-tional methods. (2) We further show that M{\&}M can be used successfully to progress through a curriculum of architectural variants defining an agents internal state. (3) Finally, we illustrate how a variant of our method can be used to improve agent performance in a multitask setting.},
archivePrefix = {arXiv},
arxivId = {1806.01780},
author = {Czarnecki, Wojciech Marian and Jayakumar, Siddhant M. and Jadcrbcrg, Max and Hasenclever, Leonard and Tch, Yec Whye and Osindero, Simon and Heess, Nicolas and Pascanu, Razvan},
eprint = {1806.01780},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1806.01780.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning, ICML 2018},
pages = {1761--1773},
title = {{Mix {\&} match - Agent curricula for reinforcement learning}},
volume = {3},
year = {2018}
}
@article{Chapman-Rounds2019,
abstract = {Models of visual saliency normally belong to one of two camps: models such as Experience Guided Search (E-GS), which emphasize top-down guidance based on task features, and models such as Attention as Information Maximisation (AIM), which emphasize the role of bottom-up saliency. In this paper, we show that E-GS and AIM are structurally similar and can be unified to create a general model of visual search which includes a generic prior over potential non-task related objects. We demonstrate that this model displays inattentional blindness, and that blindness can be modulated by adjusting the relative precisions of several terms within the model. At the same time, our model correctly accounts for a series of classical visual search results.},
author = {Chapman-Rounds, Matt and Lucas, Christopher and Keller, Frank},
doi = {10.31234/osf.io/yts23},
file = {:Users/jaime/Documents/SwinDRLVP/papers/Cogsci2019-2.pdf:pdf},
keywords = {Bayesian Brain,Inattentional Blindness,Visual Search},
title = {{Inattentional Blindness in Visual Search}},
year = {2019}
}
@misc{Konstan2018,
author = {Konstan, David},
booktitle = {The Stanford Encyclopedia of Philosophy},
title = {{Epicurus}},
urldate = {2020-05-30},
year = {2018}
}
@article{Bashashati2007,
abstract = {Brain-computer interfaces (BCIs) aim at providing a non-muscular channel for sending commands to the external world using the electroencephalographic activity or other electrophysiological measures of the brain function. An essential factor in the successful operation of BCI systems is the methods used to process the brain signals. In the BCI literature, however, there is no comprehensive review of the signal processing techniques used. This work presents the first such comprehensive survey of all BCI designs using electrical signal recordings published prior to January 2006. Detailed results from this survey are presented and discussed. The following key research questions are addressed: (1) what are the key signal processing components of a BCI, (2) what signal processing algorithms have been used in BCIs and (3) which signal processing techniques have received more attention? {\textcopyright} 2007 IOP Publishing Ltd.},
author = {Bashashati, Ali and Fatourechi, Mehrdad and Ward, Rabab K. and Birch, Gary E.},
doi = {10.1088/1741-2560/4/2/R03},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Bashashati et al. - 2007 - A survey of signal processing algorithms in brain-computer interfaces based on electrical brain signals.pdf:pdf},
issn = {17412560},
journal = {Journal of Neural Engineering},
number = {2},
pmid = {17409474},
title = {{A survey of signal processing algorithms in brain-computer interfaces based on electrical brain signals}},
volume = {4},
year = {2007}
}
@article{Martinez-Gonzalez2020,
abstract = {Data-driven algorithms have surpassed traditional techniques in almost every aspect in robotic vision problems. Such algorithms need vast amounts of quality data to be able to work properly after their training process. Gathering and annotating that sheer amount of data in the real world is a time-consuming and error-prone task. These problems limit scale and quality. Synthetic data generation has become increasingly popular since it is faster to generate and automatic to annotate. However, most of the current datasets and environments lack realism, interactions, and details from the real world. UnrealROX is an environment built over Unreal Engine 4 which aims to reduce that reality gap by leveraging hyperrealistic indoor scenes that are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline to generate raw data and ground truth annotations. This virtual reality environment enables robotic vision researchers to generate realistic and visually plausible data with full ground truth for a wide variety of problems such as class and instance semantic segmentation, object detection, depth estimation, visual grasping, and navigation.},
archivePrefix = {arXiv},
arxivId = {1810.06936},
author = {Martinez-Gonzalez, Pablo and Oprea, Sergiu and Garcia-Garcia, Alberto and Jover-Alvarez, Alvaro and Orts-Escolano, Sergio and Garcia-Rodriguez, Jose},
doi = {10.1007/s10055-019-00399-5},
eprint = {1810.06936},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1810.06936.pdf:pdf},
issn = {14349957},
journal = {Virtual Reality},
keywords = {Grasping,Robotics,Synthetic data},
number = {2},
pages = {271--288},
title = {{UnrealROX: an extremely photorealistic virtual reality environment for robotics simulations and synthetic data generation}},
volume = {24},
year = {2020}
}
@article{Mirowski2017,
abstract = {Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour1, its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities.},
archivePrefix = {arXiv},
arxivId = {1611.03673},
author = {Mirowski, Piotr and Pascanu, Razvan and Viola, Fabio and Soyer, Hubert and Ballard, Andrew J. and Banino, Andrea and Denil, Misha and Goroshin, Ross and Sifre, Laurent and Kavukcuoglu, Koray and Kumaran, Dharshan and Hadsell, Raia},
eprint = {1611.03673},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Mirowski et al. - 2017 - Learning to navigate in complex environments.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
title = {{Learning to navigate in complex environments}},
year = {2017}
}
@misc{Cameracci2019,
abstract = {We present structured domain randomization (SDR), a variant of domain randomization (DR) that takes into account the structure and context of the scene. In contrast to DR, which places objects and distractors randomly according to a uniform probability distribution, SDR places objects and distractors randomly according to probability distributions that arise from the specific problem at hand. In this manner, SDR-generated imagery enables the neural network to take the context around an object into consideration during detection. We demonstrate the power of SDR for the problem of 2D bounding box car detection, achieving competitive results on real data after training only on synthetic data. On the KITTI easy, moderate, and hard tasks, we show that SDR outperforms other approaches to generating synthetic data (VKITTI, Sim 200k, or DR), as well as real data collected in a different domain (BDD100K). Moreover, synthetic SDR data combined with real KITTI data outperforms real KITTI data alone.},
author = {Prakash, Aayush and Cameracci, Eric and Boochoon, Shaad and State, Gavriel and Brophy, Mark and Shapira, Omer and Acuna, David and Birchfield, Stan},
booktitle = {arXiv},
file = {:Users/jaime/Documents/SwinDRLVP/papers/prakash2019.pdf:pdf},
isbn = {9781538660270},
pages = {7249--7255},
title = {{Structured domain randomization: Bridging the reality gap by context-aware synthetic data}},
year = {2018}
}
@article{Ha2018,
abstract = {We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment.},
archivePrefix = {arXiv},
arxivId = {arXiv:1803.10122v4},
author = {Ha, David and Schmidhuber, J{\"{u}}rgen},
eprint = {arXiv:1803.10122v4},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ha, Schmidhuber - 2018 - World models.pdf:pdf},
title = {{World models}},
year = {2018}
}
@article{Rand2012,
abstract = {Cooperation is central to human social behaviour. However, choosing to cooperate requires individuals to incur a personal cost to benefit others. Here we explore the cognitive basis of cooperative decision-making in humans using a dual-process framework. We ask whether people are predisposed towards selfishness, behaving cooperatively only through active self-control; or whether they are intuitively cooperative, with reflection and prospective reasoning favouring rational self-interest. To investigate this issue, we perform ten studies using economic games. We find that across a range of experimental designs, subjects who reach their decisions more quickly are more cooperative. Furthermore, forcing subjects to decide quickly increases contributions, whereas instructing them to reflect and forcing them to decide slowly decreases contributions. Finally, an induction that primes subjects to trust their intuitions increases contributions compared with an induction that promotes greater reflection. To explain these results, we propose that cooperation is intuitive because cooperative heuristics are developed in daily life where cooperation is typically advantageous. We then validate predictions generated by this proposed mechanism. Our results provide convergent evidence that intuition supports cooperation in social dilemmas, and that reflection can undermine these cooperative impulses. {\textcopyright} 2012 Macmillan Publishers Limited. All rights reserved.},
author = {Rand, David G. and Greene, Joshua D. and Nowak, Martin A.},
doi = {10.1038/nature11467},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Rand, Greene, Nowak - 2012 - Spontaneous giving and calculated greed.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {7416},
pages = {427--430},
pmid = {22996558},
publisher = {Nature Publishing Group},
title = {{Spontaneous giving and calculated greed}},
url = {http://dx.doi.org/10.1038/nature11467},
volume = {489},
year = {2012}
}
@article{Snoek2012,
abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm{\{}$\backslash$textquoteright{\}}s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expert-level performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
archivePrefix = {arXiv},
arxivId = {1206.2944v2},
author = {Jasper},
doi = {10.1017/9781316266175.015},
eprint = {1206.2944v2},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Jasper - 2016 - Practical Bayes optimization.pdf:pdf},
isbn = {9781316266175},
journal = {The Cambridge Companion to Saul Bellow},
pages = {159--170},
title = {{Practical Bayes optimization}},
year = {2016}
}
@article{Chuang2014,
abstract = {Retinal implants present an innovative way of restoring sight in degenerative retinal diseases. Previous reviews of research progress were written by groups developing their own devices. This systematic review objectively compares selected models by examining publications describing five representative retinal prostheses: Argus II, Boston Retinal Implant Project, Epi-Ret 3, Intelligent Medical Implants (IMI) and Alpha-IMS (Retina Implant AG). Publications were analysed using three criteria for interim success: clinical availability, vision restoration potential and long-term biocompatibility. Clinical availability: Argus II is the only device with FDA approval. Argus II and Alpha-IMS have both received the European CE Marking. All others are in clinical trials, except the Boston Retinal Implant, which is in animal studies. Vision restoration: resolution theoretically correlates with electrode number. Among devices with external cameras, the Boston Retinal Implant leads with 100 electrodes, followed by Argus II with 60 electrodes and visual acuity of 20/1262. Instead of an external camera, Alpha-IMS uses a photodiode system dependent on natural eye movements and can deliver visual acuity up to 20/546. Long-term compatibility: IMI offers iterative learning; Epi-Ret 3 is a fully intraocular device; Alpha-IMS uses intraocular photosensitive elements. Merging the results of these three criteria, Alpha-IMS is the most likely to achieve long-term success decades later, beyond current clinical availability.},
author = {Chuang, Alice T. and Margo, Curtis E. and Greenberg, Paul B.},
doi = {10.1136/bjophthalmol-2013-303708},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Chuang, Margo, Greenberg - 2014 - Retinal implants A systematic review.pdf:pdf},
issn = {14682079},
journal = {British Journal of Ophthalmology},
number = {7},
pages = {852--856},
pmid = {24403565},
title = {{Retinal implants: A systematic review}},
volume = {98},
year = {2014}
}
@inproceedings{Hu2019,
abstract = {The convolution layer has been the dominant feature extractor in computer vision for years. However, the spatial aggregation in convolution is basically a pattern matching process that applies fixed filters which are inefficient at modeling visual elements with varying spatial distributions. This paper presents a new image feature extractor, called the local relation layer, that adaptively determines aggregation weights based on the compositional relationship of local pixel pairs. With this relational approach, it can composite visual elements into higher-level entities in a more efficient manner that benefits semantic inference. A network built with local relation layers, called the Local Relation Network (LR-Net), is found to provide greater modeling capacity than its counterpart built with regular convolution on large-scale recognition tasks such as ImageNet classification.},
archivePrefix = {arXiv},
arxivId = {1904.11491},
author = {Hu, Han and Zhang, Zheng and Xie, Zhenda and Lin, Stephen},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2019.00356},
eprint = {1904.11491},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hu et al. - 2019 - Local relation networks for image recognition.pdf:pdf},
isbn = {9781728148038},
issn = {15505499},
month = {oct},
pages = {3463--3472},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Local relation networks for image recognition}},
volume = {2019-Octob},
year = {2019}
}
@article{Christiano2017,
abstract = {For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than 1{\%} of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.},
annote = {Human (non-expert) compares short video snippets of the agent's actions. Agent learns the value of actions based on the comparison.

Reward function predictor is updated via supervised learning using the segment comparisons rated by humans. Comparisons are stored as triples (sigma1, sigma2, mu), with mu being a distribution with either all its mass on the preferred segment, or uniform if they are deemed equal. If the human expresses that they cannot rate the segments, the triple is not stored.

It must be hard for the human to compare segment at the start of training when behavior is random?

},
archivePrefix = {arXiv},
arxivId = {1706.03741},
author = {Christiano, Paul F. and Leike, Jan and Brown, Tom B. and Martic, Miljan and Legg, Shane and Amodei, Dario},
eprint = {1706.03741},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Christiano et al. - 2017 - Deep reinforcement learning from human preferences.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {4300--4308},
title = {{Deep reinforcement learning from human preferences}},
volume = {2017-Decem},
year = {2017}
}
@misc{Lipton2015,
author = {Lipton, Zachary C and Berkowitz, John and Elkan, Charles},
title = {{A Critical Review of Recurrent Neural Networks for Sequence Learning}},
url = {https://arxiv.org/abs/1506.00019},
year = {2015}
}
@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
journal = {Nature},
month = {may},
pages = {529--533},
title = {{Human-level control through deep reinforcement learning}},
url = {https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf},
volume = {518},
year = {2015}
}
@article{Vergnieux2017,
abstract = {Visual neuroprostheses are still limited and simulated prosthetic vision (SPV) is used to evaluate potential and forthcoming functionality of these implants. SPV has been used to evaluate the minimum requirement on visual neuroprosthetic characteristics to restore various functions such as reading, objects and face recognition, object grasping, etc. Some of these studies focused on obstacle avoidance but only a few investigated orientation or navigation abilities with prosthetic vision. The resolution of current arrays of electrodes is not sufficient to allow navigation tasks without additional processing of the visual input. In this study, we simulated a low resolution array (15 × 18 electrodes, similar to a forthcoming generation of arrays) and evaluated the navigation abilities restored when visual information was processed with various computer vision algorithms to enhance the visual rendering. Three main visual rendering strategies were compared to a control rendering in a wayfinding task within an unknown environment. The control rendering corresponded to a resizing of the original image onto the electrode array size, according to the average brightness of the pixels. In the first rendering strategy, vision distance was limited to 3, 6, or 9 m, respectively. In the second strategy, the rendering was not based on the brightness of the image pixels, but on the distance between the user and the elements in the field of view. In the last rendering strategy, only the edges of the environments were displayed, similar to a wireframe rendering. All the tested renderings, except the 3 m limitation of the viewing distance, improved navigation performance and decreased cognitive load. Interestingly, the distance-based and wireframe renderings also improved the cognitive mapping of the unknown environment. These results show that low resolution implants are usable for wayfinding if specific computer vision algorithms are used to select and display appropriate information regarding the environment.},
author = {Vergnieux, Victor and Mac{\'{e}}, Marc J.‐M. and Jouffrais, Christophe},
doi = {10.1111/aor.12868},
issn = {15251594},
journal = {Artificial Organs},
keywords = {Blind,Computer vision,Navigation,Retinal implant,Spatial cognition,Visual neuroprostheses,Wayfinding},
number = {9},
pages = {852--861},
pmid = {28321887},
title = {{Simplification of Visual Rendering in Simulated Prosthetic Vision Facilitates Navigation}},
volume = {41},
year = {2017}
}
@inproceedings{Schmidhuber2013,
author = {Schmidhuber, J{\"{u}}rgen and Koutn{\'{i}}k, Jan and Cuccu, Giuseppe and Gomez, Faustino},
booktitle = {Proceedings of the 15th annual conference on Genetic and evolutionary computation},
pages = {1061--1068},
title = {{Evolving large-scale neural networks for vision-based reinforcement learning}},
url = {http://people.idsia.ch/{~}juergen/compressednetworksearch.html},
year = {2013}
}
@article{Jin2020,
abstract = {Nature provides a way to understand physics with reinforcement learning since nature favors the economical way for an object to propagate. In the case of classical mechanics, nature favors the object to move along the path according to the integral of the Lagrangian, called the action {\$}\backslashmathcal{\{}S{\}}{\$}. We consider setting the reward/penalty as a function of {\$}\backslashmathcal{\{}S{\}}{\$}, so the agent could learn the physical trajectory of particles in various kinds of environments with reinforcement learning. In this work, we verified the idea by using a Q-Learning based algorithm on learning how light propagates in materials with different refraction indices, and show that the agent could recover the minimal-time path equivalent to the solution obtained by Snell's law or Fermat's Principle. We also discuss the similarity of our reinforcement learning approach to the path integral formalism.},
archivePrefix = {arXiv},
arxivId = {2011.11891},
author = {Jin, Zehao and Lin, Joshua Yao-Yu and Li, Siao-Fong},
eprint = {2011.11891},
file = {:Users/jaime/Documents/SwinDRLVP/papers/2011.11891.pdf:pdf},
pages = {1--5},
title = {{Learning Principle of Least Action with Reinforcement Learning}},
url = {http://arxiv.org/abs/2011.11891},
year = {2020}
}
@article{Dong2020,
abstract = {Few-shot learning for visual recognition aims to adapt to novel unseen classes with only a few images. Recent work, especially the work based on low-level information, has achieved great progress. In these work, local representations (LRs) are typically employed, because LRs are more consistent among the seen and unseen classes. However, most of them are limited to an individual image-to-image or image-to-class measure manner, which cannot fully exploit the capabilities of LRs, especially in the context of a certain task. This paper proposes an Adaptive Task-aware Local Representations Network (ATL-Net) to address this limitation by introducing episodic attention, which can adaptively select the important local patches among the entire task, as the process of human recognition. We achieve much superior results on multiple benchmarks. On the miniImagenet, ATL-Net gains 0.93{\%} and 0.88{\%} improvements over the compared methods under the 5-way 1-shot and 5-shot settings. Moreover, ATL-Net can naturally tackle the problem that how to adaptively identify and weight the importance of different key local parts, which is the major concern of fine-grained recognition. Specifically, on the fine-grained dataset Stanford Dogs, ATL-Net outperforms the second best method with 5.39{\%} and 9.69{\%} gains under the 5-way 1-shot and 5-shot settings.},
author = {Dong, Chuanqi and Li, Wenbin and Huo, Jing and Gu, Zheng and Gao, Yang},
doi = {10.24963/ijcai.2020/100},
file = {:Users/jaime/Documents/SwinDRLVP/papers/0100.pdf:pdf},
isbn = {9780999241165},
issn = {10450823},
keywords = {Computer Vision: Recognition: Detection {\&} Categori},
pages = {716--722},
title = {{Learning Task-aware Local Representations for Few-shot Learning}},
year = {2020}
}
@article{Luker1994,
abstract = {A collection of classic articles from the field of artificial intelligence (AI), The Philosophy of Artificial Intelligence would be a good complement to an introductory textbook on AI fundamentals. The back cover of the book states that the material is intended for the university student or general reader, but don't be fooled. Unless you are a student in a supportive class setting or a general reader who happens to have a degree in engineering, you are likely to find the content difficult. The first chapter, for example, assumes knowledge of calculus. However, if you have the right preparation, you'll be treated to fifteen important papers in AI-including Alan Turing's Computing Machinery and Intelligence article, which proposed the now well- known Turing test for determining whether a machine is intelligent.},
author = {Luker, Paul A. and Rothermel, Dennis},
doi = {10.1145/191033.191050},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Luker, Rothermel - 1994 - The philosophy of artificial intelligence.pdf:pdf},
isbn = {0198248547},
issn = {00978418},
journal = {ACM SIGCSE Bulletin},
number = {1},
pages = {41--45},
title = {{The philosophy of artificial intelligence}},
volume = {26},
year = {1994}
}
@article{Bharadhwaj2018,
abstract = {Learning effective visuomotor policies for robots purely from data is challenging, but also appealing since a learning-based system should not require manual tuning or calibration. In the case of a robot operating in a real environment the training process can be costly, time-consuming, and even dangerous since failures are common at the start of training. For this reason, it is desirable to be able to leverage simulation and off-policy data to the extent possible to train the robot. In this work, we introduce a robust framework that plans in simulation and transfers well to the real environment. Our model incorporates a gradient-descent based planning module, which, given the initial image and goal image, encodes the images to a lower dimensional latent state and plans a trajectory to reach the goal. The model, consisting of the encoder and planner modules, is trained through a meta-learning strategy in simulation first. We subsequently perform adversarial domain transfer on the encoder by using a bank of unlabelled but random images from the simulation and real environments to enable the encoder to map images from the real and simulated environments to a similarly distributed latent representation. By fine tuning the entire model (encoder + planner) with far fewer real world expert demonstrations, we show successful planning performances in different navigation tasks.},
author = {Bharadhwaj, Homanga and Wang, Zihan and Bengio, Yoshua and Paull, Liam},
file = {:Users/jaime/Documents/SwinDRLVP/papers/bharadhwaj2019.pdf:pdf},
isbn = {9781538660270},
journal = {arXiv},
keywords = {Learning from Demonstration,Model Learning for Con},
title = {{A data-efficient framework for training and sim-to-real transfer of navigation policies}},
year = {2018}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
archivePrefix = {arXiv},
arxivId = {arXiv:1706.03762v5},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
eprint = {arXiv:1706.03762v5},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Vaswani et al. - 2017 - Attention is all you need.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {5999--6009},
title = {{Attention is all you need}},
volume = {2017-Decem},
year = {2017}
}
@inproceedings{Stein2018,
abstract = {We propose a novel approach for generating high-quality, synthetic data for domain-specific learning tasks, for which training data may not be readily available. We leverage recent progress in image-to-image translation to bridge the gap between simulated and real images, allowing us to generate realistic training data for real-world tasks using only unlabeled real-world images and a simulation. GeneSIS-Rtameliorates the burden of having to collect labeled real-world images and is a promising candidate for generating high-quality, domain-specific, synthetic data. To show the effectiveness of using GeneSIS-Rtto create training data, we study two tasks: semantic segmentation and reactive obstacle avoidance. We demonstrate that learning algorithms trained using data generated by GeneSIS-RT make high-accuracy predictions and outperform systems trained on raw simulated data alone, and as well or better than those trained on real data. Finally, we use our data to train a quadcopter to fly 60 meters at speeds up to 3.4 m/s through a cluttered environment, demonstrating that our GeneSIS-RT images can be used to learn to perform mission-critical tasks.},
archivePrefix = {arXiv},
arxivId = {1710.04280},
author = {Stein, Gregory J and Roy, Nicholas},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2018.8462971},
eprint = {1710.04280},
file = {:Users/jaime/Documents/SwinDRLVP/papers/1710.04280.pdf:pdf},
isbn = {9781538630815},
issn = {10504729},
pages = {7151--7158},
title = {{GeneSIS-Rt: Generating Synthetic Images for Training Secondary Real-World Tasks}},
year = {2018}
}
@article{Lv2020,
abstract = {Embodied artificial intelligence (AI) tasks shift from tasks focusing on internet images to active settings involving embodied agents that perceive and act within 3D environments. In this paper, we investigate the target-driven visual navigation using deep reinforcement learning (DRL) in 3D indoor scenes, whose navigation task aims to train an agent that can intelligently make a series of decisions to arrive at a pre-specified target location from any possible starting positions only based on egocentric views. However, most navigation methods currently struggle against several challenging problems, such as data efficiency, automatic obstacle avoidance, and generalization. Generalization problem means that agent does not have the ability to transfer navigation skills learned from previous experience to unseen targets and scenes. To address these issues, we incorporate two designs into classic DRL framework: attention on 3D knowledge graph (KG) and target skill extension (TSE) module. On the one hand, our proposed method combines visual features and 3D spatial representations to learn navigation policy. On the other hand, TSE module is used to generate sub-targets which allow agent to learn from failures. Specifically, our 3D spatial relationships are encoded through recently popular graph convolutional network (GCN). Considering the real world settings, our work also considers open action and adds actionable targets into conventional navigation situations. Those more difficult settings are applied to test whether DRL agent really understand its task, navigating environment, and can carry out reasoning. Our experiments, performed in the AI2-THOR, show that our model outperforms the baselines in both SR and SPL metrics, and improves generalization ability across targets and scenes.},
archivePrefix = {arXiv},
arxivId = {2005.02153},
author = {Lv, Yunlian and Xie, Ning and Shi, Yimin and Wang, Zijiao and Shen, Heng Tao},
eprint = {2005.02153},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Lv et al. - 2020 - Improving Target-driven Visual Navigation with Attention on 3D Spatial Relationships.pdf:pdf},
pages = {1--12},
title = {{Improving Target-driven Visual Navigation with Attention on 3D Spatial Relationships}},
url = {http://arxiv.org/abs/2005.02153},
year = {2020}
}
@article{Jaderberg2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.05397v1},
author = {Jaderberg, Max and Mnih, Volodymyr},
doi = {10.1051/0004-6361/201527329},
eprint = {arXiv:1611.05397v1},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Jaderberg, Mnih - 2018 - Reinforcement Learning with Unsupervised Auxiliary Tasks.pdf:pdf},
isbn = {2004012439},
issn = {0004-6361},
pages = {1--9},
pmid = {23459267},
title = {{Reinforcement Learning with Unsupervised Auxiliary Tasks}},
year = {2018}
}
@article{Lehnert2019a,
abstract = {Autonomous navigation of artificial agents is a challenging task for changing and complex environments. Reinforcement learning (RL) algorithms are widely used for autonomous navigation, where the agent, through the interaction with the environment, learns the behaviors needed to maximize the reward. Recent architectures extract information from the environment using convolutional neural networks, where the visual features needed to maximize the reward are unknown and uncertain, and then, increasing the number of parameters learned by the entire system. Moreover, the presence of sparse rewards complicates, even more, the task generating unstable results in the learning problem. The work here presented is twofold. First, we show the advantages of using retina physiology knowledge to design a visual sensor feeding the RL network. Secondly, based on intrinsic motivation, we propose the use of auxiliary tasks to deal with sparse rewards, generating a continuous learning process. We define two auxiliary tasks, state, and action predictions, forcing the network to learn characteristics of environment; and also, to detect which of them are valuable for the task. These two contributions were implemented in the DeepMind Lab environment simulating an agent moving inside two different maze scenarios. The results obtained reveal a promising extension of the inclusion of biological-plausible mechanisms inside artificial intelligence applications. Moreover, to include auxiliary tasks improves the performance adding robustness to the system.},
author = {Lehnert, Hans and Araya, Mauricio and Carrasco-Davis, Rodrigo and Escobar, Maria Jose},
doi = {10.1109/TLA.2019.9011549},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Lehnert et al. - 2019 - Bio-Inspired Deep Reinforcement Learning for Autonomous Navigation of Artificial Agents.pdf:pdf},
issn = {15480992},
journal = {IEEE Latin America Transactions},
keywords = {Autonomous Navigation,Reinforcement Learning,Visual Models},
number = {12},
pages = {2037--2044},
title = {{Bio-Inspired Deep Reinforcement Learning for Autonomous Navigation of Artificial Agents}},
volume = {17},
year = {2019}
}
@article{Ulrich2005,
abstract = {The personal electric vehicle (PEV) emerged as a new category of transportation device in the late 1990s. PEVs transport a single passenger over trip distances of 1-10 km and employ electricity as the motive energy source. The category is principally comprised of electric-powered scooters and cycles. Personal electric vehicles offer several potential benefits to consumers and to society including lower transportation costs, reduced trip times, and lower environmental impact. The PEV therefore offers many intriguing possibilities for extending the human range of mobility from about 1 km (via walking) to 10 km or more. However, the full potential of the category has not been realized, to a large extent because the vehicles are not yet light enough, do not go far enough, and cost too much. The main question addressed by this article is what are the technological limits on personal electric vehicle design? And more specifically, How light can PEVs be? How far can they go? How little can they cost? What are the trade-offs across these dimensions of performance at the efficient frontier? The methodological approach of the paper is to combine a technology assessment of the major subsystems of a PEV with a technical model of vehicle performance in order to estimate the cost and mass of a vehicle for a given set of functional requirements. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Ulrich, Karl T.},
doi = {10.1016/j.trc.2006.01.002},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Ulrich - 2005 - Estimating the technology frontier for personal electric vehicles.pdf:pdf},
issn = {0968090X},
journal = {Transportation Research Part C: Emerging Technologies},
keywords = {Cost model,Electric bicycle,Electric scooter,Electric vehicles,Personal electric vehicles,Personal transportation,Technical model},
number = {5-6},
pages = {448--462},
title = {{Estimating the technology frontier for personal electric vehicles}},
volume = {13},
year = {2005}
}
@article{Hausknecht2014,
abstract = {This paper addresses the challenge of learning to play many different video games with little domain-specific knowledge. Specifically, it introduces a neuroevolution approach to general Atari 2600 game playing. Four neuroevolution algorithms were paired with three different state representations and evaluated on a set of 61 Atari games. The neuroevolution agents represent different points along the spectrum of algorithmic sophistication - including weight evolution on topologically fixed neural networks (conventional neuroevolution), covariance matrix adaptation evolution strategy (CMA-ES), neuroevolution of augmenting topologies (NEAT), and indirect network encoding (HyperNEAT). State representations include an object representation of the game screen, the raw pixels of the game screen, and seeded noise (a comparative baseline). Results indicate that direct-encoding methods work best on compact state representations while indirect-encoding methods (i.e., HyperNEAT) allow scaling to higher dimensional representations (i.e., the raw game screen). Previous approaches based on temporal-difference (TD) learning had trouble dealing with the large state spaces and sparse reward gradients often found in Atari games. Neuroevolution ameliorates these problems and evolved policies achieve state-of-the-art results, even surpassing human high scores on three games. These results suggest that neuroevolution is a promising approach to general video game playing (GVGP).},
author = {Hausknecht, Matthew and Lehman, Joel and Miikkulainen, Risto and Stone, Peter},
doi = {10.1109/TCIAIG.2013.2294713},
file = {:Users/jaime/Library/Application Support/Mendeley Desktop/Downloaded/Hausknecht et al. - 2014 - A neuroevolution approach to general atari game playing.pdf:pdf},
issn = {1943068X},
journal = {IEEE Transactions on Computational Intelligence and AI in Games},
keywords = {Algorithms,artificial neural networks,evolutionary computation,genetic algorithms,neural networks},
number = {4},
pages = {355--366},
title = {{A neuroevolution approach to general atari game playing}},
volume = {6},
year = {2014}
}
@phdthesis{Urban2015a,
annote = {Who or what will be in control of that power, and what will their motivation be? 

* oracle
* genie
* sovereign

Nanotechnology replacing traditional methods of production. We can make meat, so animals don't need to die for consumption any more.

ASI could even solve our most complex macro issues—our debates over how economies should be run and how world trade is best facilitated, even our haziest grapplings in philosophy or ethics—would all be painfully obvious to ASI.

Immortality. There is no indication of the necessity of death in biology (Feynman)

“[ASI] is emerging from many diverse efforts and will be deeply integrated into our civilization's infrastructure. Indeed, it will be intimately embedded in our bodies and brains. As such, it will reflect our values because it will be us.” (Kurzweil)

Consciousness of AI? Can it ever be conscious, or will it just mimic self-awareness?

Mind crime: "turning off" artificial intelligence: is it killing it?

Talks about "amorality", things that are outside being moral or immoral. Non-human, nonbiological.

Humans as “the biological boot loader for digital superintelligence” Elon Musk

Fermi paradox

"Superpowers":

* Intelligence amplification. The computer becomes great at making itself smarter, and bootstrapping its own intelligence.
* Strategizing. The computer can strategically make, analyze, and prioritize long-term plans. It can also be clever and outwit beings of lower intelligence.
* Social manipulation. The machine becomes great at persuasion.
* Other skills like computer coding and hacking, technology research, and the ability to work the financial system to make money.

Covert preparation, escape, strike, overt operation.

We'd need to design an AI's core coding in a way that leaves it with a deep understanding of human values.

No, we'd have to program in an ability for humanity to continue evolving. Of everything I read, the best shot I think someone has taken is Eliezer Yudkowsky, with a goal for AI he calls Coherent Extrapolated Volition. The AI's core goal would be:

Our coherent extrapolated volition is our wish if we knew more, thought faster, were more the people we wished we were, had grown up farther together; where the extrapolation converges rather than diverges, where our wishes cohere rather than interfere; extrapolated as we wish that extrapolated, interpreted as we wish that interpreted.

Chinese room thought experiment (Searle). Against functionalism and computationalism theories of mind.},
author = {Urban, Tim},
title = {{The AI Revolution: Our Immortality of Extinction}},
year = {2015}
}
